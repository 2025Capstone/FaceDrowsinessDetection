{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-17T15:51:54.286958Z",
     "start_time": "2024-11-17T15:51:53.887705Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class FaceLandmarksDatasetLimited(Dataset):\n",
    "    def __init__(self, file_paths, max_sequence_length=100):\n",
    "        self.file_paths = file_paths\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        for file_path in self.file_paths:\n",
    "            data = pd.read_csv(file_path, nrows=max_sequence_length)\n",
    "            label = int(file_path.split('/')[-1].split('_')[0])  # Extract label from file name\n",
    "\n",
    "            # Remove the timestamp column\n",
    "            features = data.iloc[:, 1:].values  # Exclude timestamp\n",
    "\n",
    "            # Normalize the features\n",
    "            features = (features - np.mean(features, axis=0)) / np.std(features, axis=0)\n",
    "\n",
    "            # Truncate or pad sequences to the max length\n",
    "            if features.shape[0] > max_sequence_length:\n",
    "                features = features[:max_sequence_length]\n",
    "            else:\n",
    "                padding = np.zeros((max_sequence_length - features.shape[0], features.shape[1]))\n",
    "                features = np.vstack((features, padding))\n",
    "\n",
    "            self.data.append(features)\n",
    "            self.labels.append(label)\n",
    "\n",
    "        self.data = np.array(self.data)\n",
    "        self.labels = np.array(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T15:51:49.008347Z",
     "start_time": "2024-11-17T15:51:47.694623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class FaceLandmarksModelAttention(nn.Module):\n",
    "    def __init__(self, input_dim=1434, hidden_size=128, num_classes=4, num_heads=4, num_layers=2):\n",
    "        super(FaceLandmarksModelAttention, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_size)\n",
    "        self.transformer = TransformerEncoder(\n",
    "            TransformerEncoderLayer(hidden_size, num_heads, dim_feedforward=256, dropout=0.1),\n",
    "            num_layers\n",
    "        )\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)  # Average pooling across sequence length\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        out = self.fc2(x)\n",
    "        return out"
   ],
   "id": "949674a73dfa791",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T15:52:08.072262Z",
     "start_time": "2024-11-17T15:52:07.029742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# Define search space\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "batch_sizes = [32, 64, 128]\n",
    "optimizers = ['Adam', 'SGD', 'RMSprop']\n",
    "epochs = [200]\n",
    "\n",
    "search_space = {\n",
    "    'learning_rate': learning_rates,\n",
    "    'batch_size': batch_sizes,\n",
    "    'optimizer': optimizers,\n",
    "    'epochs': epochs,\n",
    "}\n",
    "\n",
    "parameter_grid = ParameterGrid(search_space)"
   ],
   "id": "4b137caf707c2c3f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T15:52:59.412573Z",
     "start_time": "2024-11-17T15:52:56.813003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "\n",
    "dataset_folder = \"./111/zzz\"  # Update with your folder path\n",
    "csv_files = glob(os.path.join(dataset_folder, \"*.csv\"))\n",
    "print(f\"Found {len(csv_files)} CSV files.\")\n",
    "\n",
    "# Dataset initialization\n",
    "dataset = FaceLandmarksDatasetLimited(csv_files)\n",
    "\n",
    "# Class-wise data splitting\n",
    "labels = dataset.labels\n",
    "unique_labels = np.unique(labels)\n",
    "train_indices, valid_indices = [], []\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_indices = np.where(labels == label)[0]\n",
    "    train_idx, valid_idx = train_test_split(label_indices, test_size=0.3, random_state=42)\n",
    "    train_indices.extend(train_idx)\n",
    "    valid_indices.extend(valid_idx)\n",
    "\n",
    "# Subsets for train and valid\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "valid_dataset = Subset(dataset, valid_indices)\n",
    "\n",
    "# DataLoader creation\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "ca2bfacc00409257",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 CSV files.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T16:04:00.050221Z",
     "start_time": "2024-11-17T15:56:15.872949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Ensure the 'model' folder exists\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Training loop for parameter grid\n",
    "for params in parameter_grid:\n",
    "    print(f\"Training with parameters: {params}\")\n",
    "\n",
    "    # Unpack parameters\n",
    "    lr = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    optimizer_name = params['optimizer']\n",
    "    num_epochs = params['epochs']\n",
    "\n",
    "    # Reinitialize DataLoader with the new batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Initialize model\n",
    "    model = FaceLandmarksModelAttention(input_dim=1434, hidden_size=128, num_layers=2, num_classes=4).to(device)\n",
    "    # model = FaceLandmarksModel(input_size=1404, hidden_size=128, num_layers=2, num_classes=4).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Select optimizer\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    elif optimizer_name == \"RMSprop\":\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "    # Early stopping variables\n",
    "    patience = 10  # Number of epochs with no improvement after which training stops\n",
    "    best_valid_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        valid_loss /= len(valid_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}\")\n",
    "\n",
    "        # Check for improvement\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            epochs_no_improve = 0\n",
    "            print(f\"Validation loss improved to {best_valid_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early stopping condition\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Save the model with final parameters\n",
    "    model_filename = (f\"model/loss_{best_valid_loss:.4f}_lr_{lr}_batch_{batch_size}_\"\n",
    "                      f\"opt_{optimizer_name}.pt\")\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    print(f\"Training completed. Final model saved as {model_filename}\")"
   ],
   "id": "80e25aaa7a00cfb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'batch_size': 32, 'epochs': 200, 'learning_rate': 0.0001, 'optimizer': 'Adam'}\n",
      "Epoch [1/200], Train Loss: 1.4047, Valid Loss: 1.3648\n",
      "Validation loss improved to 1.3648\n",
      "Epoch [2/200], Train Loss: 1.3698, Valid Loss: 1.3476\n",
      "Validation loss improved to 1.3476\n",
      "Epoch [3/200], Train Loss: 1.3318, Valid Loss: 1.3314\n",
      "Validation loss improved to 1.3314\n",
      "Epoch [4/200], Train Loss: 1.3220, Valid Loss: 1.3170\n",
      "Validation loss improved to 1.3170\n",
      "Epoch [5/200], Train Loss: 1.2994, Valid Loss: 1.3048\n",
      "Validation loss improved to 1.3048\n",
      "Epoch [6/200], Train Loss: 1.2764, Valid Loss: 1.2935\n",
      "Validation loss improved to 1.2935\n",
      "Epoch [7/200], Train Loss: 1.2581, Valid Loss: 1.2803\n",
      "Validation loss improved to 1.2803\n",
      "Epoch [8/200], Train Loss: 1.2705, Valid Loss: 1.2673\n",
      "Validation loss improved to 1.2673\n",
      "Epoch [9/200], Train Loss: 1.2330, Valid Loss: 1.2540\n",
      "Validation loss improved to 1.2540\n",
      "Epoch [10/200], Train Loss: 1.2400, Valid Loss: 1.2403\n",
      "Validation loss improved to 1.2403\n",
      "Epoch [11/200], Train Loss: 1.2025, Valid Loss: 1.2268\n",
      "Validation loss improved to 1.2268\n",
      "Epoch [12/200], Train Loss: 1.2011, Valid Loss: 1.2120\n",
      "Validation loss improved to 1.2120\n",
      "Epoch [13/200], Train Loss: 1.2058, Valid Loss: 1.1960\n",
      "Validation loss improved to 1.1960\n",
      "Epoch [14/200], Train Loss: 1.1779, Valid Loss: 1.1817\n",
      "Validation loss improved to 1.1817\n",
      "Epoch [15/200], Train Loss: 1.1120, Valid Loss: 1.1668\n",
      "Validation loss improved to 1.1668\n",
      "Epoch [16/200], Train Loss: 1.1314, Valid Loss: 1.1515\n",
      "Validation loss improved to 1.1515\n",
      "Epoch [17/200], Train Loss: 1.1495, Valid Loss: 1.1336\n",
      "Validation loss improved to 1.1336\n",
      "Epoch [18/200], Train Loss: 1.0793, Valid Loss: 1.1142\n",
      "Validation loss improved to 1.1142\n",
      "Epoch [19/200], Train Loss: 1.0798, Valid Loss: 1.0945\n",
      "Validation loss improved to 1.0945\n",
      "Epoch [20/200], Train Loss: 1.0826, Valid Loss: 1.0760\n",
      "Validation loss improved to 1.0760\n",
      "Epoch [21/200], Train Loss: 1.0338, Valid Loss: 1.0589\n",
      "Validation loss improved to 1.0589\n",
      "Epoch [22/200], Train Loss: 1.0794, Valid Loss: 1.0414\n",
      "Validation loss improved to 1.0414\n",
      "Epoch [23/200], Train Loss: 1.0041, Valid Loss: 1.0269\n",
      "Validation loss improved to 1.0269\n",
      "Epoch [24/200], Train Loss: 1.0195, Valid Loss: 1.0111\n",
      "Validation loss improved to 1.0111\n",
      "Epoch [25/200], Train Loss: 0.9646, Valid Loss: 0.9874\n",
      "Validation loss improved to 0.9874\n",
      "Epoch [26/200], Train Loss: 0.9665, Valid Loss: 0.9668\n",
      "Validation loss improved to 0.9668\n",
      "Epoch [27/200], Train Loss: 0.9423, Valid Loss: 0.9477\n",
      "Validation loss improved to 0.9477\n",
      "Epoch [28/200], Train Loss: 0.9548, Valid Loss: 0.9307\n",
      "Validation loss improved to 0.9307\n",
      "Epoch [29/200], Train Loss: 0.9090, Valid Loss: 0.9147\n",
      "Validation loss improved to 0.9147\n",
      "Epoch [30/200], Train Loss: 0.9025, Valid Loss: 0.9043\n",
      "Validation loss improved to 0.9043\n",
      "Epoch [31/200], Train Loss: 0.8925, Valid Loss: 0.8894\n",
      "Validation loss improved to 0.8894\n",
      "Epoch [32/200], Train Loss: 0.8477, Valid Loss: 0.8663\n",
      "Validation loss improved to 0.8663\n",
      "Epoch [33/200], Train Loss: 0.8633, Valid Loss: 0.8455\n",
      "Validation loss improved to 0.8455\n",
      "Epoch [34/200], Train Loss: 0.8205, Valid Loss: 0.8271\n",
      "Validation loss improved to 0.8271\n",
      "Epoch [35/200], Train Loss: 0.7701, Valid Loss: 0.8099\n",
      "Validation loss improved to 0.8099\n",
      "Epoch [36/200], Train Loss: 0.8182, Valid Loss: 0.7949\n",
      "Validation loss improved to 0.7949\n",
      "Epoch [37/200], Train Loss: 0.7810, Valid Loss: 0.7810\n",
      "Validation loss improved to 0.7810\n",
      "Epoch [38/200], Train Loss: 0.7433, Valid Loss: 0.7642\n",
      "Validation loss improved to 0.7642\n",
      "Epoch [39/200], Train Loss: 0.7182, Valid Loss: 0.7480\n",
      "Validation loss improved to 0.7480\n",
      "Epoch [40/200], Train Loss: 0.7384, Valid Loss: 0.7304\n",
      "Validation loss improved to 0.7304\n",
      "Epoch [41/200], Train Loss: 0.6708, Valid Loss: 0.7130\n",
      "Validation loss improved to 0.7130\n",
      "Epoch [42/200], Train Loss: 0.6938, Valid Loss: 0.6976\n",
      "Validation loss improved to 0.6976\n",
      "Epoch [43/200], Train Loss: 0.6734, Valid Loss: 0.6761\n",
      "Validation loss improved to 0.6761\n",
      "Epoch [44/200], Train Loss: 0.6475, Valid Loss: 0.6576\n",
      "Validation loss improved to 0.6576\n",
      "Epoch [45/200], Train Loss: 0.6359, Valid Loss: 0.6450\n",
      "Validation loss improved to 0.6450\n",
      "Epoch [46/200], Train Loss: 0.6433, Valid Loss: 0.6353\n",
      "Validation loss improved to 0.6353\n",
      "Epoch [47/200], Train Loss: 0.6078, Valid Loss: 0.6237\n",
      "Validation loss improved to 0.6237\n",
      "Epoch [48/200], Train Loss: 0.5920, Valid Loss: 0.6052\n",
      "Validation loss improved to 0.6052\n",
      "Epoch [49/200], Train Loss: 0.5913, Valid Loss: 0.5923\n",
      "Validation loss improved to 0.5923\n",
      "Epoch [50/200], Train Loss: 0.5486, Valid Loss: 0.5782\n",
      "Validation loss improved to 0.5782\n",
      "Epoch [51/200], Train Loss: 0.5731, Valid Loss: 0.5659\n",
      "Validation loss improved to 0.5659\n",
      "Epoch [52/200], Train Loss: 0.5690, Valid Loss: 0.5546\n",
      "Validation loss improved to 0.5546\n",
      "Epoch [53/200], Train Loss: 0.5311, Valid Loss: 0.5369\n",
      "Validation loss improved to 0.5369\n",
      "Epoch [54/200], Train Loss: 0.5224, Valid Loss: 0.5225\n",
      "Validation loss improved to 0.5225\n",
      "Epoch [55/200], Train Loss: 0.4797, Valid Loss: 0.5142\n",
      "Validation loss improved to 0.5142\n",
      "Epoch [56/200], Train Loss: 0.5021, Valid Loss: 0.5048\n",
      "Validation loss improved to 0.5048\n",
      "Epoch [57/200], Train Loss: 0.4710, Valid Loss: 0.4942\n",
      "Validation loss improved to 0.4942\n",
      "Epoch [58/200], Train Loss: 0.4894, Valid Loss: 0.4815\n",
      "Validation loss improved to 0.4815\n",
      "Epoch [59/200], Train Loss: 0.4640, Valid Loss: 0.4702\n",
      "Validation loss improved to 0.4702\n",
      "Epoch [60/200], Train Loss: 0.4432, Valid Loss: 0.4609\n",
      "Validation loss improved to 0.4609\n",
      "Epoch [61/200], Train Loss: 0.4415, Valid Loss: 0.4465\n",
      "Validation loss improved to 0.4465\n",
      "Epoch [62/200], Train Loss: 0.3953, Valid Loss: 0.4339\n",
      "Validation loss improved to 0.4339\n",
      "Epoch [63/200], Train Loss: 0.4103, Valid Loss: 0.4261\n",
      "Validation loss improved to 0.4261\n",
      "Epoch [64/200], Train Loss: 0.3921, Valid Loss: 0.4172\n",
      "Validation loss improved to 0.4172\n",
      "Epoch [65/200], Train Loss: 0.4350, Valid Loss: 0.4064\n",
      "Validation loss improved to 0.4064\n",
      "Epoch [66/200], Train Loss: 0.3958, Valid Loss: 0.3967\n",
      "Validation loss improved to 0.3967\n",
      "Epoch [67/200], Train Loss: 0.3774, Valid Loss: 0.3873\n",
      "Validation loss improved to 0.3873\n",
      "Epoch [68/200], Train Loss: 0.3615, Valid Loss: 0.3812\n",
      "Validation loss improved to 0.3812\n",
      "Epoch [69/200], Train Loss: 0.2913, Valid Loss: 0.3800\n",
      "Validation loss improved to 0.3800\n",
      "Epoch [70/200], Train Loss: 0.3333, Valid Loss: 0.3714\n",
      "Validation loss improved to 0.3714\n",
      "Epoch [71/200], Train Loss: 0.3357, Valid Loss: 0.3625\n",
      "Validation loss improved to 0.3625\n",
      "Epoch [72/200], Train Loss: 0.3248, Valid Loss: 0.3529\n",
      "Validation loss improved to 0.3529\n",
      "Epoch [73/200], Train Loss: 0.2753, Valid Loss: 0.3442\n",
      "Validation loss improved to 0.3442\n",
      "Epoch [74/200], Train Loss: 0.3168, Valid Loss: 0.3400\n",
      "Validation loss improved to 0.3400\n",
      "Epoch [75/200], Train Loss: 0.2836, Valid Loss: 0.3407\n",
      "Epoch [76/200], Train Loss: 0.2332, Valid Loss: 0.3380\n",
      "Validation loss improved to 0.3380\n",
      "Epoch [77/200], Train Loss: 0.2830, Valid Loss: 0.3272\n",
      "Validation loss improved to 0.3272\n",
      "Epoch [78/200], Train Loss: 0.2626, Valid Loss: 0.3154\n",
      "Validation loss improved to 0.3154\n",
      "Epoch [79/200], Train Loss: 0.2586, Valid Loss: 0.2998\n",
      "Validation loss improved to 0.2998\n",
      "Epoch [80/200], Train Loss: 0.2278, Valid Loss: 0.2924\n",
      "Validation loss improved to 0.2924\n",
      "Epoch [81/200], Train Loss: 0.1988, Valid Loss: 0.2963\n",
      "Epoch [82/200], Train Loss: 0.2185, Valid Loss: 0.2992\n",
      "Epoch [83/200], Train Loss: 0.2452, Valid Loss: 0.3042\n",
      "Epoch [84/200], Train Loss: 0.2273, Valid Loss: 0.3015\n",
      "Epoch [85/200], Train Loss: 0.1773, Valid Loss: 0.2899\n",
      "Validation loss improved to 0.2899\n",
      "Epoch [86/200], Train Loss: 0.2019, Valid Loss: 0.2749\n",
      "Validation loss improved to 0.2749\n",
      "Epoch [87/200], Train Loss: 0.1867, Valid Loss: 0.2596\n",
      "Validation loss improved to 0.2596\n",
      "Epoch [88/200], Train Loss: 0.2064, Valid Loss: 0.2531\n",
      "Validation loss improved to 0.2531\n",
      "Epoch [89/200], Train Loss: 0.1659, Valid Loss: 0.2514\n",
      "Validation loss improved to 0.2514\n",
      "Epoch [90/200], Train Loss: 0.2030, Valid Loss: 0.2586\n",
      "Epoch [91/200], Train Loss: 0.1586, Valid Loss: 0.2630\n",
      "Epoch [92/200], Train Loss: 0.1612, Valid Loss: 0.2632\n",
      "Epoch [93/200], Train Loss: 0.1528, Valid Loss: 0.2613\n",
      "Epoch [94/200], Train Loss: 0.1472, Valid Loss: 0.2557\n",
      "Epoch [95/200], Train Loss: 0.1594, Valid Loss: 0.2481\n",
      "Validation loss improved to 0.2481\n",
      "Epoch [96/200], Train Loss: 0.1561, Valid Loss: 0.2433\n",
      "Validation loss improved to 0.2433\n",
      "Epoch [97/200], Train Loss: 0.1397, Valid Loss: 0.2420\n",
      "Validation loss improved to 0.2420\n",
      "Epoch [98/200], Train Loss: 0.1492, Valid Loss: 0.2392\n",
      "Validation loss improved to 0.2392\n",
      "Epoch [99/200], Train Loss: 0.1458, Valid Loss: 0.2352\n",
      "Validation loss improved to 0.2352\n",
      "Epoch [100/200], Train Loss: 0.1317, Valid Loss: 0.2315\n",
      "Validation loss improved to 0.2315\n",
      "Epoch [101/200], Train Loss: 0.1431, Valid Loss: 0.2304\n",
      "Validation loss improved to 0.2304\n",
      "Epoch [102/200], Train Loss: 0.0915, Valid Loss: 0.2326\n",
      "Epoch [103/200], Train Loss: 0.1136, Valid Loss: 0.2239\n",
      "Validation loss improved to 0.2239\n",
      "Epoch [104/200], Train Loss: 0.1458, Valid Loss: 0.2110\n",
      "Validation loss improved to 0.2110\n",
      "Epoch [105/200], Train Loss: 0.1206, Valid Loss: 0.2103\n",
      "Validation loss improved to 0.2103\n",
      "Epoch [106/200], Train Loss: 0.1238, Valid Loss: 0.2109\n",
      "Epoch [107/200], Train Loss: 0.1618, Valid Loss: 0.2161\n",
      "Epoch [108/200], Train Loss: 0.1213, Valid Loss: 0.2049\n",
      "Validation loss improved to 0.2049\n",
      "Epoch [109/200], Train Loss: 0.1171, Valid Loss: 0.2024\n",
      "Validation loss improved to 0.2024\n",
      "Epoch [110/200], Train Loss: 0.1024, Valid Loss: 0.2133\n",
      "Epoch [111/200], Train Loss: 0.1203, Valid Loss: 0.2268\n",
      "Epoch [112/200], Train Loss: 0.1117, Valid Loss: 0.2256\n",
      "Epoch [113/200], Train Loss: 0.1187, Valid Loss: 0.2033\n",
      "Epoch [114/200], Train Loss: 0.0862, Valid Loss: 0.1916\n",
      "Validation loss improved to 0.1916\n",
      "Epoch [115/200], Train Loss: 0.0847, Valid Loss: 0.1952\n",
      "Epoch [116/200], Train Loss: 0.0969, Valid Loss: 0.2049\n",
      "Epoch [117/200], Train Loss: 0.0973, Valid Loss: 0.2018\n",
      "Epoch [118/200], Train Loss: 0.0959, Valid Loss: 0.2015\n",
      "Epoch [119/200], Train Loss: 0.0805, Valid Loss: 0.1921\n",
      "Epoch [120/200], Train Loss: 0.0734, Valid Loss: 0.1900\n",
      "Validation loss improved to 0.1900\n",
      "Epoch [121/200], Train Loss: 0.0686, Valid Loss: 0.1994\n",
      "Epoch [122/200], Train Loss: 0.0850, Valid Loss: 0.2073\n",
      "Epoch [123/200], Train Loss: 0.0658, Valid Loss: 0.2218\n",
      "Epoch [124/200], Train Loss: 0.0983, Valid Loss: 0.2199\n",
      "Epoch [125/200], Train Loss: 0.0854, Valid Loss: 0.2128\n",
      "Epoch [126/200], Train Loss: 0.0693, Valid Loss: 0.2098\n",
      "Epoch [127/200], Train Loss: 0.0723, Valid Loss: 0.2050\n",
      "Epoch [128/200], Train Loss: 0.0888, Valid Loss: 0.1922\n",
      "Epoch [129/200], Train Loss: 0.0569, Valid Loss: 0.1988\n",
      "Epoch [130/200], Train Loss: 0.0765, Valid Loss: 0.2242\n",
      "Early stopping triggered at epoch 130\n",
      "Training completed. Final model saved as model/loss_0.1900_lr_0.0001_batch_32_opt_Adam.pt\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 200, 'learning_rate': 0.0001, 'optimizer': 'SGD'}\n",
      "Epoch [1/200], Train Loss: 1.3983, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [2/200], Train Loss: 1.3955, Valid Loss: 1.3862\n",
      "Validation loss improved to 1.3862\n",
      "Epoch [3/200], Train Loss: 1.3924, Valid Loss: 1.3858\n",
      "Validation loss improved to 1.3858\n",
      "Epoch [4/200], Train Loss: 1.4033, Valid Loss: 1.3853\n",
      "Validation loss improved to 1.3853\n",
      "Epoch [5/200], Train Loss: 1.3963, Valid Loss: 1.3848\n",
      "Validation loss improved to 1.3848\n",
      "Epoch [6/200], Train Loss: 1.3893, Valid Loss: 1.3841\n",
      "Validation loss improved to 1.3841\n",
      "Epoch [7/200], Train Loss: 1.4046, Valid Loss: 1.3834\n",
      "Validation loss improved to 1.3834\n",
      "Epoch [8/200], Train Loss: 1.3894, Valid Loss: 1.3827\n",
      "Validation loss improved to 1.3827\n",
      "Epoch [9/200], Train Loss: 1.3693, Valid Loss: 1.3820\n",
      "Validation loss improved to 1.3820\n",
      "Epoch [10/200], Train Loss: 1.3905, Valid Loss: 1.3812\n",
      "Validation loss improved to 1.3812\n",
      "Epoch [11/200], Train Loss: 1.3892, Valid Loss: 1.3805\n",
      "Validation loss improved to 1.3805\n",
      "Epoch [12/200], Train Loss: 1.3990, Valid Loss: 1.3797\n",
      "Validation loss improved to 1.3797\n",
      "Epoch [13/200], Train Loss: 1.3836, Valid Loss: 1.3790\n",
      "Validation loss improved to 1.3790\n",
      "Epoch [14/200], Train Loss: 1.3979, Valid Loss: 1.3782\n",
      "Validation loss improved to 1.3782\n",
      "Epoch [15/200], Train Loss: 1.3911, Valid Loss: 1.3774\n",
      "Validation loss improved to 1.3774\n",
      "Epoch [16/200], Train Loss: 1.3733, Valid Loss: 1.3766\n",
      "Validation loss improved to 1.3766\n",
      "Epoch [17/200], Train Loss: 1.3757, Valid Loss: 1.3758\n",
      "Validation loss improved to 1.3758\n",
      "Epoch [18/200], Train Loss: 1.3886, Valid Loss: 1.3750\n",
      "Validation loss improved to 1.3750\n",
      "Epoch [19/200], Train Loss: 1.3813, Valid Loss: 1.3741\n",
      "Validation loss improved to 1.3741\n",
      "Epoch [20/200], Train Loss: 1.3804, Valid Loss: 1.3733\n",
      "Validation loss improved to 1.3733\n",
      "Epoch [21/200], Train Loss: 1.3582, Valid Loss: 1.3725\n",
      "Validation loss improved to 1.3725\n",
      "Epoch [22/200], Train Loss: 1.3655, Valid Loss: 1.3716\n",
      "Validation loss improved to 1.3716\n",
      "Epoch [23/200], Train Loss: 1.3715, Valid Loss: 1.3708\n",
      "Validation loss improved to 1.3708\n",
      "Epoch [24/200], Train Loss: 1.3648, Valid Loss: 1.3700\n",
      "Validation loss improved to 1.3700\n",
      "Epoch [25/200], Train Loss: 1.3789, Valid Loss: 1.3692\n",
      "Validation loss improved to 1.3692\n",
      "Epoch [26/200], Train Loss: 1.3622, Valid Loss: 1.3683\n",
      "Validation loss improved to 1.3683\n",
      "Epoch [27/200], Train Loss: 1.3672, Valid Loss: 1.3675\n",
      "Validation loss improved to 1.3675\n",
      "Epoch [28/200], Train Loss: 1.3717, Valid Loss: 1.3667\n",
      "Validation loss improved to 1.3667\n",
      "Epoch [29/200], Train Loss: 1.3802, Valid Loss: 1.3659\n",
      "Validation loss improved to 1.3659\n",
      "Epoch [30/200], Train Loss: 1.3608, Valid Loss: 1.3650\n",
      "Validation loss improved to 1.3650\n",
      "Epoch [31/200], Train Loss: 1.3568, Valid Loss: 1.3642\n",
      "Validation loss improved to 1.3642\n",
      "Epoch [32/200], Train Loss: 1.3651, Valid Loss: 1.3634\n",
      "Validation loss improved to 1.3634\n",
      "Epoch [33/200], Train Loss: 1.3718, Valid Loss: 1.3626\n",
      "Validation loss improved to 1.3626\n",
      "Epoch [34/200], Train Loss: 1.3732, Valid Loss: 1.3618\n",
      "Validation loss improved to 1.3618\n",
      "Epoch [35/200], Train Loss: 1.3640, Valid Loss: 1.3610\n",
      "Validation loss improved to 1.3610\n",
      "Epoch [36/200], Train Loss: 1.3652, Valid Loss: 1.3602\n",
      "Validation loss improved to 1.3602\n",
      "Epoch [37/200], Train Loss: 1.3627, Valid Loss: 1.3594\n",
      "Validation loss improved to 1.3594\n",
      "Epoch [38/200], Train Loss: 1.3589, Valid Loss: 1.3586\n",
      "Validation loss improved to 1.3586\n",
      "Epoch [39/200], Train Loss: 1.3545, Valid Loss: 1.3578\n",
      "Validation loss improved to 1.3578\n",
      "Epoch [40/200], Train Loss: 1.3543, Valid Loss: 1.3569\n",
      "Validation loss improved to 1.3569\n",
      "Epoch [41/200], Train Loss: 1.3498, Valid Loss: 1.3562\n",
      "Validation loss improved to 1.3562\n",
      "Epoch [42/200], Train Loss: 1.3710, Valid Loss: 1.3554\n",
      "Validation loss improved to 1.3554\n",
      "Epoch [43/200], Train Loss: 1.3459, Valid Loss: 1.3545\n",
      "Validation loss improved to 1.3545\n",
      "Epoch [44/200], Train Loss: 1.3390, Valid Loss: 1.3537\n",
      "Validation loss improved to 1.3537\n",
      "Epoch [45/200], Train Loss: 1.3326, Valid Loss: 1.3529\n",
      "Validation loss improved to 1.3529\n",
      "Epoch [46/200], Train Loss: 1.3568, Valid Loss: 1.3522\n",
      "Validation loss improved to 1.3522\n",
      "Epoch [47/200], Train Loss: 1.3226, Valid Loss: 1.3514\n",
      "Validation loss improved to 1.3514\n",
      "Epoch [48/200], Train Loss: 1.3472, Valid Loss: 1.3507\n",
      "Validation loss improved to 1.3507\n",
      "Epoch [49/200], Train Loss: 1.3373, Valid Loss: 1.3499\n",
      "Validation loss improved to 1.3499\n",
      "Epoch [50/200], Train Loss: 1.3320, Valid Loss: 1.3491\n",
      "Validation loss improved to 1.3491\n",
      "Epoch [51/200], Train Loss: 1.3299, Valid Loss: 1.3483\n",
      "Validation loss improved to 1.3483\n",
      "Epoch [52/200], Train Loss: 1.3522, Valid Loss: 1.3474\n",
      "Validation loss improved to 1.3474\n",
      "Epoch [53/200], Train Loss: 1.3451, Valid Loss: 1.3467\n",
      "Validation loss improved to 1.3467\n",
      "Epoch [54/200], Train Loss: 1.3188, Valid Loss: 1.3459\n",
      "Validation loss improved to 1.3459\n",
      "Epoch [55/200], Train Loss: 1.3575, Valid Loss: 1.3451\n",
      "Validation loss improved to 1.3451\n",
      "Epoch [56/200], Train Loss: 1.3345, Valid Loss: 1.3443\n",
      "Validation loss improved to 1.3443\n",
      "Epoch [57/200], Train Loss: 1.3478, Valid Loss: 1.3435\n",
      "Validation loss improved to 1.3435\n",
      "Epoch [58/200], Train Loss: 1.3283, Valid Loss: 1.3427\n",
      "Validation loss improved to 1.3427\n",
      "Epoch [59/200], Train Loss: 1.3503, Valid Loss: 1.3420\n",
      "Validation loss improved to 1.3420\n",
      "Epoch [60/200], Train Loss: 1.3255, Valid Loss: 1.3412\n",
      "Validation loss improved to 1.3412\n",
      "Epoch [61/200], Train Loss: 1.3389, Valid Loss: 1.3404\n",
      "Validation loss improved to 1.3404\n",
      "Epoch [62/200], Train Loss: 1.3369, Valid Loss: 1.3396\n",
      "Validation loss improved to 1.3396\n",
      "Epoch [63/200], Train Loss: 1.3385, Valid Loss: 1.3388\n",
      "Validation loss improved to 1.3388\n",
      "Epoch [64/200], Train Loss: 1.3316, Valid Loss: 1.3381\n",
      "Validation loss improved to 1.3381\n",
      "Epoch [65/200], Train Loss: 1.3228, Valid Loss: 1.3374\n",
      "Validation loss improved to 1.3374\n",
      "Epoch [66/200], Train Loss: 1.3296, Valid Loss: 1.3366\n",
      "Validation loss improved to 1.3366\n",
      "Epoch [67/200], Train Loss: 1.3425, Valid Loss: 1.3359\n",
      "Validation loss improved to 1.3359\n",
      "Epoch [68/200], Train Loss: 1.3317, Valid Loss: 1.3353\n",
      "Validation loss improved to 1.3353\n",
      "Epoch [69/200], Train Loss: 1.3202, Valid Loss: 1.3346\n",
      "Validation loss improved to 1.3346\n",
      "Epoch [70/200], Train Loss: 1.3286, Valid Loss: 1.3339\n",
      "Validation loss improved to 1.3339\n",
      "Epoch [71/200], Train Loss: 1.3277, Valid Loss: 1.3333\n",
      "Validation loss improved to 1.3333\n",
      "Epoch [72/200], Train Loss: 1.3216, Valid Loss: 1.3326\n",
      "Validation loss improved to 1.3326\n",
      "Epoch [73/200], Train Loss: 1.3179, Valid Loss: 1.3319\n",
      "Validation loss improved to 1.3319\n",
      "Epoch [74/200], Train Loss: 1.3224, Valid Loss: 1.3312\n",
      "Validation loss improved to 1.3312\n",
      "Epoch [75/200], Train Loss: 1.3089, Valid Loss: 1.3305\n",
      "Validation loss improved to 1.3305\n",
      "Epoch [76/200], Train Loss: 1.3015, Valid Loss: 1.3297\n",
      "Validation loss improved to 1.3297\n",
      "Epoch [77/200], Train Loss: 1.3332, Valid Loss: 1.3290\n",
      "Validation loss improved to 1.3290\n",
      "Epoch [78/200], Train Loss: 1.3104, Valid Loss: 1.3283\n",
      "Validation loss improved to 1.3283\n",
      "Epoch [79/200], Train Loss: 1.3214, Valid Loss: 1.3275\n",
      "Validation loss improved to 1.3275\n",
      "Epoch [80/200], Train Loss: 1.3174, Valid Loss: 1.3268\n",
      "Validation loss improved to 1.3268\n",
      "Epoch [81/200], Train Loss: 1.3409, Valid Loss: 1.3260\n",
      "Validation loss improved to 1.3260\n",
      "Epoch [82/200], Train Loss: 1.3248, Valid Loss: 1.3253\n",
      "Validation loss improved to 1.3253\n",
      "Epoch [83/200], Train Loss: 1.3336, Valid Loss: 1.3246\n",
      "Validation loss improved to 1.3246\n",
      "Epoch [84/200], Train Loss: 1.3159, Valid Loss: 1.3240\n",
      "Validation loss improved to 1.3240\n",
      "Epoch [85/200], Train Loss: 1.3141, Valid Loss: 1.3233\n",
      "Validation loss improved to 1.3233\n",
      "Epoch [86/200], Train Loss: 1.3002, Valid Loss: 1.3226\n",
      "Validation loss improved to 1.3226\n",
      "Epoch [87/200], Train Loss: 1.3188, Valid Loss: 1.3219\n",
      "Validation loss improved to 1.3219\n",
      "Epoch [88/200], Train Loss: 1.3018, Valid Loss: 1.3212\n",
      "Validation loss improved to 1.3212\n",
      "Epoch [89/200], Train Loss: 1.3192, Valid Loss: 1.3205\n",
      "Validation loss improved to 1.3205\n",
      "Epoch [90/200], Train Loss: 1.3224, Valid Loss: 1.3199\n",
      "Validation loss improved to 1.3199\n",
      "Epoch [91/200], Train Loss: 1.2999, Valid Loss: 1.3192\n",
      "Validation loss improved to 1.3192\n",
      "Epoch [92/200], Train Loss: 1.3079, Valid Loss: 1.3185\n",
      "Validation loss improved to 1.3185\n",
      "Epoch [93/200], Train Loss: 1.2935, Valid Loss: 1.3179\n",
      "Validation loss improved to 1.3179\n",
      "Epoch [94/200], Train Loss: 1.3214, Valid Loss: 1.3172\n",
      "Validation loss improved to 1.3172\n",
      "Epoch [95/200], Train Loss: 1.3240, Valid Loss: 1.3165\n",
      "Validation loss improved to 1.3165\n",
      "Epoch [96/200], Train Loss: 1.3021, Valid Loss: 1.3158\n",
      "Validation loss improved to 1.3158\n",
      "Epoch [97/200], Train Loss: 1.3125, Valid Loss: 1.3152\n",
      "Validation loss improved to 1.3152\n",
      "Epoch [98/200], Train Loss: 1.3183, Valid Loss: 1.3146\n",
      "Validation loss improved to 1.3146\n",
      "Epoch [99/200], Train Loss: 1.2933, Valid Loss: 1.3139\n",
      "Validation loss improved to 1.3139\n",
      "Epoch [100/200], Train Loss: 1.3095, Valid Loss: 1.3133\n",
      "Validation loss improved to 1.3133\n",
      "Epoch [101/200], Train Loss: 1.3050, Valid Loss: 1.3126\n",
      "Validation loss improved to 1.3126\n",
      "Epoch [102/200], Train Loss: 1.3097, Valid Loss: 1.3120\n",
      "Validation loss improved to 1.3120\n",
      "Epoch [103/200], Train Loss: 1.3062, Valid Loss: 1.3114\n",
      "Validation loss improved to 1.3114\n",
      "Epoch [104/200], Train Loss: 1.3166, Valid Loss: 1.3107\n",
      "Validation loss improved to 1.3107\n",
      "Epoch [105/200], Train Loss: 1.3094, Valid Loss: 1.3101\n",
      "Validation loss improved to 1.3101\n",
      "Epoch [106/200], Train Loss: 1.2889, Valid Loss: 1.3096\n",
      "Validation loss improved to 1.3096\n",
      "Epoch [107/200], Train Loss: 1.2961, Valid Loss: 1.3090\n",
      "Validation loss improved to 1.3090\n",
      "Epoch [108/200], Train Loss: 1.2959, Valid Loss: 1.3084\n",
      "Validation loss improved to 1.3084\n",
      "Epoch [109/200], Train Loss: 1.3042, Valid Loss: 1.3078\n",
      "Validation loss improved to 1.3078\n",
      "Epoch [110/200], Train Loss: 1.3218, Valid Loss: 1.3072\n",
      "Validation loss improved to 1.3072\n",
      "Epoch [111/200], Train Loss: 1.3131, Valid Loss: 1.3066\n",
      "Validation loss improved to 1.3066\n",
      "Epoch [112/200], Train Loss: 1.2823, Valid Loss: 1.3060\n",
      "Validation loss improved to 1.3060\n",
      "Epoch [113/200], Train Loss: 1.2922, Valid Loss: 1.3053\n",
      "Validation loss improved to 1.3053\n",
      "Epoch [114/200], Train Loss: 1.3030, Valid Loss: 1.3047\n",
      "Validation loss improved to 1.3047\n",
      "Epoch [115/200], Train Loss: 1.3011, Valid Loss: 1.3040\n",
      "Validation loss improved to 1.3040\n",
      "Epoch [116/200], Train Loss: 1.2932, Valid Loss: 1.3034\n",
      "Validation loss improved to 1.3034\n",
      "Epoch [117/200], Train Loss: 1.2847, Valid Loss: 1.3028\n",
      "Validation loss improved to 1.3028\n",
      "Epoch [118/200], Train Loss: 1.2905, Valid Loss: 1.3021\n",
      "Validation loss improved to 1.3021\n",
      "Epoch [119/200], Train Loss: 1.2749, Valid Loss: 1.3015\n",
      "Validation loss improved to 1.3015\n",
      "Epoch [120/200], Train Loss: 1.3084, Valid Loss: 1.3008\n",
      "Validation loss improved to 1.3008\n",
      "Epoch [121/200], Train Loss: 1.2766, Valid Loss: 1.3002\n",
      "Validation loss improved to 1.3002\n",
      "Epoch [122/200], Train Loss: 1.3067, Valid Loss: 1.2996\n",
      "Validation loss improved to 1.2996\n",
      "Epoch [123/200], Train Loss: 1.2867, Valid Loss: 1.2990\n",
      "Validation loss improved to 1.2990\n",
      "Epoch [124/200], Train Loss: 1.2830, Valid Loss: 1.2983\n",
      "Validation loss improved to 1.2983\n",
      "Epoch [125/200], Train Loss: 1.2840, Valid Loss: 1.2977\n",
      "Validation loss improved to 1.2977\n",
      "Epoch [126/200], Train Loss: 1.2956, Valid Loss: 1.2971\n",
      "Validation loss improved to 1.2971\n",
      "Epoch [127/200], Train Loss: 1.2820, Valid Loss: 1.2965\n",
      "Validation loss improved to 1.2965\n",
      "Epoch [128/200], Train Loss: 1.2765, Valid Loss: 1.2959\n",
      "Validation loss improved to 1.2959\n",
      "Epoch [129/200], Train Loss: 1.2744, Valid Loss: 1.2952\n",
      "Validation loss improved to 1.2952\n",
      "Epoch [130/200], Train Loss: 1.2775, Valid Loss: 1.2946\n",
      "Validation loss improved to 1.2946\n",
      "Epoch [131/200], Train Loss: 1.2714, Valid Loss: 1.2940\n",
      "Validation loss improved to 1.2940\n",
      "Epoch [132/200], Train Loss: 1.2686, Valid Loss: 1.2934\n",
      "Validation loss improved to 1.2934\n",
      "Epoch [133/200], Train Loss: 1.2971, Valid Loss: 1.2928\n",
      "Validation loss improved to 1.2928\n",
      "Epoch [134/200], Train Loss: 1.2671, Valid Loss: 1.2922\n",
      "Validation loss improved to 1.2922\n",
      "Epoch [135/200], Train Loss: 1.2839, Valid Loss: 1.2916\n",
      "Validation loss improved to 1.2916\n",
      "Epoch [136/200], Train Loss: 1.2888, Valid Loss: 1.2910\n",
      "Validation loss improved to 1.2910\n",
      "Epoch [137/200], Train Loss: 1.2751, Valid Loss: 1.2904\n",
      "Validation loss improved to 1.2904\n",
      "Epoch [138/200], Train Loss: 1.2603, Valid Loss: 1.2898\n",
      "Validation loss improved to 1.2898\n",
      "Epoch [139/200], Train Loss: 1.2698, Valid Loss: 1.2892\n",
      "Validation loss improved to 1.2892\n",
      "Epoch [140/200], Train Loss: 1.2708, Valid Loss: 1.2886\n",
      "Validation loss improved to 1.2886\n",
      "Epoch [141/200], Train Loss: 1.2707, Valid Loss: 1.2880\n",
      "Validation loss improved to 1.2880\n",
      "Epoch [142/200], Train Loss: 1.2791, Valid Loss: 1.2875\n",
      "Validation loss improved to 1.2875\n",
      "Epoch [143/200], Train Loss: 1.2769, Valid Loss: 1.2869\n",
      "Validation loss improved to 1.2869\n",
      "Epoch [144/200], Train Loss: 1.2729, Valid Loss: 1.2863\n",
      "Validation loss improved to 1.2863\n",
      "Epoch [145/200], Train Loss: 1.2725, Valid Loss: 1.2857\n",
      "Validation loss improved to 1.2857\n",
      "Epoch [146/200], Train Loss: 1.2745, Valid Loss: 1.2852\n",
      "Validation loss improved to 1.2852\n",
      "Epoch [147/200], Train Loss: 1.2879, Valid Loss: 1.2846\n",
      "Validation loss improved to 1.2846\n",
      "Epoch [148/200], Train Loss: 1.2732, Valid Loss: 1.2841\n",
      "Validation loss improved to 1.2841\n",
      "Epoch [149/200], Train Loss: 1.2759, Valid Loss: 1.2836\n",
      "Validation loss improved to 1.2836\n",
      "Epoch [150/200], Train Loss: 1.2728, Valid Loss: 1.2831\n",
      "Validation loss improved to 1.2831\n",
      "Epoch [151/200], Train Loss: 1.2581, Valid Loss: 1.2826\n",
      "Validation loss improved to 1.2826\n",
      "Epoch [152/200], Train Loss: 1.2539, Valid Loss: 1.2820\n",
      "Validation loss improved to 1.2820\n",
      "Epoch [153/200], Train Loss: 1.2479, Valid Loss: 1.2814\n",
      "Validation loss improved to 1.2814\n",
      "Epoch [154/200], Train Loss: 1.2649, Valid Loss: 1.2808\n",
      "Validation loss improved to 1.2808\n",
      "Epoch [155/200], Train Loss: 1.2516, Valid Loss: 1.2802\n",
      "Validation loss improved to 1.2802\n",
      "Epoch [156/200], Train Loss: 1.2597, Valid Loss: 1.2796\n",
      "Validation loss improved to 1.2796\n",
      "Epoch [157/200], Train Loss: 1.2641, Valid Loss: 1.2791\n",
      "Validation loss improved to 1.2791\n",
      "Epoch [158/200], Train Loss: 1.2475, Valid Loss: 1.2785\n",
      "Validation loss improved to 1.2785\n",
      "Epoch [159/200], Train Loss: 1.2388, Valid Loss: 1.2779\n",
      "Validation loss improved to 1.2779\n",
      "Epoch [160/200], Train Loss: 1.2576, Valid Loss: 1.2774\n",
      "Validation loss improved to 1.2774\n",
      "Epoch [161/200], Train Loss: 1.2752, Valid Loss: 1.2768\n",
      "Validation loss improved to 1.2768\n",
      "Epoch [162/200], Train Loss: 1.2605, Valid Loss: 1.2762\n",
      "Validation loss improved to 1.2762\n",
      "Epoch [163/200], Train Loss: 1.2642, Valid Loss: 1.2756\n",
      "Validation loss improved to 1.2756\n",
      "Epoch [164/200], Train Loss: 1.2518, Valid Loss: 1.2751\n",
      "Validation loss improved to 1.2751\n",
      "Epoch [165/200], Train Loss: 1.2605, Valid Loss: 1.2745\n",
      "Validation loss improved to 1.2745\n",
      "Epoch [166/200], Train Loss: 1.2538, Valid Loss: 1.2739\n",
      "Validation loss improved to 1.2739\n",
      "Epoch [167/200], Train Loss: 1.2626, Valid Loss: 1.2734\n",
      "Validation loss improved to 1.2734\n",
      "Epoch [168/200], Train Loss: 1.2671, Valid Loss: 1.2728\n",
      "Validation loss improved to 1.2728\n",
      "Epoch [169/200], Train Loss: 1.2596, Valid Loss: 1.2722\n",
      "Validation loss improved to 1.2722\n",
      "Epoch [170/200], Train Loss: 1.2572, Valid Loss: 1.2716\n",
      "Validation loss improved to 1.2716\n",
      "Epoch [171/200], Train Loss: 1.2619, Valid Loss: 1.2710\n",
      "Validation loss improved to 1.2710\n",
      "Epoch [172/200], Train Loss: 1.2779, Valid Loss: 1.2704\n",
      "Validation loss improved to 1.2704\n",
      "Epoch [173/200], Train Loss: 1.2601, Valid Loss: 1.2698\n",
      "Validation loss improved to 1.2698\n",
      "Epoch [174/200], Train Loss: 1.2566, Valid Loss: 1.2693\n",
      "Validation loss improved to 1.2693\n",
      "Epoch [175/200], Train Loss: 1.2641, Valid Loss: 1.2687\n",
      "Validation loss improved to 1.2687\n",
      "Epoch [176/200], Train Loss: 1.2871, Valid Loss: 1.2682\n",
      "Validation loss improved to 1.2682\n",
      "Epoch [177/200], Train Loss: 1.2385, Valid Loss: 1.2676\n",
      "Validation loss improved to 1.2676\n",
      "Epoch [178/200], Train Loss: 1.2580, Valid Loss: 1.2671\n",
      "Validation loss improved to 1.2671\n",
      "Epoch [179/200], Train Loss: 1.2590, Valid Loss: 1.2665\n",
      "Validation loss improved to 1.2665\n",
      "Epoch [180/200], Train Loss: 1.2754, Valid Loss: 1.2660\n",
      "Validation loss improved to 1.2660\n",
      "Epoch [181/200], Train Loss: 1.2376, Valid Loss: 1.2654\n",
      "Validation loss improved to 1.2654\n",
      "Epoch [182/200], Train Loss: 1.2496, Valid Loss: 1.2649\n",
      "Validation loss improved to 1.2649\n",
      "Epoch [183/200], Train Loss: 1.2366, Valid Loss: 1.2644\n",
      "Validation loss improved to 1.2644\n",
      "Epoch [184/200], Train Loss: 1.2427, Valid Loss: 1.2638\n",
      "Validation loss improved to 1.2638\n",
      "Epoch [185/200], Train Loss: 1.2434, Valid Loss: 1.2632\n",
      "Validation loss improved to 1.2632\n",
      "Epoch [186/200], Train Loss: 1.2537, Valid Loss: 1.2627\n",
      "Validation loss improved to 1.2627\n",
      "Epoch [187/200], Train Loss: 1.2535, Valid Loss: 1.2621\n",
      "Validation loss improved to 1.2621\n",
      "Epoch [188/200], Train Loss: 1.2543, Valid Loss: 1.2616\n",
      "Validation loss improved to 1.2616\n",
      "Epoch [189/200], Train Loss: 1.2407, Valid Loss: 1.2611\n",
      "Validation loss improved to 1.2611\n",
      "Epoch [190/200], Train Loss: 1.2332, Valid Loss: 1.2605\n",
      "Validation loss improved to 1.2605\n",
      "Epoch [191/200], Train Loss: 1.2369, Valid Loss: 1.2600\n",
      "Validation loss improved to 1.2600\n",
      "Epoch [192/200], Train Loss: 1.2322, Valid Loss: 1.2594\n",
      "Validation loss improved to 1.2594\n",
      "Epoch [193/200], Train Loss: 1.2516, Valid Loss: 1.2588\n",
      "Validation loss improved to 1.2588\n",
      "Epoch [194/200], Train Loss: 1.2478, Valid Loss: 1.2582\n",
      "Validation loss improved to 1.2582\n",
      "Epoch [195/200], Train Loss: 1.2500, Valid Loss: 1.2576\n",
      "Validation loss improved to 1.2576\n",
      "Epoch [196/200], Train Loss: 1.2486, Valid Loss: 1.2571\n",
      "Validation loss improved to 1.2571\n",
      "Epoch [197/200], Train Loss: 1.2417, Valid Loss: 1.2565\n",
      "Validation loss improved to 1.2565\n",
      "Epoch [198/200], Train Loss: 1.2127, Valid Loss: 1.2560\n",
      "Validation loss improved to 1.2560\n",
      "Epoch [199/200], Train Loss: 1.2200, Valid Loss: 1.2554\n",
      "Validation loss improved to 1.2554\n",
      "Epoch [200/200], Train Loss: 1.2431, Valid Loss: 1.2548\n",
      "Validation loss improved to 1.2548\n",
      "Training completed. Final model saved as model/loss_1.2548_lr_0.0001_batch_32_opt_SGD.pt\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 200, 'learning_rate': 0.0001, 'optimizer': 'RMSprop'}\n",
      "Epoch [1/200], Train Loss: 1.3835, Valid Loss: 1.3195\n",
      "Validation loss improved to 1.3195\n",
      "Epoch [2/200], Train Loss: 1.3086, Valid Loss: 1.2682\n",
      "Validation loss improved to 1.2682\n",
      "Epoch [3/200], Train Loss: 1.2697, Valid Loss: 1.2241\n",
      "Validation loss improved to 1.2241\n",
      "Epoch [4/200], Train Loss: 1.1978, Valid Loss: 1.1742\n",
      "Validation loss improved to 1.1742\n",
      "Epoch [5/200], Train Loss: 1.1572, Valid Loss: 1.1434\n",
      "Validation loss improved to 1.1434\n",
      "Epoch [6/200], Train Loss: 1.1356, Valid Loss: 1.1050\n",
      "Validation loss improved to 1.1050\n",
      "Epoch [7/200], Train Loss: 1.0732, Valid Loss: 1.0480\n",
      "Validation loss improved to 1.0480\n",
      "Epoch [8/200], Train Loss: 1.0901, Valid Loss: 1.0119\n",
      "Validation loss improved to 1.0119\n",
      "Epoch [9/200], Train Loss: 0.9995, Valid Loss: 0.9630\n",
      "Validation loss improved to 0.9630\n",
      "Epoch [10/200], Train Loss: 0.9903, Valid Loss: 0.9048\n",
      "Validation loss improved to 0.9048\n",
      "Epoch [11/200], Train Loss: 0.9174, Valid Loss: 0.8808\n",
      "Validation loss improved to 0.8808\n",
      "Epoch [12/200], Train Loss: 0.8453, Valid Loss: 0.8754\n",
      "Validation loss improved to 0.8754\n",
      "Epoch [13/200], Train Loss: 0.8568, Valid Loss: 0.7999\n",
      "Validation loss improved to 0.7999\n",
      "Epoch [14/200], Train Loss: 0.8353, Valid Loss: 0.7826\n",
      "Validation loss improved to 0.7826\n",
      "Epoch [15/200], Train Loss: 0.7682, Valid Loss: 0.7694\n",
      "Validation loss improved to 0.7694\n",
      "Epoch [16/200], Train Loss: 0.7830, Valid Loss: 0.7259\n",
      "Validation loss improved to 0.7259\n",
      "Epoch [17/200], Train Loss: 0.7280, Valid Loss: 0.6875\n",
      "Validation loss improved to 0.6875\n",
      "Epoch [18/200], Train Loss: 0.7683, Valid Loss: 0.6708\n",
      "Validation loss improved to 0.6708\n",
      "Epoch [19/200], Train Loss: 0.6472, Valid Loss: 0.6209\n",
      "Validation loss improved to 0.6209\n",
      "Epoch [20/200], Train Loss: 0.6817, Valid Loss: 0.6126\n",
      "Validation loss improved to 0.6126\n",
      "Epoch [21/200], Train Loss: 0.6276, Valid Loss: 0.5797\n",
      "Validation loss improved to 0.5797\n",
      "Epoch [22/200], Train Loss: 0.6256, Valid Loss: 0.6059\n",
      "Epoch [23/200], Train Loss: 0.6779, Valid Loss: 0.5503\n",
      "Validation loss improved to 0.5503\n",
      "Epoch [24/200], Train Loss: 0.5472, Valid Loss: 0.5512\n",
      "Epoch [25/200], Train Loss: 0.5586, Valid Loss: 0.5279\n",
      "Validation loss improved to 0.5279\n",
      "Epoch [26/200], Train Loss: 0.5577, Valid Loss: 0.4835\n",
      "Validation loss improved to 0.4835\n",
      "Epoch [27/200], Train Loss: 0.5485, Valid Loss: 0.4881\n",
      "Epoch [28/200], Train Loss: 0.5111, Valid Loss: 0.4749\n",
      "Validation loss improved to 0.4749\n",
      "Epoch [29/200], Train Loss: 0.5011, Valid Loss: 0.4547\n",
      "Validation loss improved to 0.4547\n",
      "Epoch [30/200], Train Loss: 0.5072, Valid Loss: 0.4305\n",
      "Validation loss improved to 0.4305\n",
      "Epoch [31/200], Train Loss: 0.4070, Valid Loss: 0.4180\n",
      "Validation loss improved to 0.4180\n",
      "Epoch [32/200], Train Loss: 0.3589, Valid Loss: 0.3914\n",
      "Validation loss improved to 0.3914\n",
      "Epoch [33/200], Train Loss: 0.4150, Valid Loss: 0.4001\n",
      "Epoch [34/200], Train Loss: 0.3858, Valid Loss: 0.4343\n",
      "Epoch [35/200], Train Loss: 0.4379, Valid Loss: 0.3692\n",
      "Validation loss improved to 0.3692\n",
      "Epoch [36/200], Train Loss: 0.3285, Valid Loss: 0.3582\n",
      "Validation loss improved to 0.3582\n",
      "Epoch [37/200], Train Loss: 0.3468, Valid Loss: 0.3448\n",
      "Validation loss improved to 0.3448\n",
      "Epoch [38/200], Train Loss: 0.3422, Valid Loss: 0.3716\n",
      "Epoch [39/200], Train Loss: 0.3445, Valid Loss: 0.3675\n",
      "Epoch [40/200], Train Loss: 0.3962, Valid Loss: 0.3311\n",
      "Validation loss improved to 0.3311\n",
      "Epoch [41/200], Train Loss: 0.3183, Valid Loss: 0.3296\n",
      "Validation loss improved to 0.3296\n",
      "Epoch [42/200], Train Loss: 0.2942, Valid Loss: 0.3086\n",
      "Validation loss improved to 0.3086\n",
      "Epoch [43/200], Train Loss: 0.2720, Valid Loss: 0.2980\n",
      "Validation loss improved to 0.2980\n",
      "Epoch [44/200], Train Loss: 0.2673, Valid Loss: 0.2883\n",
      "Validation loss improved to 0.2883\n",
      "Epoch [45/200], Train Loss: 0.2643, Valid Loss: 0.2815\n",
      "Validation loss improved to 0.2815\n",
      "Epoch [46/200], Train Loss: 0.2302, Valid Loss: 0.2730\n",
      "Validation loss improved to 0.2730\n",
      "Epoch [47/200], Train Loss: 0.2958, Valid Loss: 0.2951\n",
      "Epoch [48/200], Train Loss: 0.2981, Valid Loss: 0.2685\n",
      "Validation loss improved to 0.2685\n",
      "Epoch [49/200], Train Loss: 0.2225, Valid Loss: 0.2606\n",
      "Validation loss improved to 0.2606\n",
      "Epoch [50/200], Train Loss: 0.2104, Valid Loss: 0.2605\n",
      "Validation loss improved to 0.2605\n",
      "Epoch [51/200], Train Loss: 0.2398, Valid Loss: 0.2836\n",
      "Epoch [52/200], Train Loss: 0.2647, Valid Loss: 0.2507\n",
      "Validation loss improved to 0.2507\n",
      "Epoch [53/200], Train Loss: 0.2281, Valid Loss: 0.2353\n",
      "Validation loss improved to 0.2353\n",
      "Epoch [54/200], Train Loss: 0.1928, Valid Loss: 0.2200\n",
      "Validation loss improved to 0.2200\n",
      "Epoch [55/200], Train Loss: 0.2207, Valid Loss: 0.2404\n",
      "Epoch [56/200], Train Loss: 0.1855, Valid Loss: 0.2161\n",
      "Validation loss improved to 0.2161\n",
      "Epoch [57/200], Train Loss: 0.2355, Valid Loss: 0.2341\n",
      "Epoch [58/200], Train Loss: 0.2354, Valid Loss: 0.2094\n",
      "Validation loss improved to 0.2094\n",
      "Epoch [59/200], Train Loss: 0.1927, Valid Loss: 0.2136\n",
      "Epoch [60/200], Train Loss: 0.1770, Valid Loss: 0.1983\n",
      "Validation loss improved to 0.1983\n",
      "Epoch [61/200], Train Loss: 0.2062, Valid Loss: 0.1959\n",
      "Validation loss improved to 0.1959\n",
      "Epoch [62/200], Train Loss: 0.1416, Valid Loss: 0.2052\n",
      "Epoch [63/200], Train Loss: 0.1476, Valid Loss: 0.1912\n",
      "Validation loss improved to 0.1912\n",
      "Epoch [64/200], Train Loss: 0.1858, Valid Loss: 0.1975\n",
      "Epoch [65/200], Train Loss: 0.1409, Valid Loss: 0.1735\n",
      "Validation loss improved to 0.1735\n",
      "Epoch [66/200], Train Loss: 0.1530, Valid Loss: 0.1825\n",
      "Epoch [67/200], Train Loss: 0.1462, Valid Loss: 0.1821\n",
      "Epoch [68/200], Train Loss: 0.1360, Valid Loss: 0.1955\n",
      "Epoch [69/200], Train Loss: 0.1361, Valid Loss: 0.1892\n",
      "Epoch [70/200], Train Loss: 0.1094, Valid Loss: 0.1893\n",
      "Epoch [71/200], Train Loss: 0.1095, Valid Loss: 0.1799\n",
      "Epoch [72/200], Train Loss: 0.1388, Valid Loss: 0.1767\n",
      "Epoch [73/200], Train Loss: 0.1011, Valid Loss: 0.1665\n",
      "Validation loss improved to 0.1665\n",
      "Epoch [74/200], Train Loss: 0.1097, Valid Loss: 0.1732\n",
      "Epoch [75/200], Train Loss: 0.1134, Valid Loss: 0.1705\n",
      "Epoch [76/200], Train Loss: 0.1145, Valid Loss: 0.1682\n",
      "Epoch [77/200], Train Loss: 0.1428, Valid Loss: 0.1884\n",
      "Epoch [78/200], Train Loss: 0.0962, Valid Loss: 0.1518\n",
      "Validation loss improved to 0.1518\n",
      "Epoch [79/200], Train Loss: 0.0969, Valid Loss: 0.1892\n",
      "Epoch [80/200], Train Loss: 0.0897, Valid Loss: 0.1634\n",
      "Epoch [81/200], Train Loss: 0.0916, Valid Loss: 0.1822\n",
      "Epoch [82/200], Train Loss: 0.0840, Valid Loss: 0.1491\n",
      "Validation loss improved to 0.1491\n",
      "Epoch [83/200], Train Loss: 0.1008, Valid Loss: 0.1742\n",
      "Epoch [84/200], Train Loss: 0.0838, Valid Loss: 0.1605\n",
      "Epoch [85/200], Train Loss: 0.0757, Valid Loss: 0.1533\n",
      "Epoch [86/200], Train Loss: 0.1014, Valid Loss: 0.1342\n",
      "Validation loss improved to 0.1342\n",
      "Epoch [87/200], Train Loss: 0.1064, Valid Loss: 0.1598\n",
      "Epoch [88/200], Train Loss: 0.1203, Valid Loss: 0.1788\n",
      "Epoch [89/200], Train Loss: 0.0923, Valid Loss: 0.1974\n",
      "Epoch [90/200], Train Loss: 0.0853, Valid Loss: 0.1530\n",
      "Epoch [91/200], Train Loss: 0.0688, Valid Loss: 0.1565\n",
      "Epoch [92/200], Train Loss: 0.0847, Valid Loss: 0.1464\n",
      "Epoch [93/200], Train Loss: 0.0804, Valid Loss: 0.1343\n",
      "Epoch [94/200], Train Loss: 0.0683, Valid Loss: 0.1443\n",
      "Epoch [95/200], Train Loss: 0.0821, Valid Loss: 0.1424\n",
      "Epoch [96/200], Train Loss: 0.0640, Valid Loss: 0.1333\n",
      "Validation loss improved to 0.1333\n",
      "Epoch [97/200], Train Loss: 0.0761, Valid Loss: 0.1760\n",
      "Epoch [98/200], Train Loss: 0.0851, Valid Loss: 0.1379\n",
      "Epoch [99/200], Train Loss: 0.0736, Valid Loss: 0.1431\n",
      "Epoch [100/200], Train Loss: 0.1555, Valid Loss: 0.1485\n",
      "Epoch [101/200], Train Loss: 0.1024, Valid Loss: 0.1648\n",
      "Epoch [102/200], Train Loss: 0.0849, Valid Loss: 0.1445\n",
      "Epoch [103/200], Train Loss: 0.0406, Valid Loss: 0.1414\n",
      "Epoch [104/200], Train Loss: 0.0549, Valid Loss: 0.1411\n",
      "Epoch [105/200], Train Loss: 0.0600, Valid Loss: 0.1358\n",
      "Epoch [106/200], Train Loss: 0.0492, Valid Loss: 0.1571\n",
      "Early stopping triggered at epoch 106\n",
      "Training completed. Final model saved as model/loss_0.1333_lr_0.0001_batch_32_opt_RMSprop.pt\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 200, 'learning_rate': 0.001, 'optimizer': 'Adam'}\n",
      "Epoch [1/200], Train Loss: 1.3640, Valid Loss: 1.3453\n",
      "Validation loss improved to 1.3453\n",
      "Epoch [2/200], Train Loss: 1.3170, Valid Loss: 1.3074\n",
      "Validation loss improved to 1.3074\n",
      "Epoch [3/200], Train Loss: 1.2831, Valid Loss: 1.2698\n",
      "Validation loss improved to 1.2698\n",
      "Epoch [4/200], Train Loss: 1.2097, Valid Loss: 1.2313\n",
      "Validation loss improved to 1.2313\n",
      "Epoch [5/200], Train Loss: 1.1316, Valid Loss: 1.1848\n",
      "Validation loss improved to 1.1848\n",
      "Epoch [6/200], Train Loss: 1.1453, Valid Loss: 1.0978\n",
      "Validation loss improved to 1.0978\n",
      "Epoch [7/200], Train Loss: 1.0828, Valid Loss: 0.9928\n",
      "Validation loss improved to 0.9928\n",
      "Epoch [8/200], Train Loss: 0.9088, Valid Loss: 0.9123\n",
      "Validation loss improved to 0.9123\n",
      "Epoch [9/200], Train Loss: 0.8658, Valid Loss: 0.8107\n",
      "Validation loss improved to 0.8107\n",
      "Epoch [10/200], Train Loss: 0.8185, Valid Loss: 0.7628\n",
      "Validation loss improved to 0.7628\n",
      "Epoch [11/200], Train Loss: 0.7400, Valid Loss: 0.6708\n",
      "Validation loss improved to 0.6708\n",
      "Epoch [12/200], Train Loss: 0.7222, Valid Loss: 0.5536\n",
      "Validation loss improved to 0.5536\n",
      "Epoch [13/200], Train Loss: 0.5357, Valid Loss: 0.4808\n",
      "Validation loss improved to 0.4808\n",
      "Epoch [14/200], Train Loss: 0.4612, Valid Loss: 0.4271\n",
      "Validation loss improved to 0.4271\n",
      "Epoch [15/200], Train Loss: 0.4571, Valid Loss: 0.3986\n",
      "Validation loss improved to 0.3986\n",
      "Epoch [16/200], Train Loss: 0.3990, Valid Loss: 0.3248\n",
      "Validation loss improved to 0.3248\n",
      "Epoch [17/200], Train Loss: 0.3472, Valid Loss: 0.2870\n",
      "Validation loss improved to 0.2870\n",
      "Epoch [18/200], Train Loss: 0.3552, Valid Loss: 0.2685\n",
      "Validation loss improved to 0.2685\n",
      "Epoch [19/200], Train Loss: 0.3490, Valid Loss: 0.2758\n",
      "Epoch [20/200], Train Loss: 0.2533, Valid Loss: 0.2159\n",
      "Validation loss improved to 0.2159\n",
      "Epoch [21/200], Train Loss: 0.1974, Valid Loss: 0.2052\n",
      "Validation loss improved to 0.2052\n",
      "Epoch [22/200], Train Loss: 0.2763, Valid Loss: 0.1864\n",
      "Validation loss improved to 0.1864\n",
      "Epoch [23/200], Train Loss: 0.1504, Valid Loss: 0.3450\n",
      "Epoch [24/200], Train Loss: 0.1963, Valid Loss: 0.2976\n",
      "Epoch [25/200], Train Loss: 0.1439, Valid Loss: 0.1442\n",
      "Validation loss improved to 0.1442\n",
      "Epoch [26/200], Train Loss: 0.1151, Valid Loss: 0.1315\n",
      "Validation loss improved to 0.1315\n",
      "Epoch [27/200], Train Loss: 0.1562, Valid Loss: 0.1070\n",
      "Validation loss improved to 0.1070\n",
      "Epoch [28/200], Train Loss: 0.0772, Valid Loss: 0.1449\n",
      "Epoch [29/200], Train Loss: 0.0808, Valid Loss: 0.1523\n",
      "Epoch [30/200], Train Loss: 0.0649, Valid Loss: 0.1219\n",
      "Epoch [31/200], Train Loss: 0.0566, Valid Loss: 0.1160\n",
      "Epoch [32/200], Train Loss: 0.0380, Valid Loss: 0.1522\n",
      "Epoch [33/200], Train Loss: 0.0480, Valid Loss: 0.2081\n",
      "Epoch [34/200], Train Loss: 0.0428, Valid Loss: 0.2150\n",
      "Epoch [35/200], Train Loss: 0.0258, Valid Loss: 0.1835\n",
      "Epoch [36/200], Train Loss: 0.0271, Valid Loss: 0.1831\n",
      "Epoch [37/200], Train Loss: 0.0460, Valid Loss: 0.1872\n",
      "Early stopping triggered at epoch 37\n",
      "Training completed. Final model saved as model/loss_0.1070_lr_0.001_batch_32_opt_Adam.pt\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 200, 'learning_rate': 0.001, 'optimizer': 'SGD'}\n",
      "Epoch [1/200], Train Loss: 1.3801, Valid Loss: 1.3941\n",
      "Validation loss improved to 1.3941\n",
      "Epoch [2/200], Train Loss: 1.3900, Valid Loss: 1.3913\n",
      "Validation loss improved to 1.3913\n",
      "Epoch [3/200], Train Loss: 1.3899, Valid Loss: 1.3875\n",
      "Validation loss improved to 1.3875\n",
      "Epoch [4/200], Train Loss: 1.3867, Valid Loss: 1.3828\n",
      "Validation loss improved to 1.3828\n",
      "Epoch [5/200], Train Loss: 1.3796, Valid Loss: 1.3773\n",
      "Validation loss improved to 1.3773\n",
      "Epoch [6/200], Train Loss: 1.3696, Valid Loss: 1.3713\n",
      "Validation loss improved to 1.3713\n",
      "Epoch [7/200], Train Loss: 1.3615, Valid Loss: 1.3654\n",
      "Validation loss improved to 1.3654\n",
      "Epoch [8/200], Train Loss: 1.3531, Valid Loss: 1.3594\n",
      "Validation loss improved to 1.3594\n",
      "Epoch [9/200], Train Loss: 1.3355, Valid Loss: 1.3537\n",
      "Validation loss improved to 1.3537\n",
      "Epoch [10/200], Train Loss: 1.3349, Valid Loss: 1.3486\n",
      "Validation loss improved to 1.3486\n",
      "Epoch [11/200], Train Loss: 1.3201, Valid Loss: 1.3438\n",
      "Validation loss improved to 1.3438\n",
      "Epoch [12/200], Train Loss: 1.3243, Valid Loss: 1.3393\n",
      "Validation loss improved to 1.3393\n",
      "Epoch [13/200], Train Loss: 1.3328, Valid Loss: 1.3350\n",
      "Validation loss improved to 1.3350\n",
      "Epoch [14/200], Train Loss: 1.3295, Valid Loss: 1.3308\n",
      "Validation loss improved to 1.3308\n",
      "Epoch [15/200], Train Loss: 1.2941, Valid Loss: 1.3268\n",
      "Validation loss improved to 1.3268\n",
      "Epoch [16/200], Train Loss: 1.3114, Valid Loss: 1.3228\n",
      "Validation loss improved to 1.3228\n",
      "Epoch [17/200], Train Loss: 1.2957, Valid Loss: 1.3190\n",
      "Validation loss improved to 1.3190\n",
      "Epoch [18/200], Train Loss: 1.3059, Valid Loss: 1.3149\n",
      "Validation loss improved to 1.3149\n",
      "Epoch [19/200], Train Loss: 1.2736, Valid Loss: 1.3110\n",
      "Validation loss improved to 1.3110\n",
      "Epoch [20/200], Train Loss: 1.2934, Valid Loss: 1.3069\n",
      "Validation loss improved to 1.3069\n",
      "Epoch [21/200], Train Loss: 1.2791, Valid Loss: 1.3027\n",
      "Validation loss improved to 1.3027\n",
      "Epoch [22/200], Train Loss: 1.2565, Valid Loss: 1.2984\n",
      "Validation loss improved to 1.2984\n",
      "Epoch [23/200], Train Loss: 1.2634, Valid Loss: 1.2942\n",
      "Validation loss improved to 1.2942\n",
      "Epoch [24/200], Train Loss: 1.2582, Valid Loss: 1.2899\n",
      "Validation loss improved to 1.2899\n",
      "Epoch [25/200], Train Loss: 1.2678, Valid Loss: 1.2856\n",
      "Validation loss improved to 1.2856\n",
      "Epoch [26/200], Train Loss: 1.2444, Valid Loss: 1.2813\n",
      "Validation loss improved to 1.2813\n",
      "Epoch [27/200], Train Loss: 1.2418, Valid Loss: 1.2770\n",
      "Validation loss improved to 1.2770\n",
      "Epoch [28/200], Train Loss: 1.2523, Valid Loss: 1.2727\n",
      "Validation loss improved to 1.2727\n",
      "Epoch [29/200], Train Loss: 1.2380, Valid Loss: 1.2684\n",
      "Validation loss improved to 1.2684\n",
      "Epoch [30/200], Train Loss: 1.2319, Valid Loss: 1.2640\n",
      "Validation loss improved to 1.2640\n",
      "Epoch [31/200], Train Loss: 1.2310, Valid Loss: 1.2596\n",
      "Validation loss improved to 1.2596\n",
      "Epoch [32/200], Train Loss: 1.2242, Valid Loss: 1.2550\n",
      "Validation loss improved to 1.2550\n",
      "Epoch [33/200], Train Loss: 1.2115, Valid Loss: 1.2502\n",
      "Validation loss improved to 1.2502\n",
      "Epoch [34/200], Train Loss: 1.2168, Valid Loss: 1.2452\n",
      "Validation loss improved to 1.2452\n",
      "Epoch [35/200], Train Loss: 1.2107, Valid Loss: 1.2400\n",
      "Validation loss improved to 1.2400\n",
      "Epoch [36/200], Train Loss: 1.1982, Valid Loss: 1.2348\n",
      "Validation loss improved to 1.2348\n",
      "Epoch [37/200], Train Loss: 1.1845, Valid Loss: 1.2293\n",
      "Validation loss improved to 1.2293\n",
      "Epoch [38/200], Train Loss: 1.1947, Valid Loss: 1.2237\n",
      "Validation loss improved to 1.2237\n",
      "Epoch [39/200], Train Loss: 1.1872, Valid Loss: 1.2180\n",
      "Validation loss improved to 1.2180\n",
      "Epoch [40/200], Train Loss: 1.1938, Valid Loss: 1.2124\n",
      "Validation loss improved to 1.2124\n",
      "Epoch [41/200], Train Loss: 1.1703, Valid Loss: 1.2067\n",
      "Validation loss improved to 1.2067\n",
      "Epoch [42/200], Train Loss: 1.1708, Valid Loss: 1.2004\n",
      "Validation loss improved to 1.2004\n",
      "Epoch [43/200], Train Loss: 1.1595, Valid Loss: 1.1940\n",
      "Validation loss improved to 1.1940\n",
      "Epoch [44/200], Train Loss: 1.1161, Valid Loss: 1.1871\n",
      "Validation loss improved to 1.1871\n",
      "Epoch [45/200], Train Loss: 1.1314, Valid Loss: 1.1796\n",
      "Validation loss improved to 1.1796\n",
      "Epoch [46/200], Train Loss: 1.1249, Valid Loss: 1.1718\n",
      "Validation loss improved to 1.1718\n",
      "Epoch [47/200], Train Loss: 1.1416, Valid Loss: 1.1637\n",
      "Validation loss improved to 1.1637\n",
      "Epoch [48/200], Train Loss: 1.0968, Valid Loss: 1.1556\n",
      "Validation loss improved to 1.1556\n",
      "Epoch [49/200], Train Loss: 1.1109, Valid Loss: 1.1473\n",
      "Validation loss improved to 1.1473\n",
      "Epoch [50/200], Train Loss: 1.0707, Valid Loss: 1.1386\n",
      "Validation loss improved to 1.1386\n",
      "Epoch [51/200], Train Loss: 1.0957, Valid Loss: 1.1300\n",
      "Validation loss improved to 1.1300\n",
      "Epoch [52/200], Train Loss: 1.0763, Valid Loss: 1.1215\n",
      "Validation loss improved to 1.1215\n",
      "Epoch [53/200], Train Loss: 1.0669, Valid Loss: 1.1128\n",
      "Validation loss improved to 1.1128\n",
      "Epoch [54/200], Train Loss: 1.0666, Valid Loss: 1.1047\n",
      "Validation loss improved to 1.1047\n",
      "Epoch [55/200], Train Loss: 1.0477, Valid Loss: 1.0964\n",
      "Validation loss improved to 1.0964\n",
      "Epoch [56/200], Train Loss: 1.0469, Valid Loss: 1.0878\n",
      "Validation loss improved to 1.0878\n",
      "Epoch [57/200], Train Loss: 1.0097, Valid Loss: 1.0783\n",
      "Validation loss improved to 1.0783\n",
      "Epoch [58/200], Train Loss: 1.0298, Valid Loss: 1.0681\n",
      "Validation loss improved to 1.0681\n",
      "Epoch [59/200], Train Loss: 1.0178, Valid Loss: 1.0571\n",
      "Validation loss improved to 1.0571\n",
      "Epoch [60/200], Train Loss: 0.9994, Valid Loss: 1.0460\n",
      "Validation loss improved to 1.0460\n",
      "Epoch [61/200], Train Loss: 0.9607, Valid Loss: 1.0350\n",
      "Validation loss improved to 1.0350\n",
      "Epoch [62/200], Train Loss: 0.9753, Valid Loss: 1.0232\n",
      "Validation loss improved to 1.0232\n",
      "Epoch [63/200], Train Loss: 0.9867, Valid Loss: 1.0112\n",
      "Validation loss improved to 1.0112\n",
      "Epoch [64/200], Train Loss: 0.9350, Valid Loss: 0.9997\n",
      "Validation loss improved to 0.9997\n",
      "Epoch [65/200], Train Loss: 0.9390, Valid Loss: 0.9885\n",
      "Validation loss improved to 0.9885\n",
      "Epoch [66/200], Train Loss: 0.9290, Valid Loss: 0.9774\n",
      "Validation loss improved to 0.9774\n",
      "Epoch [67/200], Train Loss: 0.9585, Valid Loss: 0.9669\n",
      "Validation loss improved to 0.9669\n",
      "Epoch [68/200], Train Loss: 0.9366, Valid Loss: 0.9564\n",
      "Validation loss improved to 0.9564\n",
      "Epoch [69/200], Train Loss: 0.9146, Valid Loss: 0.9455\n",
      "Validation loss improved to 0.9455\n",
      "Epoch [70/200], Train Loss: 0.8930, Valid Loss: 0.9335\n",
      "Validation loss improved to 0.9335\n",
      "Epoch [71/200], Train Loss: 0.8821, Valid Loss: 0.9221\n",
      "Validation loss improved to 0.9221\n",
      "Epoch [72/200], Train Loss: 0.9094, Valid Loss: 0.9114\n",
      "Validation loss improved to 0.9114\n",
      "Epoch [73/200], Train Loss: 0.8501, Valid Loss: 0.9002\n",
      "Validation loss improved to 0.9002\n",
      "Epoch [74/200], Train Loss: 0.8207, Valid Loss: 0.8893\n",
      "Validation loss improved to 0.8893\n",
      "Epoch [75/200], Train Loss: 0.8548, Valid Loss: 0.8780\n",
      "Validation loss improved to 0.8780\n",
      "Epoch [76/200], Train Loss: 0.8151, Valid Loss: 0.8675\n",
      "Validation loss improved to 0.8675\n",
      "Epoch [77/200], Train Loss: 0.8636, Valid Loss: 0.8575\n",
      "Validation loss improved to 0.8575\n",
      "Epoch [78/200], Train Loss: 0.8492, Valid Loss: 0.8456\n",
      "Validation loss improved to 0.8456\n",
      "Epoch [79/200], Train Loss: 0.8180, Valid Loss: 0.8334\n",
      "Validation loss improved to 0.8334\n",
      "Epoch [80/200], Train Loss: 0.7934, Valid Loss: 0.8216\n",
      "Validation loss improved to 0.8216\n",
      "Epoch [81/200], Train Loss: 0.8090, Valid Loss: 0.8107\n",
      "Validation loss improved to 0.8107\n",
      "Epoch [82/200], Train Loss: 0.7691, Valid Loss: 0.7982\n",
      "Validation loss improved to 0.7982\n",
      "Epoch [83/200], Train Loss: 0.7864, Valid Loss: 0.7880\n",
      "Validation loss improved to 0.7880\n",
      "Epoch [84/200], Train Loss: 0.7465, Valid Loss: 0.7764\n",
      "Validation loss improved to 0.7764\n",
      "Epoch [85/200], Train Loss: 0.7245, Valid Loss: 0.7639\n",
      "Validation loss improved to 0.7639\n",
      "Epoch [86/200], Train Loss: 0.7337, Valid Loss: 0.7531\n",
      "Validation loss improved to 0.7531\n",
      "Epoch [87/200], Train Loss: 0.7160, Valid Loss: 0.7439\n",
      "Validation loss improved to 0.7439\n",
      "Epoch [88/200], Train Loss: 0.7280, Valid Loss: 0.7342\n",
      "Validation loss improved to 0.7342\n",
      "Epoch [89/200], Train Loss: 0.7184, Valid Loss: 0.7214\n",
      "Validation loss improved to 0.7214\n",
      "Epoch [90/200], Train Loss: 0.6617, Valid Loss: 0.7084\n",
      "Validation loss improved to 0.7084\n",
      "Epoch [91/200], Train Loss: 0.6742, Valid Loss: 0.6977\n",
      "Validation loss improved to 0.6977\n",
      "Epoch [92/200], Train Loss: 0.6754, Valid Loss: 0.6870\n",
      "Validation loss improved to 0.6870\n",
      "Epoch [93/200], Train Loss: 0.6586, Valid Loss: 0.6801\n",
      "Validation loss improved to 0.6801\n",
      "Epoch [94/200], Train Loss: 0.7229, Valid Loss: 0.6716\n",
      "Validation loss improved to 0.6716\n",
      "Epoch [95/200], Train Loss: 0.6587, Valid Loss: 0.6610\n",
      "Validation loss improved to 0.6610\n",
      "Epoch [96/200], Train Loss: 0.6929, Valid Loss: 0.6482\n",
      "Validation loss improved to 0.6482\n",
      "Epoch [97/200], Train Loss: 0.6468, Valid Loss: 0.6350\n",
      "Validation loss improved to 0.6350\n",
      "Epoch [98/200], Train Loss: 0.6161, Valid Loss: 0.6250\n",
      "Validation loss improved to 0.6250\n",
      "Epoch [99/200], Train Loss: 0.6559, Valid Loss: 0.6172\n",
      "Validation loss improved to 0.6172\n",
      "Epoch [100/200], Train Loss: 0.6145, Valid Loss: 0.6090\n",
      "Validation loss improved to 0.6090\n",
      "Epoch [101/200], Train Loss: 0.5425, Valid Loss: 0.6004\n",
      "Validation loss improved to 0.6004\n",
      "Epoch [102/200], Train Loss: 0.6501, Valid Loss: 0.5890\n",
      "Validation loss improved to 0.5890\n",
      "Epoch [103/200], Train Loss: 0.6478, Valid Loss: 0.5764\n",
      "Validation loss improved to 0.5764\n",
      "Epoch [104/200], Train Loss: 0.5899, Valid Loss: 0.5670\n",
      "Validation loss improved to 0.5670\n",
      "Epoch [105/200], Train Loss: 0.5657, Valid Loss: 0.5583\n",
      "Validation loss improved to 0.5583\n",
      "Epoch [106/200], Train Loss: 0.5017, Valid Loss: 0.5497\n",
      "Validation loss improved to 0.5497\n",
      "Epoch [107/200], Train Loss: 0.5717, Valid Loss: 0.5408\n",
      "Validation loss improved to 0.5408\n",
      "Epoch [108/200], Train Loss: 0.5869, Valid Loss: 0.5364\n",
      "Validation loss improved to 0.5364\n",
      "Epoch [109/200], Train Loss: 0.5654, Valid Loss: 0.5301\n",
      "Validation loss improved to 0.5301\n",
      "Epoch [110/200], Train Loss: 0.5089, Valid Loss: 0.5219\n",
      "Validation loss improved to 0.5219\n",
      "Epoch [111/200], Train Loss: 0.5149, Valid Loss: 0.5108\n",
      "Validation loss improved to 0.5108\n",
      "Epoch [112/200], Train Loss: 0.5229, Valid Loss: 0.5015\n",
      "Validation loss improved to 0.5015\n",
      "Epoch [113/200], Train Loss: 0.4658, Valid Loss: 0.4920\n",
      "Validation loss improved to 0.4920\n",
      "Epoch [114/200], Train Loss: 0.4687, Valid Loss: 0.4841\n",
      "Validation loss improved to 0.4841\n",
      "Epoch [115/200], Train Loss: 0.4485, Valid Loss: 0.4798\n",
      "Validation loss improved to 0.4798\n",
      "Epoch [116/200], Train Loss: 0.4601, Valid Loss: 0.4775\n",
      "Validation loss improved to 0.4775\n",
      "Epoch [117/200], Train Loss: 0.4451, Valid Loss: 0.4726\n",
      "Validation loss improved to 0.4726\n",
      "Epoch [118/200], Train Loss: 0.4824, Valid Loss: 0.4615\n",
      "Validation loss improved to 0.4615\n",
      "Epoch [119/200], Train Loss: 0.4596, Valid Loss: 0.4474\n",
      "Validation loss improved to 0.4474\n",
      "Epoch [120/200], Train Loss: 0.4839, Valid Loss: 0.4365\n",
      "Validation loss improved to 0.4365\n",
      "Epoch [121/200], Train Loss: 0.4414, Valid Loss: 0.4293\n",
      "Validation loss improved to 0.4293\n",
      "Epoch [122/200], Train Loss: 0.4575, Valid Loss: 0.4250\n",
      "Validation loss improved to 0.4250\n",
      "Epoch [123/200], Train Loss: 0.3963, Valid Loss: 0.4214\n",
      "Validation loss improved to 0.4214\n",
      "Epoch [124/200], Train Loss: 0.4477, Valid Loss: 0.4144\n",
      "Validation loss improved to 0.4144\n",
      "Epoch [125/200], Train Loss: 0.4349, Valid Loss: 0.4068\n",
      "Validation loss improved to 0.4068\n",
      "Epoch [126/200], Train Loss: 0.3450, Valid Loss: 0.3992\n",
      "Validation loss improved to 0.3992\n",
      "Epoch [127/200], Train Loss: 0.3989, Valid Loss: 0.3958\n",
      "Validation loss improved to 0.3958\n",
      "Epoch [128/200], Train Loss: 0.3802, Valid Loss: 0.3932\n",
      "Validation loss improved to 0.3932\n",
      "Epoch [129/200], Train Loss: 0.3354, Valid Loss: 0.3903\n",
      "Validation loss improved to 0.3903\n",
      "Epoch [130/200], Train Loss: 0.4052, Valid Loss: 0.3853\n",
      "Validation loss improved to 0.3853\n",
      "Epoch [131/200], Train Loss: 0.3648, Valid Loss: 0.3773\n",
      "Validation loss improved to 0.3773\n",
      "Epoch [132/200], Train Loss: 0.3720, Valid Loss: 0.3684\n",
      "Validation loss improved to 0.3684\n",
      "Epoch [133/200], Train Loss: 0.3580, Valid Loss: 0.3607\n",
      "Validation loss improved to 0.3607\n",
      "Epoch [134/200], Train Loss: 0.3994, Valid Loss: 0.3579\n",
      "Validation loss improved to 0.3579\n",
      "Epoch [135/200], Train Loss: 0.3246, Valid Loss: 0.3581\n",
      "Epoch [136/200], Train Loss: 0.3424, Valid Loss: 0.3555\n",
      "Validation loss improved to 0.3555\n",
      "Epoch [137/200], Train Loss: 0.2869, Valid Loss: 0.3507\n",
      "Validation loss improved to 0.3507\n",
      "Epoch [138/200], Train Loss: 0.3779, Valid Loss: 0.3408\n",
      "Validation loss improved to 0.3408\n",
      "Epoch [139/200], Train Loss: 0.3722, Valid Loss: 0.3332\n",
      "Validation loss improved to 0.3332\n",
      "Epoch [140/200], Train Loss: 0.3075, Valid Loss: 0.3286\n",
      "Validation loss improved to 0.3286\n",
      "Epoch [141/200], Train Loss: 0.3577, Valid Loss: 0.3267\n",
      "Validation loss improved to 0.3267\n",
      "Epoch [142/200], Train Loss: 0.3374, Valid Loss: 0.3268\n",
      "Epoch [143/200], Train Loss: 0.2996, Valid Loss: 0.3272\n",
      "Epoch [144/200], Train Loss: 0.2840, Valid Loss: 0.3259\n",
      "Validation loss improved to 0.3259\n",
      "Epoch [145/200], Train Loss: 0.3249, Valid Loss: 0.3195\n",
      "Validation loss improved to 0.3195\n",
      "Epoch [146/200], Train Loss: 0.3052, Valid Loss: 0.3079\n",
      "Validation loss improved to 0.3079\n",
      "Epoch [147/200], Train Loss: 0.3170, Valid Loss: 0.3019\n",
      "Validation loss improved to 0.3019\n",
      "Epoch [148/200], Train Loss: 0.2638, Valid Loss: 0.2989\n",
      "Validation loss improved to 0.2989\n",
      "Epoch [149/200], Train Loss: 0.3528, Valid Loss: 0.2952\n",
      "Validation loss improved to 0.2952\n",
      "Epoch [150/200], Train Loss: 0.2814, Valid Loss: 0.2936\n",
      "Validation loss improved to 0.2936\n",
      "Epoch [151/200], Train Loss: 0.2736, Valid Loss: 0.2925\n",
      "Validation loss improved to 0.2925\n",
      "Epoch [152/200], Train Loss: 0.2739, Valid Loss: 0.2894\n",
      "Validation loss improved to 0.2894\n",
      "Epoch [153/200], Train Loss: 0.2507, Valid Loss: 0.2839\n",
      "Validation loss improved to 0.2839\n",
      "Epoch [154/200], Train Loss: 0.2834, Valid Loss: 0.2809\n",
      "Validation loss improved to 0.2809\n",
      "Epoch [155/200], Train Loss: 0.3097, Valid Loss: 0.2799\n",
      "Validation loss improved to 0.2799\n",
      "Epoch [156/200], Train Loss: 0.2279, Valid Loss: 0.2786\n",
      "Validation loss improved to 0.2786\n",
      "Epoch [157/200], Train Loss: 0.2713, Valid Loss: 0.2767\n",
      "Validation loss improved to 0.2767\n",
      "Epoch [158/200], Train Loss: 0.2875, Valid Loss: 0.2730\n",
      "Validation loss improved to 0.2730\n",
      "Epoch [159/200], Train Loss: 0.2579, Valid Loss: 0.2682\n",
      "Validation loss improved to 0.2682\n",
      "Epoch [160/200], Train Loss: 0.2378, Valid Loss: 0.2650\n",
      "Validation loss improved to 0.2650\n",
      "Epoch [161/200], Train Loss: 0.2456, Valid Loss: 0.2629\n",
      "Validation loss improved to 0.2629\n",
      "Epoch [162/200], Train Loss: 0.2323, Valid Loss: 0.2601\n",
      "Validation loss improved to 0.2601\n",
      "Epoch [163/200], Train Loss: 0.2505, Valid Loss: 0.2558\n",
      "Validation loss improved to 0.2558\n",
      "Epoch [164/200], Train Loss: 0.2833, Valid Loss: 0.2501\n",
      "Validation loss improved to 0.2501\n",
      "Epoch [165/200], Train Loss: 0.2596, Valid Loss: 0.2447\n",
      "Validation loss improved to 0.2447\n",
      "Epoch [166/200], Train Loss: 0.2523, Valid Loss: 0.2410\n",
      "Validation loss improved to 0.2410\n",
      "Epoch [167/200], Train Loss: 0.1706, Valid Loss: 0.2384\n",
      "Validation loss improved to 0.2384\n",
      "Epoch [168/200], Train Loss: 0.1962, Valid Loss: 0.2352\n",
      "Validation loss improved to 0.2352\n",
      "Epoch [169/200], Train Loss: 0.2441, Valid Loss: 0.2346\n",
      "Validation loss improved to 0.2346\n",
      "Epoch [170/200], Train Loss: 0.2136, Valid Loss: 0.2342\n",
      "Validation loss improved to 0.2342\n",
      "Epoch [171/200], Train Loss: 0.2334, Valid Loss: 0.2368\n",
      "Epoch [172/200], Train Loss: 0.2280, Valid Loss: 0.2367\n",
      "Epoch [173/200], Train Loss: 0.2437, Valid Loss: 0.2348\n",
      "Epoch [174/200], Train Loss: 0.2025, Valid Loss: 0.2276\n",
      "Validation loss improved to 0.2276\n",
      "Epoch [175/200], Train Loss: 0.1766, Valid Loss: 0.2220\n",
      "Validation loss improved to 0.2220\n",
      "Epoch [176/200], Train Loss: 0.1927, Valid Loss: 0.2178\n",
      "Validation loss improved to 0.2178\n",
      "Epoch [177/200], Train Loss: 0.1957, Valid Loss: 0.2155\n",
      "Validation loss improved to 0.2155\n",
      "Epoch [178/200], Train Loss: 0.1614, Valid Loss: 0.2182\n",
      "Epoch [179/200], Train Loss: 0.1871, Valid Loss: 0.2206\n",
      "Epoch [180/200], Train Loss: 0.1730, Valid Loss: 0.2234\n",
      "Epoch [181/200], Train Loss: 0.1924, Valid Loss: 0.2263\n",
      "Epoch [182/200], Train Loss: 0.2063, Valid Loss: 0.2267\n",
      "Epoch [183/200], Train Loss: 0.1978, Valid Loss: 0.2239\n",
      "Epoch [184/200], Train Loss: 0.1950, Valid Loss: 0.2214\n",
      "Epoch [185/200], Train Loss: 0.1962, Valid Loss: 0.2191\n",
      "Epoch [186/200], Train Loss: 0.1753, Valid Loss: 0.2147\n",
      "Validation loss improved to 0.2147\n",
      "Epoch [187/200], Train Loss: 0.2076, Valid Loss: 0.2118\n",
      "Validation loss improved to 0.2118\n",
      "Epoch [188/200], Train Loss: 0.1751, Valid Loss: 0.2093\n",
      "Validation loss improved to 0.2093\n",
      "Epoch [189/200], Train Loss: 0.1649, Valid Loss: 0.2098\n",
      "Epoch [190/200], Train Loss: 0.1435, Valid Loss: 0.2103\n",
      "Epoch [191/200], Train Loss: 0.1301, Valid Loss: 0.2097\n",
      "Epoch [192/200], Train Loss: 0.1642, Valid Loss: 0.2064\n",
      "Validation loss improved to 0.2064\n",
      "Epoch [193/200], Train Loss: 0.1416, Valid Loss: 0.2009\n",
      "Validation loss improved to 0.2009\n",
      "Epoch [194/200], Train Loss: 0.1231, Valid Loss: 0.1985\n",
      "Validation loss improved to 0.1985\n",
      "Epoch [195/200], Train Loss: 0.1114, Valid Loss: 0.1992\n",
      "Epoch [196/200], Train Loss: 0.1526, Valid Loss: 0.2029\n",
      "Epoch [197/200], Train Loss: 0.1916, Valid Loss: 0.2088\n",
      "Epoch [198/200], Train Loss: 0.1301, Valid Loss: 0.2125\n",
      "Epoch [199/200], Train Loss: 0.1754, Valid Loss: 0.2140\n",
      "Epoch [200/200], Train Loss: 0.1459, Valid Loss: 0.2101\n",
      "Training completed. Final model saved as model/loss_0.1985_lr_0.001_batch_32_opt_SGD.pt\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 200, 'learning_rate': 0.001, 'optimizer': 'RMSprop'}\n",
      "Epoch [1/200], Train Loss: 1.4044, Valid Loss: 1.7885\n",
      "Validation loss improved to 1.7885\n",
      "Epoch [2/200], Train Loss: 1.6259, Valid Loss: 1.4263\n",
      "Validation loss improved to 1.4263\n",
      "Epoch [3/200], Train Loss: 1.4691, Valid Loss: 1.3777\n",
      "Validation loss improved to 1.3777\n",
      "Epoch [4/200], Train Loss: 1.3755, Valid Loss: 1.3875\n",
      "Epoch [5/200], Train Loss: 1.4182, Valid Loss: 1.3684\n",
      "Validation loss improved to 1.3684\n",
      "Epoch [6/200], Train Loss: 1.3973, Valid Loss: 1.4071\n",
      "Epoch [7/200], Train Loss: 1.3926, Valid Loss: 1.3528\n",
      "Validation loss improved to 1.3528\n",
      "Epoch [8/200], Train Loss: 1.3898, Valid Loss: 1.4009\n",
      "Epoch [9/200], Train Loss: 1.4270, Valid Loss: 1.3737\n",
      "Epoch [10/200], Train Loss: 1.3632, Valid Loss: 1.3698\n",
      "Epoch [11/200], Train Loss: 1.2995, Valid Loss: 1.3095\n",
      "Validation loss improved to 1.3095\n",
      "Epoch [12/200], Train Loss: 1.3303, Valid Loss: 1.3345\n",
      "Epoch [13/200], Train Loss: 1.4041, Valid Loss: 1.3595\n",
      "Epoch [14/200], Train Loss: 1.3655, Valid Loss: 1.3109\n",
      "Epoch [15/200], Train Loss: 1.3339, Valid Loss: 1.2771\n",
      "Validation loss improved to 1.2771\n",
      "Epoch [16/200], Train Loss: 1.3210, Valid Loss: 1.2552\n",
      "Validation loss improved to 1.2552\n",
      "Epoch [17/200], Train Loss: 1.3176, Valid Loss: 1.2027\n",
      "Validation loss improved to 1.2027\n",
      "Epoch [18/200], Train Loss: 1.2532, Valid Loss: 1.2490\n",
      "Epoch [19/200], Train Loss: 1.3205, Valid Loss: 1.3040\n",
      "Epoch [20/200], Train Loss: 1.3287, Valid Loss: 1.2725\n",
      "Epoch [21/200], Train Loss: 1.2707, Valid Loss: 1.1816\n",
      "Validation loss improved to 1.1816\n",
      "Epoch [22/200], Train Loss: 1.2953, Valid Loss: 1.1955\n",
      "Epoch [23/200], Train Loss: 1.3019, Valid Loss: 1.1489\n",
      "Validation loss improved to 1.1489\n",
      "Epoch [24/200], Train Loss: 1.1277, Valid Loss: 2.7989\n",
      "Epoch [25/200], Train Loss: 2.1661, Valid Loss: 1.2862\n",
      "Epoch [26/200], Train Loss: 1.3202, Valid Loss: 1.1552\n",
      "Epoch [27/200], Train Loss: 1.2167, Valid Loss: 1.3309\n",
      "Epoch [28/200], Train Loss: 1.2093, Valid Loss: 1.1965\n",
      "Epoch [29/200], Train Loss: 1.2941, Valid Loss: 1.2225\n",
      "Epoch [30/200], Train Loss: 1.2353, Valid Loss: 1.4698\n",
      "Epoch [31/200], Train Loss: 1.5611, Valid Loss: 1.4414\n",
      "Epoch [32/200], Train Loss: 1.4795, Valid Loss: 1.3987\n",
      "Epoch [33/200], Train Loss: 1.4154, Valid Loss: 1.4289\n",
      "Early stopping triggered at epoch 33\n",
      "Training completed. Final model saved as model/loss_1.1489_lr_0.001_batch_32_opt_RMSprop.pt\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 200, 'learning_rate': 0.01, 'optimizer': 'Adam'}\n",
      "Epoch [1/200], Train Loss: 1.4088, Valid Loss: 1.4571\n",
      "Validation loss improved to 1.4571\n",
      "Epoch [2/200], Train Loss: 1.5570, Valid Loss: 1.5370\n",
      "Epoch [3/200], Train Loss: 1.5717, Valid Loss: 1.3928\n",
      "Validation loss improved to 1.3928\n",
      "Epoch [4/200], Train Loss: 1.3798, Valid Loss: 1.4001\n",
      "Epoch [5/200], Train Loss: 1.4298, Valid Loss: 1.3958\n",
      "Epoch [6/200], Train Loss: 1.3827, Valid Loss: 1.3902\n",
      "Validation loss improved to 1.3902\n",
      "Epoch [7/200], Train Loss: 1.3739, Valid Loss: 1.3909\n",
      "Epoch [8/200], Train Loss: 1.4397, Valid Loss: 1.3902\n",
      "Epoch [9/200], Train Loss: 1.3997, Valid Loss: 1.3902\n",
      "Epoch [10/200], Train Loss: 1.4037, Valid Loss: 1.3903\n",
      "Epoch [11/200], Train Loss: 1.4108, Valid Loss: 1.3887\n",
      "Validation loss improved to 1.3887\n",
      "Epoch [12/200], Train Loss: 1.3980, Valid Loss: 1.3875\n",
      "Validation loss improved to 1.3875\n",
      "Epoch [13/200], Train Loss: 1.3841, Valid Loss: 1.3871\n",
      "Validation loss improved to 1.3871\n",
      "Epoch [14/200], Train Loss: 1.3876, Valid Loss: 1.3869\n",
      "Validation loss improved to 1.3869\n",
      "Epoch [15/200], Train Loss: 1.3917, Valid Loss: 1.3869\n",
      "Epoch [16/200], Train Loss: 1.3893, Valid Loss: 1.3871\n",
      "Epoch [17/200], Train Loss: 1.3873, Valid Loss: 1.3872\n",
      "Epoch [18/200], Train Loss: 1.3875, Valid Loss: 1.3871\n",
      "Epoch [19/200], Train Loss: 1.3860, Valid Loss: 1.3870\n",
      "Epoch [20/200], Train Loss: 1.3865, Valid Loss: 1.3869\n",
      "Validation loss improved to 1.3869\n",
      "Epoch [21/200], Train Loss: 1.3869, Valid Loss: 1.3868\n",
      "Validation loss improved to 1.3868\n",
      "Epoch [22/200], Train Loss: 1.3863, Valid Loss: 1.3868\n",
      "Validation loss improved to 1.3868\n",
      "Epoch [23/200], Train Loss: 1.3870, Valid Loss: 1.3867\n",
      "Validation loss improved to 1.3867\n",
      "Epoch [24/200], Train Loss: 1.3864, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [25/200], Train Loss: 1.3874, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [26/200], Train Loss: 1.3864, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [27/200], Train Loss: 1.3863, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [28/200], Train Loss: 1.3875, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [29/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [30/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [31/200], Train Loss: 1.3865, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [32/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [33/200], Train Loss: 1.3871, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [34/200], Train Loss: 1.3865, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [35/200], Train Loss: 1.3864, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [36/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [37/200], Train Loss: 1.3865, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [38/200], Train Loss: 1.3864, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [39/200], Train Loss: 1.3866, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [40/200], Train Loss: 1.3864, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [41/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [42/200], Train Loss: 1.3864, Valid Loss: 1.3863\n",
      "Epoch [43/200], Train Loss: 1.3864, Valid Loss: 1.3863\n",
      "Epoch [44/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [45/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [46/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [47/200], Train Loss: 1.3864, Valid Loss: 1.3863\n",
      "Epoch [48/200], Train Loss: 1.3865, Valid Loss: 1.3863\n",
      "Epoch [49/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [50/200], Train Loss: 1.3862, Valid Loss: 1.3863\n",
      "Epoch [51/200], Train Loss: 1.3865, Valid Loss: 1.3863\n",
      "Early stopping triggered at epoch 51\n",
      "Training completed. Final model saved as model/loss_1.3863_lr_0.01_batch_32_opt_Adam.pt\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 200, 'learning_rate': 0.01, 'optimizer': 'SGD'}\n",
      "Epoch [1/200], Train Loss: 1.3920, Valid Loss: 1.3679\n",
      "Validation loss improved to 1.3679\n",
      "Epoch [2/200], Train Loss: 1.3821, Valid Loss: 1.3477\n",
      "Validation loss improved to 1.3477\n",
      "Epoch [3/200], Train Loss: 1.3261, Valid Loss: 1.3283\n",
      "Validation loss improved to 1.3283\n",
      "Epoch [4/200], Train Loss: 1.3127, Valid Loss: 1.3105\n",
      "Validation loss improved to 1.3105\n",
      "Epoch [5/200], Train Loss: 1.2764, Valid Loss: 1.2938\n",
      "Validation loss improved to 1.2938\n",
      "Epoch [6/200], Train Loss: 1.2448, Valid Loss: 1.2770\n",
      "Validation loss improved to 1.2770\n",
      "Epoch [7/200], Train Loss: 1.2243, Valid Loss: 1.2556\n",
      "Validation loss improved to 1.2556\n",
      "Epoch [8/200], Train Loss: 1.2248, Valid Loss: 1.2309\n",
      "Validation loss improved to 1.2309\n",
      "Epoch [9/200], Train Loss: 1.1800, Valid Loss: 1.2037\n",
      "Validation loss improved to 1.2037\n",
      "Epoch [10/200], Train Loss: 1.1790, Valid Loss: 1.1721\n",
      "Validation loss improved to 1.1721\n",
      "Epoch [11/200], Train Loss: 1.1071, Valid Loss: 1.1339\n",
      "Validation loss improved to 1.1339\n",
      "Epoch [12/200], Train Loss: 1.0745, Valid Loss: 1.0906\n",
      "Validation loss improved to 1.0906\n",
      "Epoch [13/200], Train Loss: 1.0510, Valid Loss: 1.0407\n",
      "Validation loss improved to 1.0407\n",
      "Epoch [14/200], Train Loss: 1.0236, Valid Loss: 0.9800\n",
      "Validation loss improved to 0.9800\n",
      "Epoch [15/200], Train Loss: 0.9453, Valid Loss: 0.9134\n",
      "Validation loss improved to 0.9134\n",
      "Epoch [16/200], Train Loss: 0.8402, Valid Loss: 0.8484\n",
      "Validation loss improved to 0.8484\n",
      "Epoch [17/200], Train Loss: 0.8022, Valid Loss: 0.7808\n",
      "Validation loss improved to 0.7808\n",
      "Epoch [18/200], Train Loss: 0.7755, Valid Loss: 0.7078\n",
      "Validation loss improved to 0.7078\n",
      "Epoch [19/200], Train Loss: 0.7256, Valid Loss: 0.6496\n",
      "Validation loss improved to 0.6496\n",
      "Epoch [20/200], Train Loss: 0.6005, Valid Loss: 0.5770\n",
      "Validation loss improved to 0.5770\n",
      "Epoch [21/200], Train Loss: 0.5368, Valid Loss: 0.5031\n",
      "Validation loss improved to 0.5031\n",
      "Epoch [22/200], Train Loss: 0.4947, Valid Loss: 0.4500\n",
      "Validation loss improved to 0.4500\n",
      "Epoch [23/200], Train Loss: 0.4436, Valid Loss: 0.3836\n",
      "Validation loss improved to 0.3836\n",
      "Epoch [24/200], Train Loss: 0.4135, Valid Loss: 0.3259\n",
      "Validation loss improved to 0.3259\n",
      "Epoch [25/200], Train Loss: 0.3180, Valid Loss: 0.2865\n",
      "Validation loss improved to 0.2865\n",
      "Epoch [26/200], Train Loss: 0.2971, Valid Loss: 0.2478\n",
      "Validation loss improved to 0.2478\n",
      "Epoch [27/200], Train Loss: 0.2710, Valid Loss: 0.2279\n",
      "Validation loss improved to 0.2279\n",
      "Epoch [28/200], Train Loss: 0.2486, Valid Loss: 0.2028\n",
      "Validation loss improved to 0.2028\n",
      "Epoch [29/200], Train Loss: 0.2220, Valid Loss: 0.1713\n",
      "Validation loss improved to 0.1713\n",
      "Epoch [30/200], Train Loss: 0.1973, Valid Loss: 0.1520\n",
      "Validation loss improved to 0.1520\n",
      "Epoch [31/200], Train Loss: 0.1826, Valid Loss: 0.1379\n",
      "Validation loss improved to 0.1379\n",
      "Epoch [32/200], Train Loss: 0.1380, Valid Loss: 0.1372\n",
      "Validation loss improved to 0.1372\n",
      "Epoch [33/200], Train Loss: 0.1120, Valid Loss: 0.1500\n",
      "Epoch [34/200], Train Loss: 0.1487, Valid Loss: 0.1381\n",
      "Epoch [35/200], Train Loss: 0.0938, Valid Loss: 0.1163\n",
      "Validation loss improved to 0.1163\n",
      "Epoch [36/200], Train Loss: 0.0844, Valid Loss: 0.1064\n",
      "Validation loss improved to 0.1064\n",
      "Epoch [37/200], Train Loss: 0.1075, Valid Loss: 0.0949\n",
      "Validation loss improved to 0.0949\n",
      "Epoch [38/200], Train Loss: 0.0598, Valid Loss: 0.0868\n",
      "Validation loss improved to 0.0868\n",
      "Epoch [39/200], Train Loss: 0.0976, Valid Loss: 0.0863\n",
      "Validation loss improved to 0.0863\n",
      "Epoch [40/200], Train Loss: 0.0742, Valid Loss: 0.0918\n",
      "Epoch [41/200], Train Loss: 0.0623, Valid Loss: 0.1072\n",
      "Epoch [42/200], Train Loss: 0.0596, Valid Loss: 0.1317\n",
      "Epoch [43/200], Train Loss: 0.0596, Valid Loss: 0.1212\n",
      "Epoch [44/200], Train Loss: 0.0735, Valid Loss: 0.0842\n",
      "Validation loss improved to 0.0842\n",
      "Epoch [45/200], Train Loss: 0.0526, Valid Loss: 0.0505\n",
      "Validation loss improved to 0.0505\n",
      "Epoch [46/200], Train Loss: 0.0361, Valid Loss: 0.0434\n",
      "Validation loss improved to 0.0434\n",
      "Epoch [47/200], Train Loss: 0.0641, Valid Loss: 0.0530\n",
      "Epoch [48/200], Train Loss: 0.0275, Valid Loss: 0.0820\n",
      "Epoch [49/200], Train Loss: 0.0369, Valid Loss: 0.1265\n",
      "Epoch [50/200], Train Loss: 0.0303, Valid Loss: 0.1543\n",
      "Epoch [51/200], Train Loss: 0.0294, Valid Loss: 0.1664\n",
      "Epoch [52/200], Train Loss: 0.0339, Valid Loss: 0.1482\n",
      "Epoch [53/200], Train Loss: 0.0378, Valid Loss: 0.1092\n",
      "Epoch [54/200], Train Loss: 0.0337, Valid Loss: 0.0760\n",
      "Epoch [55/200], Train Loss: 0.0253, Valid Loss: 0.0627\n",
      "Epoch [56/200], Train Loss: 0.0442, Valid Loss: 0.0563\n",
      "Early stopping triggered at epoch 56\n",
      "Training completed. Final model saved as model/loss_0.0434_lr_0.01_batch_32_opt_SGD.pt\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 200, 'learning_rate': 0.01, 'optimizer': 'RMSprop'}\n",
      "Epoch [1/200], Train Loss: 2.3345, Valid Loss: 10.4631\n",
      "Validation loss improved to 10.4631\n",
      "Epoch [2/200], Train Loss: 10.9423, Valid Loss: 10.8506\n",
      "Epoch [3/200], Train Loss: 7.2353, Valid Loss: 3.9991\n",
      "Validation loss improved to 3.9991\n",
      "Epoch [4/200], Train Loss: 3.2668, Valid Loss: 1.4048\n",
      "Validation loss improved to 1.4048\n",
      "Epoch [5/200], Train Loss: 1.4088, Valid Loss: 1.3925\n",
      "Validation loss improved to 1.3925\n",
      "Epoch [6/200], Train Loss: 1.3954, Valid Loss: 1.3911\n",
      "Validation loss improved to 1.3911\n",
      "Epoch [7/200], Train Loss: 1.3933, Valid Loss: 1.3903\n",
      "Validation loss improved to 1.3903\n",
      "Epoch [8/200], Train Loss: 1.3923, Valid Loss: 1.3895\n",
      "Validation loss improved to 1.3895\n",
      "Epoch [9/200], Train Loss: 1.3914, Valid Loss: 1.3942\n",
      "Epoch [10/200], Train Loss: 1.4031, Valid Loss: 1.3890\n",
      "Validation loss improved to 1.3890\n",
      "Epoch [11/200], Train Loss: 1.3934, Valid Loss: 1.3883\n",
      "Validation loss improved to 1.3883\n",
      "Epoch [12/200], Train Loss: 1.3903, Valid Loss: 1.3879\n",
      "Validation loss improved to 1.3879\n",
      "Epoch [13/200], Train Loss: 1.3876, Valid Loss: 1.3877\n",
      "Validation loss improved to 1.3877\n",
      "Epoch [14/200], Train Loss: 1.3875, Valid Loss: 1.3876\n",
      "Validation loss improved to 1.3876\n",
      "Epoch [15/200], Train Loss: 1.3890, Valid Loss: 1.3875\n",
      "Validation loss improved to 1.3875\n",
      "Epoch [16/200], Train Loss: 1.3874, Valid Loss: 1.3874\n",
      "Validation loss improved to 1.3874\n",
      "Epoch [17/200], Train Loss: 1.3890, Valid Loss: 1.3872\n",
      "Validation loss improved to 1.3872\n",
      "Epoch [18/200], Train Loss: 1.3909, Valid Loss: 1.3871\n",
      "Validation loss improved to 1.3871\n",
      "Epoch [19/200], Train Loss: 1.3872, Valid Loss: 1.3870\n",
      "Validation loss improved to 1.3870\n",
      "Epoch [20/200], Train Loss: 1.3910, Valid Loss: 1.3868\n",
      "Validation loss improved to 1.3868\n",
      "Epoch [21/200], Train Loss: 1.3878, Valid Loss: 1.3867\n",
      "Validation loss improved to 1.3867\n",
      "Epoch [22/200], Train Loss: 1.3871, Valid Loss: 1.3867\n",
      "Validation loss improved to 1.3867\n",
      "Epoch [23/200], Train Loss: 1.3870, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [24/200], Train Loss: 1.3880, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [25/200], Train Loss: 1.3890, Valid Loss: 1.3866\n",
      "Epoch [26/200], Train Loss: 1.3878, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [27/200], Train Loss: 1.3868, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [28/200], Train Loss: 1.3865, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [29/200], Train Loss: 1.3870, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [30/200], Train Loss: 1.3879, Valid Loss: 1.3865\n",
      "Epoch [31/200], Train Loss: 1.3881, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [32/200], Train Loss: 1.3868, Valid Loss: 1.3865\n",
      "Epoch [33/200], Train Loss: 1.3885, Valid Loss: 1.3865\n",
      "Epoch [34/200], Train Loss: 1.3880, Valid Loss: 1.3865\n",
      "Epoch [35/200], Train Loss: 1.3879, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [36/200], Train Loss: 1.3873, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [37/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [38/200], Train Loss: 1.3870, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [39/200], Train Loss: 1.3869, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [40/200], Train Loss: 1.3885, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [41/200], Train Loss: 1.3866, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [42/200], Train Loss: 1.3877, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [43/200], Train Loss: 1.3875, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [44/200], Train Loss: 1.3867, Valid Loss: 1.3863\n",
      "Epoch [45/200], Train Loss: 1.3873, Valid Loss: 1.3863\n",
      "Epoch [46/200], Train Loss: 1.3874, Valid Loss: 1.3863\n",
      "Epoch [47/200], Train Loss: 1.3870, Valid Loss: 1.3863\n",
      "Epoch [48/200], Train Loss: 1.3868, Valid Loss: 1.3863\n",
      "Epoch [49/200], Train Loss: 1.3868, Valid Loss: 1.3863\n",
      "Epoch [50/200], Train Loss: 1.3888, Valid Loss: 1.3863\n",
      "Epoch [51/200], Train Loss: 1.3865, Valid Loss: 1.3863\n",
      "Epoch [52/200], Train Loss: 1.3880, Valid Loss: 1.3863\n",
      "Epoch [53/200], Train Loss: 1.3896, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [54/200], Train Loss: 1.3864, Valid Loss: 1.3863\n",
      "Epoch [55/200], Train Loss: 1.3872, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [56/200], Train Loss: 1.3865, Valid Loss: 1.3863\n",
      "Epoch [57/200], Train Loss: 1.3869, Valid Loss: 1.3863\n",
      "Epoch [58/200], Train Loss: 1.3865, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [59/200], Train Loss: 1.3869, Valid Loss: 1.3863\n",
      "Epoch [60/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [61/200], Train Loss: 1.3873, Valid Loss: 1.3863\n",
      "Epoch [62/200], Train Loss: 1.3878, Valid Loss: 1.3863\n",
      "Epoch [63/200], Train Loss: 1.3869, Valid Loss: 1.3863\n",
      "Epoch [64/200], Train Loss: 1.3874, Valid Loss: 1.3863\n",
      "Epoch [65/200], Train Loss: 1.3869, Valid Loss: 1.3863\n",
      "Epoch [66/200], Train Loss: 1.3875, Valid Loss: 1.3863\n",
      "Epoch [67/200], Train Loss: 1.3881, Valid Loss: 1.3863\n",
      "Epoch [68/200], Train Loss: 1.3865, Valid Loss: 1.3863\n",
      "Early stopping triggered at epoch 68\n",
      "Training completed. Final model saved as model/loss_1.3863_lr_0.01_batch_32_opt_RMSprop.pt\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 200, 'learning_rate': 0.0001, 'optimizer': 'Adam'}\n",
      "Epoch [1/200], Train Loss: 1.4099, Valid Loss: 1.3995\n",
      "Validation loss improved to 1.3995\n",
      "Epoch [2/200], Train Loss: 1.3978, Valid Loss: 1.3910\n",
      "Validation loss improved to 1.3910\n",
      "Epoch [3/200], Train Loss: 1.3503, Valid Loss: 1.3829\n",
      "Validation loss improved to 1.3829\n",
      "Epoch [4/200], Train Loss: 1.3470, Valid Loss: 1.3754\n",
      "Validation loss improved to 1.3754\n",
      "Epoch [5/200], Train Loss: 1.3402, Valid Loss: 1.3691\n",
      "Validation loss improved to 1.3691\n",
      "Epoch [6/200], Train Loss: 1.3339, Valid Loss: 1.3632\n",
      "Validation loss improved to 1.3632\n",
      "Epoch [7/200], Train Loss: 1.3055, Valid Loss: 1.3570\n",
      "Validation loss improved to 1.3570\n",
      "Epoch [8/200], Train Loss: 1.3015, Valid Loss: 1.3508\n",
      "Validation loss improved to 1.3508\n",
      "Epoch [9/200], Train Loss: 1.3117, Valid Loss: 1.3449\n",
      "Validation loss improved to 1.3449\n",
      "Epoch [10/200], Train Loss: 1.2799, Valid Loss: 1.3391\n",
      "Validation loss improved to 1.3391\n",
      "Epoch [11/200], Train Loss: 1.2873, Valid Loss: 1.3332\n",
      "Validation loss improved to 1.3332\n",
      "Epoch [12/200], Train Loss: 1.2651, Valid Loss: 1.3271\n",
      "Validation loss improved to 1.3271\n",
      "Epoch [13/200], Train Loss: 1.2824, Valid Loss: 1.3206\n",
      "Validation loss improved to 1.3206\n",
      "Epoch [14/200], Train Loss: 1.2574, Valid Loss: 1.3140\n",
      "Validation loss improved to 1.3140\n",
      "Epoch [15/200], Train Loss: 1.2476, Valid Loss: 1.3073\n",
      "Validation loss improved to 1.3073\n",
      "Epoch [16/200], Train Loss: 1.2356, Valid Loss: 1.2999\n",
      "Validation loss improved to 1.2999\n",
      "Epoch [17/200], Train Loss: 1.2378, Valid Loss: 1.2925\n",
      "Validation loss improved to 1.2925\n",
      "Epoch [18/200], Train Loss: 1.2152, Valid Loss: 1.2849\n",
      "Validation loss improved to 1.2849\n",
      "Epoch [19/200], Train Loss: 1.2088, Valid Loss: 1.2770\n",
      "Validation loss improved to 1.2770\n",
      "Epoch [20/200], Train Loss: 1.2301, Valid Loss: 1.2691\n",
      "Validation loss improved to 1.2691\n",
      "Epoch [21/200], Train Loss: 1.1981, Valid Loss: 1.2605\n",
      "Validation loss improved to 1.2605\n",
      "Epoch [22/200], Train Loss: 1.1815, Valid Loss: 1.2517\n",
      "Validation loss improved to 1.2517\n",
      "Epoch [23/200], Train Loss: 1.2001, Valid Loss: 1.2424\n",
      "Validation loss improved to 1.2424\n",
      "Epoch [24/200], Train Loss: 1.1638, Valid Loss: 1.2324\n",
      "Validation loss improved to 1.2324\n",
      "Epoch [25/200], Train Loss: 1.1700, Valid Loss: 1.2219\n",
      "Validation loss improved to 1.2219\n",
      "Epoch [26/200], Train Loss: 1.1544, Valid Loss: 1.2108\n",
      "Validation loss improved to 1.2108\n",
      "Epoch [27/200], Train Loss: 1.1599, Valid Loss: 1.1999\n",
      "Validation loss improved to 1.1999\n",
      "Epoch [28/200], Train Loss: 1.1284, Valid Loss: 1.1889\n",
      "Validation loss improved to 1.1889\n",
      "Epoch [29/200], Train Loss: 1.1514, Valid Loss: 1.1778\n",
      "Validation loss improved to 1.1778\n",
      "Epoch [30/200], Train Loss: 1.1296, Valid Loss: 1.1662\n",
      "Validation loss improved to 1.1662\n",
      "Epoch [31/200], Train Loss: 1.0990, Valid Loss: 1.1533\n",
      "Validation loss improved to 1.1533\n",
      "Epoch [32/200], Train Loss: 1.1195, Valid Loss: 1.1405\n",
      "Validation loss improved to 1.1405\n",
      "Epoch [33/200], Train Loss: 1.0653, Valid Loss: 1.1273\n",
      "Validation loss improved to 1.1273\n",
      "Epoch [34/200], Train Loss: 1.0721, Valid Loss: 1.1140\n",
      "Validation loss improved to 1.1140\n",
      "Epoch [35/200], Train Loss: 1.0694, Valid Loss: 1.1005\n",
      "Validation loss improved to 1.1005\n",
      "Epoch [36/200], Train Loss: 1.0909, Valid Loss: 1.0875\n",
      "Validation loss improved to 1.0875\n",
      "Epoch [37/200], Train Loss: 1.0614, Valid Loss: 1.0748\n",
      "Validation loss improved to 1.0748\n",
      "Epoch [38/200], Train Loss: 1.0271, Valid Loss: 1.0620\n",
      "Validation loss improved to 1.0620\n",
      "Epoch [39/200], Train Loss: 1.0161, Valid Loss: 1.0492\n",
      "Validation loss improved to 1.0492\n",
      "Epoch [40/200], Train Loss: 1.0159, Valid Loss: 1.0359\n",
      "Validation loss improved to 1.0359\n",
      "Epoch [41/200], Train Loss: 1.0172, Valid Loss: 1.0233\n",
      "Validation loss improved to 1.0233\n",
      "Epoch [42/200], Train Loss: 0.9680, Valid Loss: 1.0098\n",
      "Validation loss improved to 1.0098\n",
      "Epoch [43/200], Train Loss: 0.9554, Valid Loss: 0.9954\n",
      "Validation loss improved to 0.9954\n",
      "Epoch [44/200], Train Loss: 0.9725, Valid Loss: 0.9805\n",
      "Validation loss improved to 0.9805\n",
      "Epoch [45/200], Train Loss: 0.9283, Valid Loss: 0.9662\n",
      "Validation loss improved to 0.9662\n",
      "Epoch [46/200], Train Loss: 0.9413, Valid Loss: 0.9523\n",
      "Validation loss improved to 0.9523\n",
      "Epoch [47/200], Train Loss: 0.9063, Valid Loss: 0.9391\n",
      "Validation loss improved to 0.9391\n",
      "Epoch [48/200], Train Loss: 0.9246, Valid Loss: 0.9272\n",
      "Validation loss improved to 0.9272\n",
      "Epoch [49/200], Train Loss: 0.8801, Valid Loss: 0.9149\n",
      "Validation loss improved to 0.9149\n",
      "Epoch [50/200], Train Loss: 0.9269, Valid Loss: 0.9028\n",
      "Validation loss improved to 0.9028\n",
      "Epoch [51/200], Train Loss: 0.8596, Valid Loss: 0.8911\n",
      "Validation loss improved to 0.8911\n",
      "Epoch [52/200], Train Loss: 0.8868, Valid Loss: 0.8786\n",
      "Validation loss improved to 0.8786\n",
      "Epoch [53/200], Train Loss: 0.8253, Valid Loss: 0.8669\n",
      "Validation loss improved to 0.8669\n",
      "Epoch [54/200], Train Loss: 0.8687, Valid Loss: 0.8557\n",
      "Validation loss improved to 0.8557\n",
      "Epoch [55/200], Train Loss: 0.8118, Valid Loss: 0.8444\n",
      "Validation loss improved to 0.8444\n",
      "Epoch [56/200], Train Loss: 0.8070, Valid Loss: 0.8331\n",
      "Validation loss improved to 0.8331\n",
      "Epoch [57/200], Train Loss: 0.7932, Valid Loss: 0.8206\n",
      "Validation loss improved to 0.8206\n",
      "Epoch [58/200], Train Loss: 0.8037, Valid Loss: 0.8084\n",
      "Validation loss improved to 0.8084\n",
      "Epoch [59/200], Train Loss: 0.7599, Valid Loss: 0.7957\n",
      "Validation loss improved to 0.7957\n",
      "Epoch [60/200], Train Loss: 0.7937, Valid Loss: 0.7846\n",
      "Validation loss improved to 0.7846\n",
      "Epoch [61/200], Train Loss: 0.7339, Valid Loss: 0.7735\n",
      "Validation loss improved to 0.7735\n",
      "Epoch [62/200], Train Loss: 0.7719, Valid Loss: 0.7626\n",
      "Validation loss improved to 0.7626\n",
      "Epoch [63/200], Train Loss: 0.7917, Valid Loss: 0.7506\n",
      "Validation loss improved to 0.7506\n",
      "Epoch [64/200], Train Loss: 0.6845, Valid Loss: 0.7386\n",
      "Validation loss improved to 0.7386\n",
      "Epoch [65/200], Train Loss: 0.6679, Valid Loss: 0.7273\n",
      "Validation loss improved to 0.7273\n",
      "Epoch [66/200], Train Loss: 0.7102, Valid Loss: 0.7170\n",
      "Validation loss improved to 0.7170\n",
      "Epoch [67/200], Train Loss: 0.6980, Valid Loss: 0.7065\n",
      "Validation loss improved to 0.7065\n",
      "Epoch [68/200], Train Loss: 0.6543, Valid Loss: 0.6958\n",
      "Validation loss improved to 0.6958\n",
      "Epoch [69/200], Train Loss: 0.6985, Valid Loss: 0.6849\n",
      "Validation loss improved to 0.6849\n",
      "Epoch [70/200], Train Loss: 0.6576, Valid Loss: 0.6740\n",
      "Validation loss improved to 0.6740\n",
      "Epoch [71/200], Train Loss: 0.6495, Valid Loss: 0.6628\n",
      "Validation loss improved to 0.6628\n",
      "Epoch [72/200], Train Loss: 0.6427, Valid Loss: 0.6534\n",
      "Validation loss improved to 0.6534\n",
      "Epoch [73/200], Train Loss: 0.6419, Valid Loss: 0.6436\n",
      "Validation loss improved to 0.6436\n",
      "Epoch [74/200], Train Loss: 0.6298, Valid Loss: 0.6321\n",
      "Validation loss improved to 0.6321\n",
      "Epoch [75/200], Train Loss: 0.6474, Valid Loss: 0.6199\n",
      "Validation loss improved to 0.6199\n",
      "Epoch [76/200], Train Loss: 0.6339, Valid Loss: 0.6082\n",
      "Validation loss improved to 0.6082\n",
      "Epoch [77/200], Train Loss: 0.6061, Valid Loss: 0.5991\n",
      "Validation loss improved to 0.5991\n",
      "Epoch [78/200], Train Loss: 0.5483, Valid Loss: 0.5896\n",
      "Validation loss improved to 0.5896\n",
      "Epoch [79/200], Train Loss: 0.5273, Valid Loss: 0.5815\n",
      "Validation loss improved to 0.5815\n",
      "Epoch [80/200], Train Loss: 0.5405, Valid Loss: 0.5761\n",
      "Validation loss improved to 0.5761\n",
      "Epoch [81/200], Train Loss: 0.5766, Valid Loss: 0.5702\n",
      "Validation loss improved to 0.5702\n",
      "Epoch [82/200], Train Loss: 0.5734, Valid Loss: 0.5634\n",
      "Validation loss improved to 0.5634\n",
      "Epoch [83/200], Train Loss: 0.5294, Valid Loss: 0.5547\n",
      "Validation loss improved to 0.5547\n",
      "Epoch [84/200], Train Loss: 0.5261, Valid Loss: 0.5449\n",
      "Validation loss improved to 0.5449\n",
      "Epoch [85/200], Train Loss: 0.4932, Valid Loss: 0.5347\n",
      "Validation loss improved to 0.5347\n",
      "Epoch [86/200], Train Loss: 0.5269, Valid Loss: 0.5252\n",
      "Validation loss improved to 0.5252\n",
      "Epoch [87/200], Train Loss: 0.5216, Valid Loss: 0.5168\n",
      "Validation loss improved to 0.5168\n",
      "Epoch [88/200], Train Loss: 0.4909, Valid Loss: 0.5094\n",
      "Validation loss improved to 0.5094\n",
      "Epoch [89/200], Train Loss: 0.4585, Valid Loss: 0.5019\n",
      "Validation loss improved to 0.5019\n",
      "Epoch [90/200], Train Loss: 0.4447, Valid Loss: 0.4941\n",
      "Validation loss improved to 0.4941\n",
      "Epoch [91/200], Train Loss: 0.4417, Valid Loss: 0.4872\n",
      "Validation loss improved to 0.4872\n",
      "Epoch [92/200], Train Loss: 0.4132, Valid Loss: 0.4780\n",
      "Validation loss improved to 0.4780\n",
      "Epoch [93/200], Train Loss: 0.4194, Valid Loss: 0.4694\n",
      "Validation loss improved to 0.4694\n",
      "Epoch [94/200], Train Loss: 0.4119, Valid Loss: 0.4612\n",
      "Validation loss improved to 0.4612\n",
      "Epoch [95/200], Train Loss: 0.3836, Valid Loss: 0.4523\n",
      "Validation loss improved to 0.4523\n",
      "Epoch [96/200], Train Loss: 0.4345, Valid Loss: 0.4448\n",
      "Validation loss improved to 0.4448\n",
      "Epoch [97/200], Train Loss: 0.4489, Valid Loss: 0.4393\n",
      "Validation loss improved to 0.4393\n",
      "Epoch [98/200], Train Loss: 0.3785, Valid Loss: 0.4352\n",
      "Validation loss improved to 0.4352\n",
      "Epoch [99/200], Train Loss: 0.3920, Valid Loss: 0.4304\n",
      "Validation loss improved to 0.4304\n",
      "Epoch [100/200], Train Loss: 0.3710, Valid Loss: 0.4256\n",
      "Validation loss improved to 0.4256\n",
      "Epoch [101/200], Train Loss: 0.4012, Valid Loss: 0.4185\n",
      "Validation loss improved to 0.4185\n",
      "Epoch [102/200], Train Loss: 0.3716, Valid Loss: 0.4120\n",
      "Validation loss improved to 0.4120\n",
      "Epoch [103/200], Train Loss: 0.3796, Valid Loss: 0.4064\n",
      "Validation loss improved to 0.4064\n",
      "Epoch [104/200], Train Loss: 0.3519, Valid Loss: 0.4024\n",
      "Validation loss improved to 0.4024\n",
      "Epoch [105/200], Train Loss: 0.3299, Valid Loss: 0.3972\n",
      "Validation loss improved to 0.3972\n",
      "Epoch [106/200], Train Loss: 0.3536, Valid Loss: 0.3947\n",
      "Validation loss improved to 0.3947\n",
      "Epoch [107/200], Train Loss: 0.3297, Valid Loss: 0.3937\n",
      "Validation loss improved to 0.3937\n",
      "Epoch [108/200], Train Loss: 0.3498, Valid Loss: 0.3921\n",
      "Validation loss improved to 0.3921\n",
      "Epoch [109/200], Train Loss: 0.2923, Valid Loss: 0.3866\n",
      "Validation loss improved to 0.3866\n",
      "Epoch [110/200], Train Loss: 0.2770, Valid Loss: 0.3783\n",
      "Validation loss improved to 0.3783\n",
      "Epoch [111/200], Train Loss: 0.3074, Valid Loss: 0.3690\n",
      "Validation loss improved to 0.3690\n",
      "Epoch [112/200], Train Loss: 0.3158, Valid Loss: 0.3604\n",
      "Validation loss improved to 0.3604\n",
      "Epoch [113/200], Train Loss: 0.3087, Valid Loss: 0.3552\n",
      "Validation loss improved to 0.3552\n",
      "Epoch [114/200], Train Loss: 0.2751, Valid Loss: 0.3528\n",
      "Validation loss improved to 0.3528\n",
      "Epoch [115/200], Train Loss: 0.3145, Valid Loss: 0.3554\n",
      "Epoch [116/200], Train Loss: 0.2580, Valid Loss: 0.3586\n",
      "Epoch [117/200], Train Loss: 0.2699, Valid Loss: 0.3572\n",
      "Epoch [118/200], Train Loss: 0.2889, Valid Loss: 0.3502\n",
      "Validation loss improved to 0.3502\n",
      "Epoch [119/200], Train Loss: 0.2614, Valid Loss: 0.3441\n",
      "Validation loss improved to 0.3441\n",
      "Epoch [120/200], Train Loss: 0.2368, Valid Loss: 0.3420\n",
      "Validation loss improved to 0.3420\n",
      "Epoch [121/200], Train Loss: 0.2361, Valid Loss: 0.3413\n",
      "Validation loss improved to 0.3413\n",
      "Epoch [122/200], Train Loss: 0.2225, Valid Loss: 0.3407\n",
      "Validation loss improved to 0.3407\n",
      "Epoch [123/200], Train Loss: 0.2363, Valid Loss: 0.3404\n",
      "Validation loss improved to 0.3404\n",
      "Epoch [124/200], Train Loss: 0.1950, Valid Loss: 0.3398\n",
      "Validation loss improved to 0.3398\n",
      "Epoch [125/200], Train Loss: 0.2219, Valid Loss: 0.3340\n",
      "Validation loss improved to 0.3340\n",
      "Epoch [126/200], Train Loss: 0.2163, Valid Loss: 0.3283\n",
      "Validation loss improved to 0.3283\n",
      "Epoch [127/200], Train Loss: 0.2330, Valid Loss: 0.3236\n",
      "Validation loss improved to 0.3236\n",
      "Epoch [128/200], Train Loss: 0.2216, Valid Loss: 0.3153\n",
      "Validation loss improved to 0.3153\n",
      "Epoch [129/200], Train Loss: 0.2383, Valid Loss: 0.3108\n",
      "Validation loss improved to 0.3108\n",
      "Epoch [130/200], Train Loss: 0.2029, Valid Loss: 0.3114\n",
      "Epoch [131/200], Train Loss: 0.2035, Valid Loss: 0.3152\n",
      "Epoch [132/200], Train Loss: 0.2069, Valid Loss: 0.3239\n",
      "Epoch [133/200], Train Loss: 0.1525, Valid Loss: 0.3286\n",
      "Epoch [134/200], Train Loss: 0.1919, Valid Loss: 0.3262\n",
      "Epoch [135/200], Train Loss: 0.1896, Valid Loss: 0.3211\n",
      "Epoch [136/200], Train Loss: 0.2016, Valid Loss: 0.3122\n",
      "Epoch [137/200], Train Loss: 0.2070, Valid Loss: 0.3078\n",
      "Validation loss improved to 0.3078\n",
      "Epoch [138/200], Train Loss: 0.1551, Valid Loss: 0.3087\n",
      "Epoch [139/200], Train Loss: 0.1806, Valid Loss: 0.3096\n",
      "Epoch [140/200], Train Loss: 0.1691, Valid Loss: 0.3117\n",
      "Epoch [141/200], Train Loss: 0.1633, Valid Loss: 0.3113\n",
      "Epoch [142/200], Train Loss: 0.1566, Valid Loss: 0.3130\n",
      "Epoch [143/200], Train Loss: 0.1816, Valid Loss: 0.3114\n",
      "Epoch [144/200], Train Loss: 0.1640, Valid Loss: 0.3035\n",
      "Validation loss improved to 0.3035\n",
      "Epoch [145/200], Train Loss: 0.1388, Valid Loss: 0.2963\n",
      "Validation loss improved to 0.2963\n",
      "Epoch [146/200], Train Loss: 0.1558, Valid Loss: 0.2895\n",
      "Validation loss improved to 0.2895\n",
      "Epoch [147/200], Train Loss: 0.1569, Valid Loss: 0.2882\n",
      "Validation loss improved to 0.2882\n",
      "Epoch [148/200], Train Loss: 0.1675, Valid Loss: 0.2867\n",
      "Validation loss improved to 0.2867\n",
      "Epoch [149/200], Train Loss: 0.1730, Valid Loss: 0.2924\n",
      "Epoch [150/200], Train Loss: 0.1203, Valid Loss: 0.2990\n",
      "Epoch [151/200], Train Loss: 0.1373, Valid Loss: 0.3028\n",
      "Epoch [152/200], Train Loss: 0.1469, Valid Loss: 0.2954\n",
      "Epoch [153/200], Train Loss: 0.1454, Valid Loss: 0.2840\n",
      "Validation loss improved to 0.2840\n",
      "Epoch [154/200], Train Loss: 0.1538, Valid Loss: 0.2782\n",
      "Validation loss improved to 0.2782\n",
      "Epoch [155/200], Train Loss: 0.1464, Valid Loss: 0.2803\n",
      "Epoch [156/200], Train Loss: 0.1306, Valid Loss: 0.2878\n",
      "Epoch [157/200], Train Loss: 0.1293, Valid Loss: 0.2940\n",
      "Epoch [158/200], Train Loss: 0.0997, Valid Loss: 0.2961\n",
      "Epoch [159/200], Train Loss: 0.1238, Valid Loss: 0.2978\n",
      "Epoch [160/200], Train Loss: 0.1331, Valid Loss: 0.2984\n",
      "Epoch [161/200], Train Loss: 0.1414, Valid Loss: 0.2979\n",
      "Epoch [162/200], Train Loss: 0.1384, Valid Loss: 0.2953\n",
      "Epoch [163/200], Train Loss: 0.1217, Valid Loss: 0.2916\n",
      "Epoch [164/200], Train Loss: 0.1190, Valid Loss: 0.2870\n",
      "Early stopping triggered at epoch 164\n",
      "Training completed. Final model saved as model/loss_0.2782_lr_0.0001_batch_64_opt_Adam.pt\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 200, 'learning_rate': 0.0001, 'optimizer': 'SGD'}\n",
      "Epoch [1/200], Train Loss: 1.3629, Valid Loss: 1.3897\n",
      "Validation loss improved to 1.3897\n",
      "Epoch [2/200], Train Loss: 1.3982, Valid Loss: 1.3896\n",
      "Validation loss improved to 1.3896\n",
      "Epoch [3/200], Train Loss: 1.4089, Valid Loss: 1.3895\n",
      "Validation loss improved to 1.3895\n",
      "Epoch [4/200], Train Loss: 1.3878, Valid Loss: 1.3894\n",
      "Validation loss improved to 1.3894\n",
      "Epoch [5/200], Train Loss: 1.3870, Valid Loss: 1.3893\n",
      "Validation loss improved to 1.3893\n",
      "Epoch [6/200], Train Loss: 1.4047, Valid Loss: 1.3891\n",
      "Validation loss improved to 1.3891\n",
      "Epoch [7/200], Train Loss: 1.3760, Valid Loss: 1.3889\n",
      "Validation loss improved to 1.3889\n",
      "Epoch [8/200], Train Loss: 1.4023, Valid Loss: 1.3887\n",
      "Validation loss improved to 1.3887\n",
      "Epoch [9/200], Train Loss: 1.3935, Valid Loss: 1.3885\n",
      "Validation loss improved to 1.3885\n",
      "Epoch [10/200], Train Loss: 1.3882, Valid Loss: 1.3882\n",
      "Validation loss improved to 1.3882\n",
      "Epoch [11/200], Train Loss: 1.3901, Valid Loss: 1.3880\n",
      "Validation loss improved to 1.3880\n",
      "Epoch [12/200], Train Loss: 1.3853, Valid Loss: 1.3877\n",
      "Validation loss improved to 1.3877\n",
      "Epoch [13/200], Train Loss: 1.3722, Valid Loss: 1.3874\n",
      "Validation loss improved to 1.3874\n",
      "Epoch [14/200], Train Loss: 1.4013, Valid Loss: 1.3872\n",
      "Validation loss improved to 1.3872\n",
      "Epoch [15/200], Train Loss: 1.3822, Valid Loss: 1.3869\n",
      "Validation loss improved to 1.3869\n",
      "Epoch [16/200], Train Loss: 1.3986, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [17/200], Train Loss: 1.3934, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [18/200], Train Loss: 1.3863, Valid Loss: 1.3860\n",
      "Validation loss improved to 1.3860\n",
      "Epoch [19/200], Train Loss: 1.3672, Valid Loss: 1.3857\n",
      "Validation loss improved to 1.3857\n",
      "Epoch [20/200], Train Loss: 1.3897, Valid Loss: 1.3853\n",
      "Validation loss improved to 1.3853\n",
      "Epoch [21/200], Train Loss: 1.3767, Valid Loss: 1.3850\n",
      "Validation loss improved to 1.3850\n",
      "Epoch [22/200], Train Loss: 1.3873, Valid Loss: 1.3847\n",
      "Validation loss improved to 1.3847\n",
      "Epoch [23/200], Train Loss: 1.3835, Valid Loss: 1.3844\n",
      "Validation loss improved to 1.3844\n",
      "Epoch [24/200], Train Loss: 1.3827, Valid Loss: 1.3841\n",
      "Validation loss improved to 1.3841\n",
      "Epoch [25/200], Train Loss: 1.3826, Valid Loss: 1.3838\n",
      "Validation loss improved to 1.3838\n",
      "Epoch [26/200], Train Loss: 1.3874, Valid Loss: 1.3834\n",
      "Validation loss improved to 1.3834\n",
      "Epoch [27/200], Train Loss: 1.3901, Valid Loss: 1.3831\n",
      "Validation loss improved to 1.3831\n",
      "Epoch [28/200], Train Loss: 1.3793, Valid Loss: 1.3828\n",
      "Validation loss improved to 1.3828\n",
      "Epoch [29/200], Train Loss: 1.3860, Valid Loss: 1.3825\n",
      "Validation loss improved to 1.3825\n",
      "Epoch [30/200], Train Loss: 1.4067, Valid Loss: 1.3821\n",
      "Validation loss improved to 1.3821\n",
      "Epoch [31/200], Train Loss: 1.3972, Valid Loss: 1.3818\n",
      "Validation loss improved to 1.3818\n",
      "Epoch [32/200], Train Loss: 1.3598, Valid Loss: 1.3815\n",
      "Validation loss improved to 1.3815\n",
      "Epoch [33/200], Train Loss: 1.3714, Valid Loss: 1.3812\n",
      "Validation loss improved to 1.3812\n",
      "Epoch [34/200], Train Loss: 1.3896, Valid Loss: 1.3808\n",
      "Validation loss improved to 1.3808\n",
      "Epoch [35/200], Train Loss: 1.3841, Valid Loss: 1.3805\n",
      "Validation loss improved to 1.3805\n",
      "Epoch [36/200], Train Loss: 1.3737, Valid Loss: 1.3802\n",
      "Validation loss improved to 1.3802\n",
      "Epoch [37/200], Train Loss: 1.3883, Valid Loss: 1.3799\n",
      "Validation loss improved to 1.3799\n",
      "Epoch [38/200], Train Loss: 1.3774, Valid Loss: 1.3795\n",
      "Validation loss improved to 1.3795\n",
      "Epoch [39/200], Train Loss: 1.3680, Valid Loss: 1.3792\n",
      "Validation loss improved to 1.3792\n",
      "Epoch [40/200], Train Loss: 1.4004, Valid Loss: 1.3789\n",
      "Validation loss improved to 1.3789\n",
      "Epoch [41/200], Train Loss: 1.3705, Valid Loss: 1.3786\n",
      "Validation loss improved to 1.3786\n",
      "Epoch [42/200], Train Loss: 1.3769, Valid Loss: 1.3782\n",
      "Validation loss improved to 1.3782\n",
      "Epoch [43/200], Train Loss: 1.3608, Valid Loss: 1.3779\n",
      "Validation loss improved to 1.3779\n",
      "Epoch [44/200], Train Loss: 1.3797, Valid Loss: 1.3776\n",
      "Validation loss improved to 1.3776\n",
      "Epoch [45/200], Train Loss: 1.3725, Valid Loss: 1.3773\n",
      "Validation loss improved to 1.3773\n",
      "Epoch [46/200], Train Loss: 1.3872, Valid Loss: 1.3769\n",
      "Validation loss improved to 1.3769\n",
      "Epoch [47/200], Train Loss: 1.3773, Valid Loss: 1.3766\n",
      "Validation loss improved to 1.3766\n",
      "Epoch [48/200], Train Loss: 1.3893, Valid Loss: 1.3763\n",
      "Validation loss improved to 1.3763\n",
      "Epoch [49/200], Train Loss: 1.3930, Valid Loss: 1.3759\n",
      "Validation loss improved to 1.3759\n",
      "Epoch [50/200], Train Loss: 1.3643, Valid Loss: 1.3756\n",
      "Validation loss improved to 1.3756\n",
      "Epoch [51/200], Train Loss: 1.3765, Valid Loss: 1.3753\n",
      "Validation loss improved to 1.3753\n",
      "Epoch [52/200], Train Loss: 1.3780, Valid Loss: 1.3750\n",
      "Validation loss improved to 1.3750\n",
      "Epoch [53/200], Train Loss: 1.3625, Valid Loss: 1.3747\n",
      "Validation loss improved to 1.3747\n",
      "Epoch [54/200], Train Loss: 1.3601, Valid Loss: 1.3744\n",
      "Validation loss improved to 1.3744\n",
      "Epoch [55/200], Train Loss: 1.3697, Valid Loss: 1.3741\n",
      "Validation loss improved to 1.3741\n",
      "Epoch [56/200], Train Loss: 1.3606, Valid Loss: 1.3737\n",
      "Validation loss improved to 1.3737\n",
      "Epoch [57/200], Train Loss: 1.3630, Valid Loss: 1.3734\n",
      "Validation loss improved to 1.3734\n",
      "Epoch [58/200], Train Loss: 1.3635, Valid Loss: 1.3731\n",
      "Validation loss improved to 1.3731\n",
      "Epoch [59/200], Train Loss: 1.3678, Valid Loss: 1.3728\n",
      "Validation loss improved to 1.3728\n",
      "Epoch [60/200], Train Loss: 1.3768, Valid Loss: 1.3725\n",
      "Validation loss improved to 1.3725\n",
      "Epoch [61/200], Train Loss: 1.3636, Valid Loss: 1.3722\n",
      "Validation loss improved to 1.3722\n",
      "Epoch [62/200], Train Loss: 1.3690, Valid Loss: 1.3719\n",
      "Validation loss improved to 1.3719\n",
      "Epoch [63/200], Train Loss: 1.3495, Valid Loss: 1.3716\n",
      "Validation loss improved to 1.3716\n",
      "Epoch [64/200], Train Loss: 1.3702, Valid Loss: 1.3713\n",
      "Validation loss improved to 1.3713\n",
      "Epoch [65/200], Train Loss: 1.3762, Valid Loss: 1.3710\n",
      "Validation loss improved to 1.3710\n",
      "Epoch [66/200], Train Loss: 1.3569, Valid Loss: 1.3707\n",
      "Validation loss improved to 1.3707\n",
      "Epoch [67/200], Train Loss: 1.3558, Valid Loss: 1.3704\n",
      "Validation loss improved to 1.3704\n",
      "Epoch [68/200], Train Loss: 1.3704, Valid Loss: 1.3701\n",
      "Validation loss improved to 1.3701\n",
      "Epoch [69/200], Train Loss: 1.3629, Valid Loss: 1.3698\n",
      "Validation loss improved to 1.3698\n",
      "Epoch [70/200], Train Loss: 1.3652, Valid Loss: 1.3695\n",
      "Validation loss improved to 1.3695\n",
      "Epoch [71/200], Train Loss: 1.3645, Valid Loss: 1.3693\n",
      "Validation loss improved to 1.3693\n",
      "Epoch [72/200], Train Loss: 1.3670, Valid Loss: 1.3690\n",
      "Validation loss improved to 1.3690\n",
      "Epoch [73/200], Train Loss: 1.3683, Valid Loss: 1.3687\n",
      "Validation loss improved to 1.3687\n",
      "Epoch [74/200], Train Loss: 1.3635, Valid Loss: 1.3684\n",
      "Validation loss improved to 1.3684\n",
      "Epoch [75/200], Train Loss: 1.3546, Valid Loss: 1.3681\n",
      "Validation loss improved to 1.3681\n",
      "Epoch [76/200], Train Loss: 1.3609, Valid Loss: 1.3678\n",
      "Validation loss improved to 1.3678\n",
      "Epoch [77/200], Train Loss: 1.3665, Valid Loss: 1.3676\n",
      "Validation loss improved to 1.3676\n",
      "Epoch [78/200], Train Loss: 1.3569, Valid Loss: 1.3673\n",
      "Validation loss improved to 1.3673\n",
      "Epoch [79/200], Train Loss: 1.3583, Valid Loss: 1.3670\n",
      "Validation loss improved to 1.3670\n",
      "Epoch [80/200], Train Loss: 1.3303, Valid Loss: 1.3667\n",
      "Validation loss improved to 1.3667\n",
      "Epoch [81/200], Train Loss: 1.3621, Valid Loss: 1.3664\n",
      "Validation loss improved to 1.3664\n",
      "Epoch [82/200], Train Loss: 1.3635, Valid Loss: 1.3662\n",
      "Validation loss improved to 1.3662\n",
      "Epoch [83/200], Train Loss: 1.3689, Valid Loss: 1.3659\n",
      "Validation loss improved to 1.3659\n",
      "Epoch [84/200], Train Loss: 1.3417, Valid Loss: 1.3656\n",
      "Validation loss improved to 1.3656\n",
      "Epoch [85/200], Train Loss: 1.3665, Valid Loss: 1.3653\n",
      "Validation loss improved to 1.3653\n",
      "Epoch [86/200], Train Loss: 1.3818, Valid Loss: 1.3651\n",
      "Validation loss improved to 1.3651\n",
      "Epoch [87/200], Train Loss: 1.3648, Valid Loss: 1.3648\n",
      "Validation loss improved to 1.3648\n",
      "Epoch [88/200], Train Loss: 1.3596, Valid Loss: 1.3645\n",
      "Validation loss improved to 1.3645\n",
      "Epoch [89/200], Train Loss: 1.3473, Valid Loss: 1.3642\n",
      "Validation loss improved to 1.3642\n",
      "Epoch [90/200], Train Loss: 1.3586, Valid Loss: 1.3639\n",
      "Validation loss improved to 1.3639\n",
      "Epoch [91/200], Train Loss: 1.3597, Valid Loss: 1.3637\n",
      "Validation loss improved to 1.3637\n",
      "Epoch [92/200], Train Loss: 1.3458, Valid Loss: 1.3634\n",
      "Validation loss improved to 1.3634\n",
      "Epoch [93/200], Train Loss: 1.3458, Valid Loss: 1.3631\n",
      "Validation loss improved to 1.3631\n",
      "Epoch [94/200], Train Loss: 1.3654, Valid Loss: 1.3628\n",
      "Validation loss improved to 1.3628\n",
      "Epoch [95/200], Train Loss: 1.3626, Valid Loss: 1.3625\n",
      "Validation loss improved to 1.3625\n",
      "Epoch [96/200], Train Loss: 1.3525, Valid Loss: 1.3622\n",
      "Validation loss improved to 1.3622\n",
      "Epoch [97/200], Train Loss: 1.3565, Valid Loss: 1.3619\n",
      "Validation loss improved to 1.3619\n",
      "Epoch [98/200], Train Loss: 1.3429, Valid Loss: 1.3617\n",
      "Validation loss improved to 1.3617\n",
      "Epoch [99/200], Train Loss: 1.3418, Valid Loss: 1.3614\n",
      "Validation loss improved to 1.3614\n",
      "Epoch [100/200], Train Loss: 1.3410, Valid Loss: 1.3611\n",
      "Validation loss improved to 1.3611\n",
      "Epoch [101/200], Train Loss: 1.3424, Valid Loss: 1.3608\n",
      "Validation loss improved to 1.3608\n",
      "Epoch [102/200], Train Loss: 1.3450, Valid Loss: 1.3606\n",
      "Validation loss improved to 1.3606\n",
      "Epoch [103/200], Train Loss: 1.3718, Valid Loss: 1.3603\n",
      "Validation loss improved to 1.3603\n",
      "Epoch [104/200], Train Loss: 1.3561, Valid Loss: 1.3600\n",
      "Validation loss improved to 1.3600\n",
      "Epoch [105/200], Train Loss: 1.3525, Valid Loss: 1.3598\n",
      "Validation loss improved to 1.3598\n",
      "Epoch [106/200], Train Loss: 1.3383, Valid Loss: 1.3595\n",
      "Validation loss improved to 1.3595\n",
      "Epoch [107/200], Train Loss: 1.3277, Valid Loss: 1.3592\n",
      "Validation loss improved to 1.3592\n",
      "Epoch [108/200], Train Loss: 1.3455, Valid Loss: 1.3590\n",
      "Validation loss improved to 1.3590\n",
      "Epoch [109/200], Train Loss: 1.3374, Valid Loss: 1.3587\n",
      "Validation loss improved to 1.3587\n",
      "Epoch [110/200], Train Loss: 1.3588, Valid Loss: 1.3584\n",
      "Validation loss improved to 1.3584\n",
      "Epoch [111/200], Train Loss: 1.3326, Valid Loss: 1.3582\n",
      "Validation loss improved to 1.3582\n",
      "Epoch [112/200], Train Loss: 1.3421, Valid Loss: 1.3579\n",
      "Validation loss improved to 1.3579\n",
      "Epoch [113/200], Train Loss: 1.3431, Valid Loss: 1.3577\n",
      "Validation loss improved to 1.3577\n",
      "Epoch [114/200], Train Loss: 1.3359, Valid Loss: 1.3574\n",
      "Validation loss improved to 1.3574\n",
      "Epoch [115/200], Train Loss: 1.3612, Valid Loss: 1.3572\n",
      "Validation loss improved to 1.3572\n",
      "Epoch [116/200], Train Loss: 1.3417, Valid Loss: 1.3569\n",
      "Validation loss improved to 1.3569\n",
      "Epoch [117/200], Train Loss: 1.3392, Valid Loss: 1.3567\n",
      "Validation loss improved to 1.3567\n",
      "Epoch [118/200], Train Loss: 1.3419, Valid Loss: 1.3565\n",
      "Validation loss improved to 1.3565\n",
      "Epoch [119/200], Train Loss: 1.3589, Valid Loss: 1.3562\n",
      "Validation loss improved to 1.3562\n",
      "Epoch [120/200], Train Loss: 1.3389, Valid Loss: 1.3560\n",
      "Validation loss improved to 1.3560\n",
      "Epoch [121/200], Train Loss: 1.3329, Valid Loss: 1.3557\n",
      "Validation loss improved to 1.3557\n",
      "Epoch [122/200], Train Loss: 1.3457, Valid Loss: 1.3555\n",
      "Validation loss improved to 1.3555\n",
      "Epoch [123/200], Train Loss: 1.3386, Valid Loss: 1.3552\n",
      "Validation loss improved to 1.3552\n",
      "Epoch [124/200], Train Loss: 1.3255, Valid Loss: 1.3550\n",
      "Validation loss improved to 1.3550\n",
      "Epoch [125/200], Train Loss: 1.3304, Valid Loss: 1.3548\n",
      "Validation loss improved to 1.3548\n",
      "Epoch [126/200], Train Loss: 1.3316, Valid Loss: 1.3545\n",
      "Validation loss improved to 1.3545\n",
      "Epoch [127/200], Train Loss: 1.3395, Valid Loss: 1.3543\n",
      "Validation loss improved to 1.3543\n",
      "Epoch [128/200], Train Loss: 1.3293, Valid Loss: 1.3540\n",
      "Validation loss improved to 1.3540\n",
      "Epoch [129/200], Train Loss: 1.3415, Valid Loss: 1.3538\n",
      "Validation loss improved to 1.3538\n",
      "Epoch [130/200], Train Loss: 1.3223, Valid Loss: 1.3535\n",
      "Validation loss improved to 1.3535\n",
      "Epoch [131/200], Train Loss: 1.3309, Valid Loss: 1.3533\n",
      "Validation loss improved to 1.3533\n",
      "Epoch [132/200], Train Loss: 1.3215, Valid Loss: 1.3530\n",
      "Validation loss improved to 1.3530\n",
      "Epoch [133/200], Train Loss: 1.3181, Valid Loss: 1.3528\n",
      "Validation loss improved to 1.3528\n",
      "Epoch [134/200], Train Loss: 1.3101, Valid Loss: 1.3525\n",
      "Validation loss improved to 1.3525\n",
      "Epoch [135/200], Train Loss: 1.3533, Valid Loss: 1.3523\n",
      "Validation loss improved to 1.3523\n",
      "Epoch [136/200], Train Loss: 1.3340, Valid Loss: 1.3520\n",
      "Validation loss improved to 1.3520\n",
      "Epoch [137/200], Train Loss: 1.3317, Valid Loss: 1.3517\n",
      "Validation loss improved to 1.3517\n",
      "Epoch [138/200], Train Loss: 1.3338, Valid Loss: 1.3515\n",
      "Validation loss improved to 1.3515\n",
      "Epoch [139/200], Train Loss: 1.3270, Valid Loss: 1.3512\n",
      "Validation loss improved to 1.3512\n",
      "Epoch [140/200], Train Loss: 1.3467, Valid Loss: 1.3510\n",
      "Validation loss improved to 1.3510\n",
      "Epoch [141/200], Train Loss: 1.3228, Valid Loss: 1.3507\n",
      "Validation loss improved to 1.3507\n",
      "Epoch [142/200], Train Loss: 1.3325, Valid Loss: 1.3505\n",
      "Validation loss improved to 1.3505\n",
      "Epoch [143/200], Train Loss: 1.3366, Valid Loss: 1.3502\n",
      "Validation loss improved to 1.3502\n",
      "Epoch [144/200], Train Loss: 1.3186, Valid Loss: 1.3500\n",
      "Validation loss improved to 1.3500\n",
      "Epoch [145/200], Train Loss: 1.3219, Valid Loss: 1.3497\n",
      "Validation loss improved to 1.3497\n",
      "Epoch [146/200], Train Loss: 1.3440, Valid Loss: 1.3494\n",
      "Validation loss improved to 1.3494\n",
      "Epoch [147/200], Train Loss: 1.3253, Valid Loss: 1.3492\n",
      "Validation loss improved to 1.3492\n",
      "Epoch [148/200], Train Loss: 1.3130, Valid Loss: 1.3489\n",
      "Validation loss improved to 1.3489\n",
      "Epoch [149/200], Train Loss: 1.3322, Valid Loss: 1.3487\n",
      "Validation loss improved to 1.3487\n",
      "Epoch [150/200], Train Loss: 1.3423, Valid Loss: 1.3484\n",
      "Validation loss improved to 1.3484\n",
      "Epoch [151/200], Train Loss: 1.3222, Valid Loss: 1.3482\n",
      "Validation loss improved to 1.3482\n",
      "Epoch [152/200], Train Loss: 1.3353, Valid Loss: 1.3479\n",
      "Validation loss improved to 1.3479\n",
      "Epoch [153/200], Train Loss: 1.3202, Valid Loss: 1.3477\n",
      "Validation loss improved to 1.3477\n",
      "Epoch [154/200], Train Loss: 1.3136, Valid Loss: 1.3474\n",
      "Validation loss improved to 1.3474\n",
      "Epoch [155/200], Train Loss: 1.3247, Valid Loss: 1.3471\n",
      "Validation loss improved to 1.3471\n",
      "Epoch [156/200], Train Loss: 1.3426, Valid Loss: 1.3469\n",
      "Validation loss improved to 1.3469\n",
      "Epoch [157/200], Train Loss: 1.3231, Valid Loss: 1.3466\n",
      "Validation loss improved to 1.3466\n",
      "Epoch [158/200], Train Loss: 1.3134, Valid Loss: 1.3464\n",
      "Validation loss improved to 1.3464\n",
      "Epoch [159/200], Train Loss: 1.3223, Valid Loss: 1.3461\n",
      "Validation loss improved to 1.3461\n",
      "Epoch [160/200], Train Loss: 1.3134, Valid Loss: 1.3459\n",
      "Validation loss improved to 1.3459\n",
      "Epoch [161/200], Train Loss: 1.3187, Valid Loss: 1.3456\n",
      "Validation loss improved to 1.3456\n",
      "Epoch [162/200], Train Loss: 1.3146, Valid Loss: 1.3454\n",
      "Validation loss improved to 1.3454\n",
      "Epoch [163/200], Train Loss: 1.3272, Valid Loss: 1.3451\n",
      "Validation loss improved to 1.3451\n",
      "Epoch [164/200], Train Loss: 1.3427, Valid Loss: 1.3448\n",
      "Validation loss improved to 1.3448\n",
      "Epoch [165/200], Train Loss: 1.3118, Valid Loss: 1.3446\n",
      "Validation loss improved to 1.3446\n",
      "Epoch [166/200], Train Loss: 1.3258, Valid Loss: 1.3443\n",
      "Validation loss improved to 1.3443\n",
      "Epoch [167/200], Train Loss: 1.3106, Valid Loss: 1.3441\n",
      "Validation loss improved to 1.3441\n",
      "Epoch [168/200], Train Loss: 1.3215, Valid Loss: 1.3438\n",
      "Validation loss improved to 1.3438\n",
      "Epoch [169/200], Train Loss: 1.2975, Valid Loss: 1.3436\n",
      "Validation loss improved to 1.3436\n",
      "Epoch [170/200], Train Loss: 1.3323, Valid Loss: 1.3433\n",
      "Validation loss improved to 1.3433\n",
      "Epoch [171/200], Train Loss: 1.3354, Valid Loss: 1.3430\n",
      "Validation loss improved to 1.3430\n",
      "Epoch [172/200], Train Loss: 1.3205, Valid Loss: 1.3428\n",
      "Validation loss improved to 1.3428\n",
      "Epoch [173/200], Train Loss: 1.3002, Valid Loss: 1.3425\n",
      "Validation loss improved to 1.3425\n",
      "Epoch [174/200], Train Loss: 1.3083, Valid Loss: 1.3423\n",
      "Validation loss improved to 1.3423\n",
      "Epoch [175/200], Train Loss: 1.3205, Valid Loss: 1.3420\n",
      "Validation loss improved to 1.3420\n",
      "Epoch [176/200], Train Loss: 1.3288, Valid Loss: 1.3417\n",
      "Validation loss improved to 1.3417\n",
      "Epoch [177/200], Train Loss: 1.3163, Valid Loss: 1.3415\n",
      "Validation loss improved to 1.3415\n",
      "Epoch [178/200], Train Loss: 1.3290, Valid Loss: 1.3412\n",
      "Validation loss improved to 1.3412\n",
      "Epoch [179/200], Train Loss: 1.3359, Valid Loss: 1.3410\n",
      "Validation loss improved to 1.3410\n",
      "Epoch [180/200], Train Loss: 1.2999, Valid Loss: 1.3407\n",
      "Validation loss improved to 1.3407\n",
      "Epoch [181/200], Train Loss: 1.3146, Valid Loss: 1.3404\n",
      "Validation loss improved to 1.3404\n",
      "Epoch [182/200], Train Loss: 1.3150, Valid Loss: 1.3402\n",
      "Validation loss improved to 1.3402\n",
      "Epoch [183/200], Train Loss: 1.3255, Valid Loss: 1.3399\n",
      "Validation loss improved to 1.3399\n",
      "Epoch [184/200], Train Loss: 1.3203, Valid Loss: 1.3397\n",
      "Validation loss improved to 1.3397\n",
      "Epoch [185/200], Train Loss: 1.3267, Valid Loss: 1.3394\n",
      "Validation loss improved to 1.3394\n",
      "Epoch [186/200], Train Loss: 1.3339, Valid Loss: 1.3392\n",
      "Validation loss improved to 1.3392\n",
      "Epoch [187/200], Train Loss: 1.3127, Valid Loss: 1.3389\n",
      "Validation loss improved to 1.3389\n",
      "Epoch [188/200], Train Loss: 1.3138, Valid Loss: 1.3387\n",
      "Validation loss improved to 1.3387\n",
      "Epoch [189/200], Train Loss: 1.3353, Valid Loss: 1.3384\n",
      "Validation loss improved to 1.3384\n",
      "Epoch [190/200], Train Loss: 1.3221, Valid Loss: 1.3382\n",
      "Validation loss improved to 1.3382\n",
      "Epoch [191/200], Train Loss: 1.3133, Valid Loss: 1.3379\n",
      "Validation loss improved to 1.3379\n",
      "Epoch [192/200], Train Loss: 1.3202, Valid Loss: 1.3377\n",
      "Validation loss improved to 1.3377\n",
      "Epoch [193/200], Train Loss: 1.3175, Valid Loss: 1.3374\n",
      "Validation loss improved to 1.3374\n",
      "Epoch [194/200], Train Loss: 1.3182, Valid Loss: 1.3372\n",
      "Validation loss improved to 1.3372\n",
      "Epoch [195/200], Train Loss: 1.2995, Valid Loss: 1.3369\n",
      "Validation loss improved to 1.3369\n",
      "Epoch [196/200], Train Loss: 1.3124, Valid Loss: 1.3366\n",
      "Validation loss improved to 1.3366\n",
      "Epoch [197/200], Train Loss: 1.3068, Valid Loss: 1.3364\n",
      "Validation loss improved to 1.3364\n",
      "Epoch [198/200], Train Loss: 1.3099, Valid Loss: 1.3361\n",
      "Validation loss improved to 1.3361\n",
      "Epoch [199/200], Train Loss: 1.2998, Valid Loss: 1.3359\n",
      "Validation loss improved to 1.3359\n",
      "Epoch [200/200], Train Loss: 1.3218, Valid Loss: 1.3356\n",
      "Validation loss improved to 1.3356\n",
      "Training completed. Final model saved as model/loss_1.3356_lr_0.0001_batch_64_opt_SGD.pt\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 200, 'learning_rate': 0.0001, 'optimizer': 'RMSprop'}\n",
      "Epoch [1/200], Train Loss: 1.4033, Valid Loss: 1.3390\n",
      "Validation loss improved to 1.3390\n",
      "Epoch [2/200], Train Loss: 1.3296, Valid Loss: 1.3340\n",
      "Validation loss improved to 1.3340\n",
      "Epoch [3/200], Train Loss: 1.2692, Valid Loss: 1.2977\n",
      "Validation loss improved to 1.2977\n",
      "Epoch [4/200], Train Loss: 1.2488, Valid Loss: 1.2695\n",
      "Validation loss improved to 1.2695\n",
      "Epoch [5/200], Train Loss: 1.2128, Valid Loss: 1.2503\n",
      "Validation loss improved to 1.2503\n",
      "Epoch [6/200], Train Loss: 1.1617, Valid Loss: 1.2047\n",
      "Validation loss improved to 1.2047\n",
      "Epoch [7/200], Train Loss: 1.1393, Valid Loss: 1.1725\n",
      "Validation loss improved to 1.1725\n",
      "Epoch [8/200], Train Loss: 1.0854, Valid Loss: 1.1206\n",
      "Validation loss improved to 1.1206\n",
      "Epoch [9/200], Train Loss: 1.1085, Valid Loss: 1.1445\n",
      "Epoch [10/200], Train Loss: 1.0821, Valid Loss: 1.1096\n",
      "Validation loss improved to 1.1096\n",
      "Epoch [11/200], Train Loss: 1.0751, Valid Loss: 1.0661\n",
      "Validation loss improved to 1.0661\n",
      "Epoch [12/200], Train Loss: 0.9765, Valid Loss: 1.0436\n",
      "Validation loss improved to 1.0436\n",
      "Epoch [13/200], Train Loss: 0.9888, Valid Loss: 1.0008\n",
      "Validation loss improved to 1.0008\n",
      "Epoch [14/200], Train Loss: 0.9529, Valid Loss: 0.9535\n",
      "Validation loss improved to 0.9535\n",
      "Epoch [15/200], Train Loss: 0.9039, Valid Loss: 0.9480\n",
      "Validation loss improved to 0.9480\n",
      "Epoch [16/200], Train Loss: 0.9106, Valid Loss: 0.9041\n",
      "Validation loss improved to 0.9041\n",
      "Epoch [17/200], Train Loss: 0.8743, Valid Loss: 0.8891\n",
      "Validation loss improved to 0.8891\n",
      "Epoch [18/200], Train Loss: 0.8675, Valid Loss: 0.8732\n",
      "Validation loss improved to 0.8732\n",
      "Epoch [19/200], Train Loss: 0.7979, Valid Loss: 0.8114\n",
      "Validation loss improved to 0.8114\n",
      "Epoch [20/200], Train Loss: 0.7822, Valid Loss: 0.8750\n",
      "Epoch [21/200], Train Loss: 0.7996, Valid Loss: 0.7722\n",
      "Validation loss improved to 0.7722\n",
      "Epoch [22/200], Train Loss: 0.7425, Valid Loss: 0.7489\n",
      "Validation loss improved to 0.7489\n",
      "Epoch [23/200], Train Loss: 0.6953, Valid Loss: 0.7313\n",
      "Validation loss improved to 0.7313\n",
      "Epoch [24/200], Train Loss: 0.6695, Valid Loss: 0.7120\n",
      "Validation loss improved to 0.7120\n",
      "Epoch [25/200], Train Loss: 0.6720, Valid Loss: 0.7093\n",
      "Validation loss improved to 0.7093\n",
      "Epoch [26/200], Train Loss: 0.6377, Valid Loss: 0.6993\n",
      "Validation loss improved to 0.6993\n",
      "Epoch [27/200], Train Loss: 0.7316, Valid Loss: 0.6715\n",
      "Validation loss improved to 0.6715\n",
      "Epoch [28/200], Train Loss: 0.6428, Valid Loss: 0.6174\n",
      "Validation loss improved to 0.6174\n",
      "Epoch [29/200], Train Loss: 0.6028, Valid Loss: 0.6779\n",
      "Epoch [30/200], Train Loss: 0.6271, Valid Loss: 0.5980\n",
      "Validation loss improved to 0.5980\n",
      "Epoch [31/200], Train Loss: 0.4915, Valid Loss: 0.5953\n",
      "Validation loss improved to 0.5953\n",
      "Epoch [32/200], Train Loss: 0.5615, Valid Loss: 0.5634\n",
      "Validation loss improved to 0.5634\n",
      "Epoch [33/200], Train Loss: 0.5393, Valid Loss: 0.5695\n",
      "Epoch [34/200], Train Loss: 0.5004, Valid Loss: 0.5570\n",
      "Validation loss improved to 0.5570\n",
      "Epoch [35/200], Train Loss: 0.5213, Valid Loss: 0.5944\n",
      "Epoch [36/200], Train Loss: 0.5467, Valid Loss: 0.5455\n",
      "Validation loss improved to 0.5455\n",
      "Epoch [37/200], Train Loss: 0.4871, Valid Loss: 0.5131\n",
      "Validation loss improved to 0.5131\n",
      "Epoch [38/200], Train Loss: 0.4509, Valid Loss: 0.4889\n",
      "Validation loss improved to 0.4889\n",
      "Epoch [39/200], Train Loss: 0.4383, Valid Loss: 0.4831\n",
      "Validation loss improved to 0.4831\n",
      "Epoch [40/200], Train Loss: 0.3868, Valid Loss: 0.4705\n",
      "Validation loss improved to 0.4705\n",
      "Epoch [41/200], Train Loss: 0.4371, Valid Loss: 0.4873\n",
      "Epoch [42/200], Train Loss: 0.3983, Valid Loss: 0.4757\n",
      "Epoch [43/200], Train Loss: 0.4523, Valid Loss: 0.4774\n",
      "Epoch [44/200], Train Loss: 0.3925, Valid Loss: 0.4415\n",
      "Validation loss improved to 0.4415\n",
      "Epoch [45/200], Train Loss: 0.3756, Valid Loss: 0.4416\n",
      "Epoch [46/200], Train Loss: 0.4129, Valid Loss: 0.4011\n",
      "Validation loss improved to 0.4011\n",
      "Epoch [47/200], Train Loss: 0.3602, Valid Loss: 0.4090\n",
      "Epoch [48/200], Train Loss: 0.3557, Valid Loss: 0.3887\n",
      "Validation loss improved to 0.3887\n",
      "Epoch [49/200], Train Loss: 0.3688, Valid Loss: 0.3909\n",
      "Epoch [50/200], Train Loss: 0.3440, Valid Loss: 0.4268\n",
      "Epoch [51/200], Train Loss: 0.3350, Valid Loss: 0.3728\n",
      "Validation loss improved to 0.3728\n",
      "Epoch [52/200], Train Loss: 0.3611, Valid Loss: 0.3899\n",
      "Epoch [53/200], Train Loss: 0.3107, Valid Loss: 0.3559\n",
      "Validation loss improved to 0.3559\n",
      "Epoch [54/200], Train Loss: 0.3186, Valid Loss: 0.3777\n",
      "Epoch [55/200], Train Loss: 0.3229, Valid Loss: 0.3398\n",
      "Validation loss improved to 0.3398\n",
      "Epoch [56/200], Train Loss: 0.2929, Valid Loss: 0.3633\n",
      "Epoch [57/200], Train Loss: 0.3115, Valid Loss: 0.3310\n",
      "Validation loss improved to 0.3310\n",
      "Epoch [58/200], Train Loss: 0.2624, Valid Loss: 0.3383\n",
      "Epoch [59/200], Train Loss: 0.2681, Valid Loss: 0.3237\n",
      "Validation loss improved to 0.3237\n",
      "Epoch [60/200], Train Loss: 0.2676, Valid Loss: 0.3555\n",
      "Epoch [61/200], Train Loss: 0.2840, Valid Loss: 0.3041\n",
      "Validation loss improved to 0.3041\n",
      "Epoch [62/200], Train Loss: 0.2743, Valid Loss: 0.3353\n",
      "Epoch [63/200], Train Loss: 0.2890, Valid Loss: 0.2901\n",
      "Validation loss improved to 0.2901\n",
      "Epoch [64/200], Train Loss: 0.2426, Valid Loss: 0.3471\n",
      "Epoch [65/200], Train Loss: 0.2704, Valid Loss: 0.3042\n",
      "Epoch [66/200], Train Loss: 0.2466, Valid Loss: 0.2962\n",
      "Epoch [67/200], Train Loss: 0.2466, Valid Loss: 0.2789\n",
      "Validation loss improved to 0.2789\n",
      "Epoch [68/200], Train Loss: 0.2093, Valid Loss: 0.3001\n",
      "Epoch [69/200], Train Loss: 0.2450, Valid Loss: 0.2738\n",
      "Validation loss improved to 0.2738\n",
      "Epoch [70/200], Train Loss: 0.2324, Valid Loss: 0.2696\n",
      "Validation loss improved to 0.2696\n",
      "Epoch [71/200], Train Loss: 0.2113, Valid Loss: 0.2767\n",
      "Epoch [72/200], Train Loss: 0.2099, Valid Loss: 0.2491\n",
      "Validation loss improved to 0.2491\n",
      "Epoch [73/200], Train Loss: 0.1865, Valid Loss: 0.2615\n",
      "Epoch [74/200], Train Loss: 0.1697, Valid Loss: 0.2575\n",
      "Epoch [75/200], Train Loss: 0.1891, Valid Loss: 0.2524\n",
      "Epoch [76/200], Train Loss: 0.1579, Valid Loss: 0.2505\n",
      "Epoch [77/200], Train Loss: 0.1343, Valid Loss: 0.2315\n",
      "Validation loss improved to 0.2315\n",
      "Epoch [78/200], Train Loss: 0.1396, Valid Loss: 0.2336\n",
      "Epoch [79/200], Train Loss: 0.1870, Valid Loss: 0.2244\n",
      "Validation loss improved to 0.2244\n",
      "Epoch [80/200], Train Loss: 0.1648, Valid Loss: 0.2383\n",
      "Epoch [81/200], Train Loss: 0.1850, Valid Loss: 0.2061\n",
      "Validation loss improved to 0.2061\n",
      "Epoch [82/200], Train Loss: 0.1728, Valid Loss: 0.2246\n",
      "Epoch [83/200], Train Loss: 0.1674, Valid Loss: 0.2200\n",
      "Epoch [84/200], Train Loss: 0.1469, Valid Loss: 0.2426\n",
      "Epoch [85/200], Train Loss: 0.1696, Valid Loss: 0.2132\n",
      "Epoch [86/200], Train Loss: 0.1174, Valid Loss: 0.2260\n",
      "Epoch [87/200], Train Loss: 0.1320, Valid Loss: 0.2069\n",
      "Epoch [88/200], Train Loss: 0.1644, Valid Loss: 0.2188\n",
      "Epoch [89/200], Train Loss: 0.1275, Valid Loss: 0.2033\n",
      "Validation loss improved to 0.2033\n",
      "Epoch [90/200], Train Loss: 0.1208, Valid Loss: 0.2015\n",
      "Validation loss improved to 0.2015\n",
      "Epoch [91/200], Train Loss: 0.1397, Valid Loss: 0.2042\n",
      "Epoch [92/200], Train Loss: 0.1688, Valid Loss: 0.1853\n",
      "Validation loss improved to 0.1853\n",
      "Epoch [93/200], Train Loss: 0.1476, Valid Loss: 0.2073\n",
      "Epoch [94/200], Train Loss: 0.1453, Valid Loss: 0.1944\n",
      "Epoch [95/200], Train Loss: 0.1479, Valid Loss: 0.1893\n",
      "Epoch [96/200], Train Loss: 0.1341, Valid Loss: 0.1976\n",
      "Epoch [97/200], Train Loss: 0.1206, Valid Loss: 0.1832\n",
      "Validation loss improved to 0.1832\n",
      "Epoch [98/200], Train Loss: 0.1258, Valid Loss: 0.1813\n",
      "Validation loss improved to 0.1813\n",
      "Epoch [99/200], Train Loss: 0.1294, Valid Loss: 0.2156\n",
      "Epoch [100/200], Train Loss: 0.1410, Valid Loss: 0.1937\n",
      "Epoch [101/200], Train Loss: 0.1379, Valid Loss: 0.1892\n",
      "Epoch [102/200], Train Loss: 0.1066, Valid Loss: 0.1919\n",
      "Epoch [103/200], Train Loss: 0.1482, Valid Loss: 0.1721\n",
      "Validation loss improved to 0.1721\n",
      "Epoch [104/200], Train Loss: 0.1193, Valid Loss: 0.1722\n",
      "Epoch [105/200], Train Loss: 0.1052, Valid Loss: 0.1916\n",
      "Epoch [106/200], Train Loss: 0.1215, Valid Loss: 0.1678\n",
      "Validation loss improved to 0.1678\n",
      "Epoch [107/200], Train Loss: 0.1022, Valid Loss: 0.1720\n",
      "Epoch [108/200], Train Loss: 0.1146, Valid Loss: 0.1689\n",
      "Epoch [109/200], Train Loss: 0.0921, Valid Loss: 0.1710\n",
      "Epoch [110/200], Train Loss: 0.1521, Valid Loss: 0.1673\n",
      "Validation loss improved to 0.1673\n",
      "Epoch [111/200], Train Loss: 0.1167, Valid Loss: 0.1886\n",
      "Epoch [112/200], Train Loss: 0.1111, Valid Loss: 0.1560\n",
      "Validation loss improved to 0.1560\n",
      "Epoch [113/200], Train Loss: 0.0799, Valid Loss: 0.1655\n",
      "Epoch [114/200], Train Loss: 0.1008, Valid Loss: 0.1589\n",
      "Epoch [115/200], Train Loss: 0.1205, Valid Loss: 0.1787\n",
      "Epoch [116/200], Train Loss: 0.0689, Valid Loss: 0.1697\n",
      "Epoch [117/200], Train Loss: 0.1011, Valid Loss: 0.1788\n",
      "Epoch [118/200], Train Loss: 0.1113, Valid Loss: 0.1507\n",
      "Validation loss improved to 0.1507\n",
      "Epoch [119/200], Train Loss: 0.0951, Valid Loss: 0.1595\n",
      "Epoch [120/200], Train Loss: 0.0742, Valid Loss: 0.1598\n",
      "Epoch [121/200], Train Loss: 0.0991, Valid Loss: 0.1515\n",
      "Epoch [122/200], Train Loss: 0.0672, Valid Loss: 0.1504\n",
      "Validation loss improved to 0.1504\n",
      "Epoch [123/200], Train Loss: 0.0690, Valid Loss: 0.1555\n",
      "Epoch [124/200], Train Loss: 0.0800, Valid Loss: 0.1499\n",
      "Validation loss improved to 0.1499\n",
      "Epoch [125/200], Train Loss: 0.0744, Valid Loss: 0.1566\n",
      "Epoch [126/200], Train Loss: 0.0942, Valid Loss: 0.1451\n",
      "Validation loss improved to 0.1451\n",
      "Epoch [127/200], Train Loss: 0.0771, Valid Loss: 0.1445\n",
      "Validation loss improved to 0.1445\n",
      "Epoch [128/200], Train Loss: 0.0747, Valid Loss: 0.1467\n",
      "Epoch [129/200], Train Loss: 0.0860, Valid Loss: 0.1523\n",
      "Epoch [130/200], Train Loss: 0.1154, Valid Loss: 0.1422\n",
      "Validation loss improved to 0.1422\n",
      "Epoch [131/200], Train Loss: 0.0931, Valid Loss: 0.1491\n",
      "Epoch [132/200], Train Loss: 0.0781, Valid Loss: 0.1438\n",
      "Epoch [133/200], Train Loss: 0.0500, Valid Loss: 0.1575\n",
      "Epoch [134/200], Train Loss: 0.0920, Valid Loss: 0.1347\n",
      "Validation loss improved to 0.1347\n",
      "Epoch [135/200], Train Loss: 0.0682, Valid Loss: 0.1614\n",
      "Epoch [136/200], Train Loss: 0.0564, Valid Loss: 0.1273\n",
      "Validation loss improved to 0.1273\n",
      "Epoch [137/200], Train Loss: 0.0721, Valid Loss: 0.1493\n",
      "Epoch [138/200], Train Loss: 0.0670, Valid Loss: 0.1420\n",
      "Epoch [139/200], Train Loss: 0.0879, Valid Loss: 0.1351\n",
      "Epoch [140/200], Train Loss: 0.0874, Valid Loss: 0.1397\n",
      "Epoch [141/200], Train Loss: 0.0687, Valid Loss: 0.1300\n",
      "Epoch [142/200], Train Loss: 0.0580, Valid Loss: 0.1216\n",
      "Validation loss improved to 0.1216\n",
      "Epoch [143/200], Train Loss: 0.0873, Valid Loss: 0.1387\n",
      "Epoch [144/200], Train Loss: 0.0662, Valid Loss: 0.1442\n",
      "Epoch [145/200], Train Loss: 0.0557, Valid Loss: 0.1327\n",
      "Epoch [146/200], Train Loss: 0.0573, Valid Loss: 0.1280\n",
      "Epoch [147/200], Train Loss: 0.0622, Valid Loss: 0.1292\n",
      "Epoch [148/200], Train Loss: 0.0474, Valid Loss: 0.1218\n",
      "Epoch [149/200], Train Loss: 0.0461, Valid Loss: 0.1317\n",
      "Epoch [150/200], Train Loss: 0.0571, Valid Loss: 0.1386\n",
      "Epoch [151/200], Train Loss: 0.0681, Valid Loss: 0.1225\n",
      "Epoch [152/200], Train Loss: 0.0468, Valid Loss: 0.1291\n",
      "Early stopping triggered at epoch 152\n",
      "Training completed. Final model saved as model/loss_0.1216_lr_0.0001_batch_64_opt_RMSprop.pt\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 200, 'learning_rate': 0.001, 'optimizer': 'Adam'}\n",
      "Epoch [1/200], Train Loss: 1.4021, Valid Loss: 1.3606\n",
      "Validation loss improved to 1.3606\n",
      "Epoch [2/200], Train Loss: 1.3445, Valid Loss: 1.3396\n",
      "Validation loss improved to 1.3396\n",
      "Epoch [3/200], Train Loss: 1.3108, Valid Loss: 1.3164\n",
      "Validation loss improved to 1.3164\n",
      "Epoch [4/200], Train Loss: 1.2879, Valid Loss: 1.2978\n",
      "Validation loss improved to 1.2978\n",
      "Epoch [5/200], Train Loss: 1.2337, Valid Loss: 1.2548\n",
      "Validation loss improved to 1.2548\n",
      "Epoch [6/200], Train Loss: 1.2201, Valid Loss: 1.2217\n",
      "Validation loss improved to 1.2217\n",
      "Epoch [7/200], Train Loss: 1.1488, Valid Loss: 1.2105\n",
      "Validation loss improved to 1.2105\n",
      "Epoch [8/200], Train Loss: 1.1538, Valid Loss: 1.1677\n",
      "Validation loss improved to 1.1677\n",
      "Epoch [9/200], Train Loss: 1.1162, Valid Loss: 1.1241\n",
      "Validation loss improved to 1.1241\n",
      "Epoch [10/200], Train Loss: 1.0617, Valid Loss: 1.0961\n",
      "Validation loss improved to 1.0961\n",
      "Epoch [11/200], Train Loss: 1.0220, Valid Loss: 1.0398\n",
      "Validation loss improved to 1.0398\n",
      "Epoch [12/200], Train Loss: 1.0080, Valid Loss: 0.9816\n",
      "Validation loss improved to 0.9816\n",
      "Epoch [13/200], Train Loss: 0.8867, Valid Loss: 0.9200\n",
      "Validation loss improved to 0.9200\n",
      "Epoch [14/200], Train Loss: 0.8576, Valid Loss: 0.8936\n",
      "Validation loss improved to 0.8936\n",
      "Epoch [15/200], Train Loss: 0.8267, Valid Loss: 0.8894\n",
      "Validation loss improved to 0.8894\n",
      "Epoch [16/200], Train Loss: 0.7710, Valid Loss: 0.8297\n",
      "Validation loss improved to 0.8297\n",
      "Epoch [17/200], Train Loss: 0.7479, Valid Loss: 0.7630\n",
      "Validation loss improved to 0.7630\n",
      "Epoch [18/200], Train Loss: 0.7739, Valid Loss: 0.7410\n",
      "Validation loss improved to 0.7410\n",
      "Epoch [19/200], Train Loss: 0.5894, Valid Loss: 0.6899\n",
      "Validation loss improved to 0.6899\n",
      "Epoch [20/200], Train Loss: 0.6165, Valid Loss: 0.6273\n",
      "Validation loss improved to 0.6273\n",
      "Epoch [21/200], Train Loss: 0.6218, Valid Loss: 0.6088\n",
      "Validation loss improved to 0.6088\n",
      "Epoch [22/200], Train Loss: 0.5045, Valid Loss: 0.5689\n",
      "Validation loss improved to 0.5689\n",
      "Epoch [23/200], Train Loss: 0.4587, Valid Loss: 0.4878\n",
      "Validation loss improved to 0.4878\n",
      "Epoch [24/200], Train Loss: 0.3927, Valid Loss: 0.4392\n",
      "Validation loss improved to 0.4392\n",
      "Epoch [25/200], Train Loss: 0.3989, Valid Loss: 0.4234\n",
      "Validation loss improved to 0.4234\n",
      "Epoch [26/200], Train Loss: 0.3806, Valid Loss: 0.3845\n",
      "Validation loss improved to 0.3845\n",
      "Epoch [27/200], Train Loss: 0.3295, Valid Loss: 0.3620\n",
      "Validation loss improved to 0.3620\n",
      "Epoch [28/200], Train Loss: 0.3008, Valid Loss: 0.3479\n",
      "Validation loss improved to 0.3479\n",
      "Epoch [29/200], Train Loss: 0.2383, Valid Loss: 0.3451\n",
      "Validation loss improved to 0.3451\n",
      "Epoch [30/200], Train Loss: 0.2242, Valid Loss: 0.3330\n",
      "Validation loss improved to 0.3330\n",
      "Epoch [31/200], Train Loss: 0.2299, Valid Loss: 0.3041\n",
      "Validation loss improved to 0.3041\n",
      "Epoch [32/200], Train Loss: 0.2055, Valid Loss: 0.2812\n",
      "Validation loss improved to 0.2812\n",
      "Epoch [33/200], Train Loss: 0.1687, Valid Loss: 0.2428\n",
      "Validation loss improved to 0.2428\n",
      "Epoch [34/200], Train Loss: 0.1451, Valid Loss: 0.1889\n",
      "Validation loss improved to 0.1889\n",
      "Epoch [35/200], Train Loss: 0.1560, Valid Loss: 0.1740\n",
      "Validation loss improved to 0.1740\n",
      "Epoch [36/200], Train Loss: 0.1275, Valid Loss: 0.1865\n",
      "Epoch [37/200], Train Loss: 0.1276, Valid Loss: 0.1766\n",
      "Epoch [38/200], Train Loss: 0.1261, Valid Loss: 0.1641\n",
      "Validation loss improved to 0.1641\n",
      "Epoch [39/200], Train Loss: 0.0924, Valid Loss: 0.1854\n",
      "Epoch [40/200], Train Loss: 0.0863, Valid Loss: 0.1799\n",
      "Epoch [41/200], Train Loss: 0.0581, Valid Loss: 0.1695\n",
      "Epoch [42/200], Train Loss: 0.1123, Valid Loss: 0.1432\n",
      "Validation loss improved to 0.1432\n",
      "Epoch [43/200], Train Loss: 0.0583, Valid Loss: 0.1246\n",
      "Validation loss improved to 0.1246\n",
      "Epoch [44/200], Train Loss: 0.0416, Valid Loss: 0.1130\n",
      "Validation loss improved to 0.1130\n",
      "Epoch [45/200], Train Loss: 0.0719, Valid Loss: 0.0916\n",
      "Validation loss improved to 0.0916\n",
      "Epoch [46/200], Train Loss: 0.0229, Valid Loss: 0.0713\n",
      "Validation loss improved to 0.0713\n",
      "Epoch [47/200], Train Loss: 0.0672, Valid Loss: 0.0702\n",
      "Validation loss improved to 0.0702\n",
      "Epoch [48/200], Train Loss: 0.0502, Valid Loss: 0.0918\n",
      "Epoch [49/200], Train Loss: 0.0404, Valid Loss: 0.0896\n",
      "Epoch [50/200], Train Loss: 0.0321, Valid Loss: 0.1180\n",
      "Epoch [51/200], Train Loss: 0.0729, Valid Loss: 0.0755\n",
      "Epoch [52/200], Train Loss: 0.0346, Valid Loss: 0.0781\n",
      "Epoch [53/200], Train Loss: 0.0393, Valid Loss: 0.0788\n",
      "Epoch [54/200], Train Loss: 0.0400, Valid Loss: 0.0714\n",
      "Epoch [55/200], Train Loss: 0.0401, Valid Loss: 0.0706\n",
      "Epoch [56/200], Train Loss: 0.0181, Valid Loss: 0.0709\n",
      "Epoch [57/200], Train Loss: 0.0179, Valid Loss: 0.0886\n",
      "Early stopping triggered at epoch 57\n",
      "Training completed. Final model saved as model/loss_0.0702_lr_0.001_batch_64_opt_Adam.pt\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 200, 'learning_rate': 0.001, 'optimizer': 'SGD'}\n",
      "Epoch [1/200], Train Loss: 1.3975, Valid Loss: 1.3945\n",
      "Validation loss improved to 1.3945\n",
      "Epoch [2/200], Train Loss: 1.3966, Valid Loss: 1.3941\n",
      "Validation loss improved to 1.3941\n",
      "Epoch [3/200], Train Loss: 1.3904, Valid Loss: 1.3936\n",
      "Validation loss improved to 1.3936\n",
      "Epoch [4/200], Train Loss: 1.3932, Valid Loss: 1.3929\n",
      "Validation loss improved to 1.3929\n",
      "Epoch [5/200], Train Loss: 1.3945, Valid Loss: 1.3920\n",
      "Validation loss improved to 1.3920\n",
      "Epoch [6/200], Train Loss: 1.3948, Valid Loss: 1.3910\n",
      "Validation loss improved to 1.3910\n",
      "Epoch [7/200], Train Loss: 1.3940, Valid Loss: 1.3899\n",
      "Validation loss improved to 1.3899\n",
      "Epoch [8/200], Train Loss: 1.3876, Valid Loss: 1.3887\n",
      "Validation loss improved to 1.3887\n",
      "Epoch [9/200], Train Loss: 1.3889, Valid Loss: 1.3873\n",
      "Validation loss improved to 1.3873\n",
      "Epoch [10/200], Train Loss: 1.3872, Valid Loss: 1.3860\n",
      "Validation loss improved to 1.3860\n",
      "Epoch [11/200], Train Loss: 1.3808, Valid Loss: 1.3845\n",
      "Validation loss improved to 1.3845\n",
      "Epoch [12/200], Train Loss: 1.3789, Valid Loss: 1.3830\n",
      "Validation loss improved to 1.3830\n",
      "Epoch [13/200], Train Loss: 1.3885, Valid Loss: 1.3816\n",
      "Validation loss improved to 1.3816\n",
      "Epoch [14/200], Train Loss: 1.3601, Valid Loss: 1.3803\n",
      "Validation loss improved to 1.3803\n",
      "Epoch [15/200], Train Loss: 1.3814, Valid Loss: 1.3789\n",
      "Validation loss improved to 1.3789\n",
      "Epoch [16/200], Train Loss: 1.3709, Valid Loss: 1.3775\n",
      "Validation loss improved to 1.3775\n",
      "Epoch [17/200], Train Loss: 1.3688, Valid Loss: 1.3761\n",
      "Validation loss improved to 1.3761\n",
      "Epoch [18/200], Train Loss: 1.3799, Valid Loss: 1.3748\n",
      "Validation loss improved to 1.3748\n",
      "Epoch [19/200], Train Loss: 1.3672, Valid Loss: 1.3735\n",
      "Validation loss improved to 1.3735\n",
      "Epoch [20/200], Train Loss: 1.3579, Valid Loss: 1.3722\n",
      "Validation loss improved to 1.3722\n",
      "Epoch [21/200], Train Loss: 1.3605, Valid Loss: 1.3709\n",
      "Validation loss improved to 1.3709\n",
      "Epoch [22/200], Train Loss: 1.3518, Valid Loss: 1.3697\n",
      "Validation loss improved to 1.3697\n",
      "Epoch [23/200], Train Loss: 1.3647, Valid Loss: 1.3685\n",
      "Validation loss improved to 1.3685\n",
      "Epoch [24/200], Train Loss: 1.3561, Valid Loss: 1.3673\n",
      "Validation loss improved to 1.3673\n",
      "Epoch [25/200], Train Loss: 1.3465, Valid Loss: 1.3660\n",
      "Validation loss improved to 1.3660\n",
      "Epoch [26/200], Train Loss: 1.3488, Valid Loss: 1.3648\n",
      "Validation loss improved to 1.3648\n",
      "Epoch [27/200], Train Loss: 1.3469, Valid Loss: 1.3636\n",
      "Validation loss improved to 1.3636\n",
      "Epoch [28/200], Train Loss: 1.3331, Valid Loss: 1.3624\n",
      "Validation loss improved to 1.3624\n",
      "Epoch [29/200], Train Loss: 1.3474, Valid Loss: 1.3612\n",
      "Validation loss improved to 1.3612\n",
      "Epoch [30/200], Train Loss: 1.3450, Valid Loss: 1.3601\n",
      "Validation loss improved to 1.3601\n",
      "Epoch [31/200], Train Loss: 1.3299, Valid Loss: 1.3589\n",
      "Validation loss improved to 1.3589\n",
      "Epoch [32/200], Train Loss: 1.3362, Valid Loss: 1.3578\n",
      "Validation loss improved to 1.3578\n",
      "Epoch [33/200], Train Loss: 1.3435, Valid Loss: 1.3567\n",
      "Validation loss improved to 1.3567\n",
      "Epoch [34/200], Train Loss: 1.3284, Valid Loss: 1.3557\n",
      "Validation loss improved to 1.3557\n",
      "Epoch [35/200], Train Loss: 1.3344, Valid Loss: 1.3546\n",
      "Validation loss improved to 1.3546\n",
      "Epoch [36/200], Train Loss: 1.3440, Valid Loss: 1.3535\n",
      "Validation loss improved to 1.3535\n",
      "Epoch [37/200], Train Loss: 1.3424, Valid Loss: 1.3524\n",
      "Validation loss improved to 1.3524\n",
      "Epoch [38/200], Train Loss: 1.3293, Valid Loss: 1.3514\n",
      "Validation loss improved to 1.3514\n",
      "Epoch [39/200], Train Loss: 1.3247, Valid Loss: 1.3504\n",
      "Validation loss improved to 1.3504\n",
      "Epoch [40/200], Train Loss: 1.3197, Valid Loss: 1.3493\n",
      "Validation loss improved to 1.3493\n",
      "Epoch [41/200], Train Loss: 1.3225, Valid Loss: 1.3483\n",
      "Validation loss improved to 1.3483\n",
      "Epoch [42/200], Train Loss: 1.3215, Valid Loss: 1.3472\n",
      "Validation loss improved to 1.3472\n",
      "Epoch [43/200], Train Loss: 1.3212, Valid Loss: 1.3461\n",
      "Validation loss improved to 1.3461\n",
      "Epoch [44/200], Train Loss: 1.3072, Valid Loss: 1.3450\n",
      "Validation loss improved to 1.3450\n",
      "Epoch [45/200], Train Loss: 1.3301, Valid Loss: 1.3439\n",
      "Validation loss improved to 1.3439\n",
      "Epoch [46/200], Train Loss: 1.3222, Valid Loss: 1.3428\n",
      "Validation loss improved to 1.3428\n",
      "Epoch [47/200], Train Loss: 1.3164, Valid Loss: 1.3416\n",
      "Validation loss improved to 1.3416\n",
      "Epoch [48/200], Train Loss: 1.3174, Valid Loss: 1.3405\n",
      "Validation loss improved to 1.3405\n",
      "Epoch [49/200], Train Loss: 1.3094, Valid Loss: 1.3394\n",
      "Validation loss improved to 1.3394\n",
      "Epoch [50/200], Train Loss: 1.3094, Valid Loss: 1.3382\n",
      "Validation loss improved to 1.3382\n",
      "Epoch [51/200], Train Loss: 1.3034, Valid Loss: 1.3370\n",
      "Validation loss improved to 1.3370\n",
      "Epoch [52/200], Train Loss: 1.2932, Valid Loss: 1.3358\n",
      "Validation loss improved to 1.3358\n",
      "Epoch [53/200], Train Loss: 1.2967, Valid Loss: 1.3347\n",
      "Validation loss improved to 1.3347\n",
      "Epoch [54/200], Train Loss: 1.3127, Valid Loss: 1.3335\n",
      "Validation loss improved to 1.3335\n",
      "Epoch [55/200], Train Loss: 1.3068, Valid Loss: 1.3324\n",
      "Validation loss improved to 1.3324\n",
      "Epoch [56/200], Train Loss: 1.3141, Valid Loss: 1.3312\n",
      "Validation loss improved to 1.3312\n",
      "Epoch [57/200], Train Loss: 1.2837, Valid Loss: 1.3300\n",
      "Validation loss improved to 1.3300\n",
      "Epoch [58/200], Train Loss: 1.2910, Valid Loss: 1.3287\n",
      "Validation loss improved to 1.3287\n",
      "Epoch [59/200], Train Loss: 1.2842, Valid Loss: 1.3274\n",
      "Validation loss improved to 1.3274\n",
      "Epoch [60/200], Train Loss: 1.2802, Valid Loss: 1.3261\n",
      "Validation loss improved to 1.3261\n",
      "Epoch [61/200], Train Loss: 1.2886, Valid Loss: 1.3248\n",
      "Validation loss improved to 1.3248\n",
      "Epoch [62/200], Train Loss: 1.2791, Valid Loss: 1.3235\n",
      "Validation loss improved to 1.3235\n",
      "Epoch [63/200], Train Loss: 1.2830, Valid Loss: 1.3221\n",
      "Validation loss improved to 1.3221\n",
      "Epoch [64/200], Train Loss: 1.2886, Valid Loss: 1.3208\n",
      "Validation loss improved to 1.3208\n",
      "Epoch [65/200], Train Loss: 1.2845, Valid Loss: 1.3194\n",
      "Validation loss improved to 1.3194\n",
      "Epoch [66/200], Train Loss: 1.2693, Valid Loss: 1.3180\n",
      "Validation loss improved to 1.3180\n",
      "Epoch [67/200], Train Loss: 1.2730, Valid Loss: 1.3165\n",
      "Validation loss improved to 1.3165\n",
      "Epoch [68/200], Train Loss: 1.2693, Valid Loss: 1.3151\n",
      "Validation loss improved to 1.3151\n",
      "Epoch [69/200], Train Loss: 1.2663, Valid Loss: 1.3136\n",
      "Validation loss improved to 1.3136\n",
      "Epoch [70/200], Train Loss: 1.2633, Valid Loss: 1.3121\n",
      "Validation loss improved to 1.3121\n",
      "Epoch [71/200], Train Loss: 1.2650, Valid Loss: 1.3105\n",
      "Validation loss improved to 1.3105\n",
      "Epoch [72/200], Train Loss: 1.2688, Valid Loss: 1.3090\n",
      "Validation loss improved to 1.3090\n",
      "Epoch [73/200], Train Loss: 1.2468, Valid Loss: 1.3074\n",
      "Validation loss improved to 1.3074\n",
      "Epoch [74/200], Train Loss: 1.2699, Valid Loss: 1.3059\n",
      "Validation loss improved to 1.3059\n",
      "Epoch [75/200], Train Loss: 1.2674, Valid Loss: 1.3043\n",
      "Validation loss improved to 1.3043\n",
      "Epoch [76/200], Train Loss: 1.2468, Valid Loss: 1.3027\n",
      "Validation loss improved to 1.3027\n",
      "Epoch [77/200], Train Loss: 1.2648, Valid Loss: 1.3011\n",
      "Validation loss improved to 1.3011\n",
      "Epoch [78/200], Train Loss: 1.2549, Valid Loss: 1.2995\n",
      "Validation loss improved to 1.2995\n",
      "Epoch [79/200], Train Loss: 1.2543, Valid Loss: 1.2978\n",
      "Validation loss improved to 1.2978\n",
      "Epoch [80/200], Train Loss: 1.2631, Valid Loss: 1.2961\n",
      "Validation loss improved to 1.2961\n",
      "Epoch [81/200], Train Loss: 1.2673, Valid Loss: 1.2944\n",
      "Validation loss improved to 1.2944\n",
      "Epoch [82/200], Train Loss: 1.2421, Valid Loss: 1.2927\n",
      "Validation loss improved to 1.2927\n",
      "Epoch [83/200], Train Loss: 1.2414, Valid Loss: 1.2909\n",
      "Validation loss improved to 1.2909\n",
      "Epoch [84/200], Train Loss: 1.2452, Valid Loss: 1.2891\n",
      "Validation loss improved to 1.2891\n",
      "Epoch [85/200], Train Loss: 1.2440, Valid Loss: 1.2872\n",
      "Validation loss improved to 1.2872\n",
      "Epoch [86/200], Train Loss: 1.2504, Valid Loss: 1.2853\n",
      "Validation loss improved to 1.2853\n",
      "Epoch [87/200], Train Loss: 1.2602, Valid Loss: 1.2834\n",
      "Validation loss improved to 1.2834\n",
      "Epoch [88/200], Train Loss: 1.2459, Valid Loss: 1.2815\n",
      "Validation loss improved to 1.2815\n",
      "Epoch [89/200], Train Loss: 1.2351, Valid Loss: 1.2796\n",
      "Validation loss improved to 1.2796\n",
      "Epoch [90/200], Train Loss: 1.2489, Valid Loss: 1.2777\n",
      "Validation loss improved to 1.2777\n",
      "Epoch [91/200], Train Loss: 1.2182, Valid Loss: 1.2757\n",
      "Validation loss improved to 1.2757\n",
      "Epoch [92/200], Train Loss: 1.1935, Valid Loss: 1.2737\n",
      "Validation loss improved to 1.2737\n",
      "Epoch [93/200], Train Loss: 1.2227, Valid Loss: 1.2715\n",
      "Validation loss improved to 1.2715\n",
      "Epoch [94/200], Train Loss: 1.2104, Valid Loss: 1.2693\n",
      "Validation loss improved to 1.2693\n",
      "Epoch [95/200], Train Loss: 1.2046, Valid Loss: 1.2671\n",
      "Validation loss improved to 1.2671\n",
      "Epoch [96/200], Train Loss: 1.2173, Valid Loss: 1.2649\n",
      "Validation loss improved to 1.2649\n",
      "Epoch [97/200], Train Loss: 1.2054, Valid Loss: 1.2626\n",
      "Validation loss improved to 1.2626\n",
      "Epoch [98/200], Train Loss: 1.2080, Valid Loss: 1.2603\n",
      "Validation loss improved to 1.2603\n",
      "Epoch [99/200], Train Loss: 1.2132, Valid Loss: 1.2578\n",
      "Validation loss improved to 1.2578\n",
      "Epoch [100/200], Train Loss: 1.1914, Valid Loss: 1.2554\n",
      "Validation loss improved to 1.2554\n",
      "Epoch [101/200], Train Loss: 1.2113, Valid Loss: 1.2530\n",
      "Validation loss improved to 1.2530\n",
      "Epoch [102/200], Train Loss: 1.1963, Valid Loss: 1.2506\n",
      "Validation loss improved to 1.2506\n",
      "Epoch [103/200], Train Loss: 1.1804, Valid Loss: 1.2481\n",
      "Validation loss improved to 1.2481\n",
      "Epoch [104/200], Train Loss: 1.2090, Valid Loss: 1.2457\n",
      "Validation loss improved to 1.2457\n",
      "Epoch [105/200], Train Loss: 1.1738, Valid Loss: 1.2431\n",
      "Validation loss improved to 1.2431\n",
      "Epoch [106/200], Train Loss: 1.1830, Valid Loss: 1.2405\n",
      "Validation loss improved to 1.2405\n",
      "Epoch [107/200], Train Loss: 1.2012, Valid Loss: 1.2378\n",
      "Validation loss improved to 1.2378\n",
      "Epoch [108/200], Train Loss: 1.1839, Valid Loss: 1.2351\n",
      "Validation loss improved to 1.2351\n",
      "Epoch [109/200], Train Loss: 1.1866, Valid Loss: 1.2323\n",
      "Validation loss improved to 1.2323\n",
      "Epoch [110/200], Train Loss: 1.1591, Valid Loss: 1.2295\n",
      "Validation loss improved to 1.2295\n",
      "Epoch [111/200], Train Loss: 1.1667, Valid Loss: 1.2267\n",
      "Validation loss improved to 1.2267\n",
      "Epoch [112/200], Train Loss: 1.1560, Valid Loss: 1.2239\n",
      "Validation loss improved to 1.2239\n",
      "Epoch [113/200], Train Loss: 1.1532, Valid Loss: 1.2211\n",
      "Validation loss improved to 1.2211\n",
      "Epoch [114/200], Train Loss: 1.1337, Valid Loss: 1.2182\n",
      "Validation loss improved to 1.2182\n",
      "Epoch [115/200], Train Loss: 1.1648, Valid Loss: 1.2153\n",
      "Validation loss improved to 1.2153\n",
      "Epoch [116/200], Train Loss: 1.1336, Valid Loss: 1.2124\n",
      "Validation loss improved to 1.2124\n",
      "Epoch [117/200], Train Loss: 1.1318, Valid Loss: 1.2094\n",
      "Validation loss improved to 1.2094\n",
      "Epoch [118/200], Train Loss: 1.1753, Valid Loss: 1.2064\n",
      "Validation loss improved to 1.2064\n",
      "Epoch [119/200], Train Loss: 1.1163, Valid Loss: 1.2032\n",
      "Validation loss improved to 1.2032\n",
      "Epoch [120/200], Train Loss: 1.1485, Valid Loss: 1.1999\n",
      "Validation loss improved to 1.1999\n",
      "Epoch [121/200], Train Loss: 1.1334, Valid Loss: 1.1966\n",
      "Validation loss improved to 1.1966\n",
      "Epoch [122/200], Train Loss: 1.1244, Valid Loss: 1.1932\n",
      "Validation loss improved to 1.1932\n",
      "Epoch [123/200], Train Loss: 1.1367, Valid Loss: 1.1897\n",
      "Validation loss improved to 1.1897\n",
      "Epoch [124/200], Train Loss: 1.1576, Valid Loss: 1.1862\n",
      "Validation loss improved to 1.1862\n",
      "Epoch [125/200], Train Loss: 1.1034, Valid Loss: 1.1826\n",
      "Validation loss improved to 1.1826\n",
      "Epoch [126/200], Train Loss: 1.1403, Valid Loss: 1.1789\n",
      "Validation loss improved to 1.1789\n",
      "Epoch [127/200], Train Loss: 1.1225, Valid Loss: 1.1751\n",
      "Validation loss improved to 1.1751\n",
      "Epoch [128/200], Train Loss: 1.1342, Valid Loss: 1.1714\n",
      "Validation loss improved to 1.1714\n",
      "Epoch [129/200], Train Loss: 1.1163, Valid Loss: 1.1676\n",
      "Validation loss improved to 1.1676\n",
      "Epoch [130/200], Train Loss: 1.1288, Valid Loss: 1.1638\n",
      "Validation loss improved to 1.1638\n",
      "Epoch [131/200], Train Loss: 1.0890, Valid Loss: 1.1600\n",
      "Validation loss improved to 1.1600\n",
      "Epoch [132/200], Train Loss: 1.0888, Valid Loss: 1.1561\n",
      "Validation loss improved to 1.1561\n",
      "Epoch [133/200], Train Loss: 1.1085, Valid Loss: 1.1523\n",
      "Validation loss improved to 1.1523\n",
      "Epoch [134/200], Train Loss: 1.0592, Valid Loss: 1.1484\n",
      "Validation loss improved to 1.1484\n",
      "Epoch [135/200], Train Loss: 1.1208, Valid Loss: 1.1445\n",
      "Validation loss improved to 1.1445\n",
      "Epoch [136/200], Train Loss: 1.0580, Valid Loss: 1.1405\n",
      "Validation loss improved to 1.1405\n",
      "Epoch [137/200], Train Loss: 1.1071, Valid Loss: 1.1364\n",
      "Validation loss improved to 1.1364\n",
      "Epoch [138/200], Train Loss: 1.1112, Valid Loss: 1.1324\n",
      "Validation loss improved to 1.1324\n",
      "Epoch [139/200], Train Loss: 1.0966, Valid Loss: 1.1285\n",
      "Validation loss improved to 1.1285\n",
      "Epoch [140/200], Train Loss: 1.0705, Valid Loss: 1.1245\n",
      "Validation loss improved to 1.1245\n",
      "Epoch [141/200], Train Loss: 1.0764, Valid Loss: 1.1205\n",
      "Validation loss improved to 1.1205\n",
      "Epoch [142/200], Train Loss: 1.0565, Valid Loss: 1.1164\n",
      "Validation loss improved to 1.1164\n",
      "Epoch [143/200], Train Loss: 1.0857, Valid Loss: 1.1123\n",
      "Validation loss improved to 1.1123\n",
      "Epoch [144/200], Train Loss: 1.0261, Valid Loss: 1.1082\n",
      "Validation loss improved to 1.1082\n",
      "Epoch [145/200], Train Loss: 1.0620, Valid Loss: 1.1042\n",
      "Validation loss improved to 1.1042\n",
      "Epoch [146/200], Train Loss: 1.0589, Valid Loss: 1.1003\n",
      "Validation loss improved to 1.1003\n",
      "Epoch [147/200], Train Loss: 1.0776, Valid Loss: 1.0963\n",
      "Validation loss improved to 1.0963\n",
      "Epoch [148/200], Train Loss: 1.0436, Valid Loss: 1.0922\n",
      "Validation loss improved to 1.0922\n",
      "Epoch [149/200], Train Loss: 1.0508, Valid Loss: 1.0879\n",
      "Validation loss improved to 1.0879\n",
      "Epoch [150/200], Train Loss: 1.0300, Valid Loss: 1.0837\n",
      "Validation loss improved to 1.0837\n",
      "Epoch [151/200], Train Loss: 1.0138, Valid Loss: 1.0792\n",
      "Validation loss improved to 1.0792\n",
      "Epoch [152/200], Train Loss: 1.0383, Valid Loss: 1.0746\n",
      "Validation loss improved to 1.0746\n",
      "Epoch [153/200], Train Loss: 1.0732, Valid Loss: 1.0700\n",
      "Validation loss improved to 1.0700\n",
      "Epoch [154/200], Train Loss: 0.9918, Valid Loss: 1.0654\n",
      "Validation loss improved to 1.0654\n",
      "Epoch [155/200], Train Loss: 1.0119, Valid Loss: 1.0607\n",
      "Validation loss improved to 1.0607\n",
      "Epoch [156/200], Train Loss: 1.0267, Valid Loss: 1.0560\n",
      "Validation loss improved to 1.0560\n",
      "Epoch [157/200], Train Loss: 0.9916, Valid Loss: 1.0513\n",
      "Validation loss improved to 1.0513\n",
      "Epoch [158/200], Train Loss: 1.0170, Valid Loss: 1.0467\n",
      "Validation loss improved to 1.0467\n",
      "Epoch [159/200], Train Loss: 0.9899, Valid Loss: 1.0421\n",
      "Validation loss improved to 1.0421\n",
      "Epoch [160/200], Train Loss: 0.9940, Valid Loss: 1.0375\n",
      "Validation loss improved to 1.0375\n",
      "Epoch [161/200], Train Loss: 1.0159, Valid Loss: 1.0328\n",
      "Validation loss improved to 1.0328\n",
      "Epoch [162/200], Train Loss: 1.0029, Valid Loss: 1.0282\n",
      "Validation loss improved to 1.0282\n",
      "Epoch [163/200], Train Loss: 0.9806, Valid Loss: 1.0235\n",
      "Validation loss improved to 1.0235\n",
      "Epoch [164/200], Train Loss: 0.9736, Valid Loss: 1.0188\n",
      "Validation loss improved to 1.0188\n",
      "Epoch [165/200], Train Loss: 0.9781, Valid Loss: 1.0141\n",
      "Validation loss improved to 1.0141\n",
      "Epoch [166/200], Train Loss: 0.9825, Valid Loss: 1.0095\n",
      "Validation loss improved to 1.0095\n",
      "Epoch [167/200], Train Loss: 0.9859, Valid Loss: 1.0048\n",
      "Validation loss improved to 1.0048\n",
      "Epoch [168/200], Train Loss: 0.9693, Valid Loss: 0.9998\n",
      "Validation loss improved to 0.9998\n",
      "Epoch [169/200], Train Loss: 0.9635, Valid Loss: 0.9947\n",
      "Validation loss improved to 0.9947\n",
      "Epoch [170/200], Train Loss: 0.9404, Valid Loss: 0.9894\n",
      "Validation loss improved to 0.9894\n",
      "Epoch [171/200], Train Loss: 0.9216, Valid Loss: 0.9841\n",
      "Validation loss improved to 0.9841\n",
      "Epoch [172/200], Train Loss: 0.9420, Valid Loss: 0.9789\n",
      "Validation loss improved to 0.9789\n",
      "Epoch [173/200], Train Loss: 0.9094, Valid Loss: 0.9737\n",
      "Validation loss improved to 0.9737\n",
      "Epoch [174/200], Train Loss: 0.8858, Valid Loss: 0.9684\n",
      "Validation loss improved to 0.9684\n",
      "Epoch [175/200], Train Loss: 0.9571, Valid Loss: 0.9634\n",
      "Validation loss improved to 0.9634\n",
      "Epoch [176/200], Train Loss: 0.9042, Valid Loss: 0.9583\n",
      "Validation loss improved to 0.9583\n",
      "Epoch [177/200], Train Loss: 0.8930, Valid Loss: 0.9532\n",
      "Validation loss improved to 0.9532\n",
      "Epoch [178/200], Train Loss: 0.9112, Valid Loss: 0.9482\n",
      "Validation loss improved to 0.9482\n",
      "Epoch [179/200], Train Loss: 0.9364, Valid Loss: 0.9433\n",
      "Validation loss improved to 0.9433\n",
      "Epoch [180/200], Train Loss: 0.9500, Valid Loss: 0.9384\n",
      "Validation loss improved to 0.9384\n",
      "Epoch [181/200], Train Loss: 0.8551, Valid Loss: 0.9335\n",
      "Validation loss improved to 0.9335\n",
      "Epoch [182/200], Train Loss: 0.9151, Valid Loss: 0.9290\n",
      "Validation loss improved to 0.9290\n",
      "Epoch [183/200], Train Loss: 0.9121, Valid Loss: 0.9247\n",
      "Validation loss improved to 0.9247\n",
      "Epoch [184/200], Train Loss: 0.8242, Valid Loss: 0.9201\n",
      "Validation loss improved to 0.9201\n",
      "Epoch [185/200], Train Loss: 0.8426, Valid Loss: 0.9151\n",
      "Validation loss improved to 0.9151\n",
      "Epoch [186/200], Train Loss: 0.8495, Valid Loss: 0.9100\n",
      "Validation loss improved to 0.9100\n",
      "Epoch [187/200], Train Loss: 0.8619, Valid Loss: 0.9046\n",
      "Validation loss improved to 0.9046\n",
      "Epoch [188/200], Train Loss: 0.8764, Valid Loss: 0.8991\n",
      "Validation loss improved to 0.8991\n",
      "Epoch [189/200], Train Loss: 0.8542, Valid Loss: 0.8935\n",
      "Validation loss improved to 0.8935\n",
      "Epoch [190/200], Train Loss: 0.8470, Valid Loss: 0.8878\n",
      "Validation loss improved to 0.8878\n",
      "Epoch [191/200], Train Loss: 0.8548, Valid Loss: 0.8822\n",
      "Validation loss improved to 0.8822\n",
      "Epoch [192/200], Train Loss: 0.8731, Valid Loss: 0.8767\n",
      "Validation loss improved to 0.8767\n",
      "Epoch [193/200], Train Loss: 0.8475, Valid Loss: 0.8713\n",
      "Validation loss improved to 0.8713\n",
      "Epoch [194/200], Train Loss: 0.8177, Valid Loss: 0.8659\n",
      "Validation loss improved to 0.8659\n",
      "Epoch [195/200], Train Loss: 0.8395, Valid Loss: 0.8606\n",
      "Validation loss improved to 0.8606\n",
      "Epoch [196/200], Train Loss: 0.8111, Valid Loss: 0.8553\n",
      "Validation loss improved to 0.8553\n",
      "Epoch [197/200], Train Loss: 0.8321, Valid Loss: 0.8501\n",
      "Validation loss improved to 0.8501\n",
      "Epoch [198/200], Train Loss: 0.8291, Valid Loss: 0.8450\n",
      "Validation loss improved to 0.8450\n",
      "Epoch [199/200], Train Loss: 0.7827, Valid Loss: 0.8399\n",
      "Validation loss improved to 0.8399\n",
      "Epoch [200/200], Train Loss: 0.8301, Valid Loss: 0.8352\n",
      "Validation loss improved to 0.8352\n",
      "Training completed. Final model saved as model/loss_0.8352_lr_0.001_batch_64_opt_SGD.pt\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 200, 'learning_rate': 0.001, 'optimizer': 'RMSprop'}\n",
      "Epoch [1/200], Train Loss: 1.3792, Valid Loss: 1.4081\n",
      "Validation loss improved to 1.4081\n",
      "Epoch [2/200], Train Loss: 1.4590, Valid Loss: 1.8365\n",
      "Epoch [3/200], Train Loss: 1.9076, Valid Loss: 1.3987\n",
      "Validation loss improved to 1.3987\n",
      "Epoch [4/200], Train Loss: 1.3826, Valid Loss: 1.4731\n",
      "Epoch [5/200], Train Loss: 1.5509, Valid Loss: 1.3601\n",
      "Validation loss improved to 1.3601\n",
      "Epoch [6/200], Train Loss: 1.4135, Valid Loss: 1.3185\n",
      "Validation loss improved to 1.3185\n",
      "Epoch [7/200], Train Loss: 1.3100, Valid Loss: 1.4964\n",
      "Epoch [8/200], Train Loss: 1.4711, Valid Loss: 1.3594\n",
      "Epoch [9/200], Train Loss: 1.3851, Valid Loss: 1.3348\n",
      "Epoch [10/200], Train Loss: 1.3286, Valid Loss: 1.3495\n",
      "Epoch [11/200], Train Loss: 1.3278, Valid Loss: 1.4663\n",
      "Epoch [12/200], Train Loss: 1.5052, Valid Loss: 1.3445\n",
      "Epoch [13/200], Train Loss: 1.3345, Valid Loss: 1.3017\n",
      "Validation loss improved to 1.3017\n",
      "Epoch [14/200], Train Loss: 1.2632, Valid Loss: 1.2746\n",
      "Validation loss improved to 1.2746\n",
      "Epoch [15/200], Train Loss: 1.3044, Valid Loss: 1.2834\n",
      "Epoch [16/200], Train Loss: 1.2429, Valid Loss: 1.2502\n",
      "Validation loss improved to 1.2502\n",
      "Epoch [17/200], Train Loss: 1.2220, Valid Loss: 1.2800\n",
      "Epoch [18/200], Train Loss: 1.2675, Valid Loss: 1.5254\n",
      "Epoch [19/200], Train Loss: 1.4602, Valid Loss: 1.4527\n",
      "Epoch [20/200], Train Loss: 1.3072, Valid Loss: 1.3304\n",
      "Epoch [21/200], Train Loss: 1.2420, Valid Loss: 1.2262\n",
      "Validation loss improved to 1.2262\n",
      "Epoch [22/200], Train Loss: 1.2101, Valid Loss: 1.2838\n",
      "Epoch [23/200], Train Loss: 1.2081, Valid Loss: 1.2298\n",
      "Epoch [24/200], Train Loss: 1.2154, Valid Loss: 1.3391\n",
      "Epoch [25/200], Train Loss: 1.3087, Valid Loss: 1.5922\n",
      "Epoch [26/200], Train Loss: 1.5383, Valid Loss: 1.3019\n",
      "Epoch [27/200], Train Loss: 1.4227, Valid Loss: 1.2629\n",
      "Epoch [28/200], Train Loss: 1.2506, Valid Loss: 1.2310\n",
      "Epoch [29/200], Train Loss: 1.2452, Valid Loss: 1.2679\n",
      "Epoch [30/200], Train Loss: 1.2939, Valid Loss: 1.3781\n",
      "Epoch [31/200], Train Loss: 1.2527, Valid Loss: 1.1914\n",
      "Validation loss improved to 1.1914\n",
      "Epoch [32/200], Train Loss: 1.1606, Valid Loss: 1.1290\n",
      "Validation loss improved to 1.1290\n",
      "Epoch [33/200], Train Loss: 1.1647, Valid Loss: 1.2418\n",
      "Epoch [34/200], Train Loss: 1.1732, Valid Loss: 1.1771\n",
      "Epoch [35/200], Train Loss: 1.1734, Valid Loss: 1.1053\n",
      "Validation loss improved to 1.1053\n",
      "Epoch [36/200], Train Loss: 1.1502, Valid Loss: 1.1292\n",
      "Epoch [37/200], Train Loss: 1.1058, Valid Loss: 1.1306\n",
      "Epoch [38/200], Train Loss: 1.0754, Valid Loss: 1.4783\n",
      "Epoch [39/200], Train Loss: 1.1515, Valid Loss: 1.3880\n",
      "Epoch [40/200], Train Loss: 1.1371, Valid Loss: 1.1705\n",
      "Epoch [41/200], Train Loss: 1.1112, Valid Loss: 1.3330\n",
      "Epoch [42/200], Train Loss: 1.1671, Valid Loss: 1.3124\n",
      "Epoch [43/200], Train Loss: 1.2922, Valid Loss: 1.2276\n",
      "Epoch [44/200], Train Loss: 1.0898, Valid Loss: 1.1714\n",
      "Epoch [45/200], Train Loss: 1.1251, Valid Loss: 1.3369\n",
      "Early stopping triggered at epoch 45\n",
      "Training completed. Final model saved as model/loss_1.1053_lr_0.001_batch_64_opt_RMSprop.pt\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 200, 'learning_rate': 0.01, 'optimizer': 'Adam'}\n",
      "Epoch [1/200], Train Loss: 1.3889, Valid Loss: 1.3871\n",
      "Validation loss improved to 1.3871\n",
      "Epoch [2/200], Train Loss: 1.4316, Valid Loss: 1.4167\n",
      "Epoch [3/200], Train Loss: 1.3884, Valid Loss: 1.5425\n",
      "Epoch [4/200], Train Loss: 1.6555, Valid Loss: 1.3748\n",
      "Validation loss improved to 1.3748\n",
      "Epoch [5/200], Train Loss: 1.4280, Valid Loss: 1.3882\n",
      "Epoch [6/200], Train Loss: 1.3859, Valid Loss: 1.3793\n",
      "Epoch [7/200], Train Loss: 1.3632, Valid Loss: 1.3581\n",
      "Validation loss improved to 1.3581\n",
      "Epoch [8/200], Train Loss: 1.3475, Valid Loss: 1.3335\n",
      "Validation loss improved to 1.3335\n",
      "Epoch [9/200], Train Loss: 1.3553, Valid Loss: 1.3377\n",
      "Epoch [10/200], Train Loss: 1.3496, Valid Loss: 1.3469\n",
      "Epoch [11/200], Train Loss: 1.3499, Valid Loss: 1.3470\n",
      "Epoch [12/200], Train Loss: 1.3193, Valid Loss: 1.3763\n",
      "Epoch [13/200], Train Loss: 1.3433, Valid Loss: 1.4926\n",
      "Epoch [14/200], Train Loss: 1.4058, Valid Loss: 1.4174\n",
      "Epoch [15/200], Train Loss: 1.3312, Valid Loss: 1.3798\n",
      "Epoch [16/200], Train Loss: 1.3559, Valid Loss: 1.3986\n",
      "Epoch [17/200], Train Loss: 1.3529, Valid Loss: 1.3900\n",
      "Epoch [18/200], Train Loss: 1.3150, Valid Loss: 1.4180\n",
      "Early stopping triggered at epoch 18\n",
      "Training completed. Final model saved as model/loss_1.3335_lr_0.01_batch_64_opt_Adam.pt\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 200, 'learning_rate': 0.01, 'optimizer': 'SGD'}\n",
      "Epoch [1/200], Train Loss: 1.3887, Valid Loss: 1.3915\n",
      "Validation loss improved to 1.3915\n",
      "Epoch [2/200], Train Loss: 1.3698, Valid Loss: 1.3847\n",
      "Validation loss improved to 1.3847\n",
      "Epoch [3/200], Train Loss: 1.3724, Valid Loss: 1.3759\n",
      "Validation loss improved to 1.3759\n",
      "Epoch [4/200], Train Loss: 1.3656, Valid Loss: 1.3662\n",
      "Validation loss improved to 1.3662\n",
      "Epoch [5/200], Train Loss: 1.3292, Valid Loss: 1.3561\n",
      "Validation loss improved to 1.3561\n",
      "Epoch [6/200], Train Loss: 1.3207, Valid Loss: 1.3453\n",
      "Validation loss improved to 1.3453\n",
      "Epoch [7/200], Train Loss: 1.3195, Valid Loss: 1.3344\n",
      "Validation loss improved to 1.3344\n",
      "Epoch [8/200], Train Loss: 1.3053, Valid Loss: 1.3233\n",
      "Validation loss improved to 1.3233\n",
      "Epoch [9/200], Train Loss: 1.2884, Valid Loss: 1.3123\n",
      "Validation loss improved to 1.3123\n",
      "Epoch [10/200], Train Loss: 1.2790, Valid Loss: 1.3018\n",
      "Validation loss improved to 1.3018\n",
      "Epoch [11/200], Train Loss: 1.2754, Valid Loss: 1.2915\n",
      "Validation loss improved to 1.2915\n",
      "Epoch [12/200], Train Loss: 1.2502, Valid Loss: 1.2806\n",
      "Validation loss improved to 1.2806\n",
      "Epoch [13/200], Train Loss: 1.2373, Valid Loss: 1.2690\n",
      "Validation loss improved to 1.2690\n",
      "Epoch [14/200], Train Loss: 1.2146, Valid Loss: 1.2570\n",
      "Validation loss improved to 1.2570\n",
      "Epoch [15/200], Train Loss: 1.2064, Valid Loss: 1.2442\n",
      "Validation loss improved to 1.2442\n",
      "Epoch [16/200], Train Loss: 1.1713, Valid Loss: 1.2300\n",
      "Validation loss improved to 1.2300\n",
      "Epoch [17/200], Train Loss: 1.1759, Valid Loss: 1.2150\n",
      "Validation loss improved to 1.2150\n",
      "Epoch [18/200], Train Loss: 1.1976, Valid Loss: 1.1998\n",
      "Validation loss improved to 1.1998\n",
      "Epoch [19/200], Train Loss: 1.1433, Valid Loss: 1.1837\n",
      "Validation loss improved to 1.1837\n",
      "Epoch [20/200], Train Loss: 1.1067, Valid Loss: 1.1664\n",
      "Validation loss improved to 1.1664\n",
      "Epoch [21/200], Train Loss: 1.1226, Valid Loss: 1.1472\n",
      "Validation loss improved to 1.1472\n",
      "Epoch [22/200], Train Loss: 1.1279, Valid Loss: 1.1263\n",
      "Validation loss improved to 1.1263\n",
      "Epoch [23/200], Train Loss: 1.0493, Valid Loss: 1.1033\n",
      "Validation loss improved to 1.1033\n",
      "Epoch [24/200], Train Loss: 1.0507, Valid Loss: 1.0806\n",
      "Validation loss improved to 1.0806\n",
      "Epoch [25/200], Train Loss: 1.0346, Valid Loss: 1.0568\n",
      "Validation loss improved to 1.0568\n",
      "Epoch [26/200], Train Loss: 1.0075, Valid Loss: 1.0321\n",
      "Validation loss improved to 1.0321\n",
      "Epoch [27/200], Train Loss: 1.0067, Valid Loss: 1.0053\n",
      "Validation loss improved to 1.0053\n",
      "Epoch [28/200], Train Loss: 0.9922, Valid Loss: 0.9779\n",
      "Validation loss improved to 0.9779\n",
      "Epoch [29/200], Train Loss: 0.9214, Valid Loss: 0.9494\n",
      "Validation loss improved to 0.9494\n",
      "Epoch [30/200], Train Loss: 0.8777, Valid Loss: 0.9189\n",
      "Validation loss improved to 0.9189\n",
      "Epoch [31/200], Train Loss: 0.8941, Valid Loss: 0.8870\n",
      "Validation loss improved to 0.8870\n",
      "Epoch [32/200], Train Loss: 0.8410, Valid Loss: 0.8535\n",
      "Validation loss improved to 0.8535\n",
      "Epoch [33/200], Train Loss: 0.8311, Valid Loss: 0.8200\n",
      "Validation loss improved to 0.8200\n",
      "Epoch [34/200], Train Loss: 0.8015, Valid Loss: 0.7845\n",
      "Validation loss improved to 0.7845\n",
      "Epoch [35/200], Train Loss: 0.7776, Valid Loss: 0.7474\n",
      "Validation loss improved to 0.7474\n",
      "Epoch [36/200], Train Loss: 0.7405, Valid Loss: 0.7114\n",
      "Validation loss improved to 0.7114\n",
      "Epoch [37/200], Train Loss: 0.6702, Valid Loss: 0.6755\n",
      "Validation loss improved to 0.6755\n",
      "Epoch [38/200], Train Loss: 0.7037, Valid Loss: 0.6398\n",
      "Validation loss improved to 0.6398\n",
      "Epoch [39/200], Train Loss: 0.6002, Valid Loss: 0.6058\n",
      "Validation loss improved to 0.6058\n",
      "Epoch [40/200], Train Loss: 0.5581, Valid Loss: 0.5748\n",
      "Validation loss improved to 0.5748\n",
      "Epoch [41/200], Train Loss: 0.4916, Valid Loss: 0.5460\n",
      "Validation loss improved to 0.5460\n",
      "Epoch [42/200], Train Loss: 0.6220, Valid Loss: 0.5146\n",
      "Validation loss improved to 0.5146\n",
      "Epoch [43/200], Train Loss: 0.5369, Valid Loss: 0.4856\n",
      "Validation loss improved to 0.4856\n",
      "Epoch [44/200], Train Loss: 0.5386, Valid Loss: 0.4563\n",
      "Validation loss improved to 0.4563\n",
      "Epoch [45/200], Train Loss: 0.5048, Valid Loss: 0.4281\n",
      "Validation loss improved to 0.4281\n",
      "Epoch [46/200], Train Loss: 0.4184, Valid Loss: 0.4012\n",
      "Validation loss improved to 0.4012\n",
      "Epoch [47/200], Train Loss: 0.4457, Valid Loss: 0.3806\n",
      "Validation loss improved to 0.3806\n",
      "Epoch [48/200], Train Loss: 0.3867, Valid Loss: 0.3633\n",
      "Validation loss improved to 0.3633\n",
      "Epoch [49/200], Train Loss: 0.3518, Valid Loss: 0.3433\n",
      "Validation loss improved to 0.3433\n",
      "Epoch [50/200], Train Loss: 0.3648, Valid Loss: 0.3235\n",
      "Validation loss improved to 0.3235\n",
      "Epoch [51/200], Train Loss: 0.3119, Valid Loss: 0.3010\n",
      "Validation loss improved to 0.3010\n",
      "Epoch [52/200], Train Loss: 0.3166, Valid Loss: 0.2738\n",
      "Validation loss improved to 0.2738\n",
      "Epoch [53/200], Train Loss: 0.3227, Valid Loss: 0.2496\n",
      "Validation loss improved to 0.2496\n",
      "Epoch [54/200], Train Loss: 0.2307, Valid Loss: 0.2322\n",
      "Validation loss improved to 0.2322\n",
      "Epoch [55/200], Train Loss: 0.2388, Valid Loss: 0.2231\n",
      "Validation loss improved to 0.2231\n",
      "Epoch [56/200], Train Loss: 0.2236, Valid Loss: 0.2193\n",
      "Validation loss improved to 0.2193\n",
      "Epoch [57/200], Train Loss: 0.2782, Valid Loss: 0.2136\n",
      "Validation loss improved to 0.2136\n",
      "Epoch [58/200], Train Loss: 0.1606, Valid Loss: 0.2010\n",
      "Validation loss improved to 0.2010\n",
      "Epoch [59/200], Train Loss: 0.2522, Valid Loss: 0.1855\n",
      "Validation loss improved to 0.1855\n",
      "Epoch [60/200], Train Loss: 0.1839, Valid Loss: 0.1712\n",
      "Validation loss improved to 0.1712\n",
      "Epoch [61/200], Train Loss: 0.1724, Valid Loss: 0.1578\n",
      "Validation loss improved to 0.1578\n",
      "Epoch [62/200], Train Loss: 0.1910, Valid Loss: 0.1557\n",
      "Validation loss improved to 0.1557\n",
      "Epoch [63/200], Train Loss: 0.1591, Valid Loss: 0.1560\n",
      "Epoch [64/200], Train Loss: 0.1624, Valid Loss: 0.1500\n",
      "Validation loss improved to 0.1500\n",
      "Epoch [65/200], Train Loss: 0.1364, Valid Loss: 0.1337\n",
      "Validation loss improved to 0.1337\n",
      "Epoch [66/200], Train Loss: 0.1391, Valid Loss: 0.1196\n",
      "Validation loss improved to 0.1196\n",
      "Epoch [67/200], Train Loss: 0.1067, Valid Loss: 0.1151\n",
      "Validation loss improved to 0.1151\n",
      "Epoch [68/200], Train Loss: 0.1182, Valid Loss: 0.1144\n",
      "Validation loss improved to 0.1144\n",
      "Epoch [69/200], Train Loss: 0.1279, Valid Loss: 0.1185\n",
      "Epoch [70/200], Train Loss: 0.0878, Valid Loss: 0.1300\n",
      "Epoch [71/200], Train Loss: 0.1114, Valid Loss: 0.1435\n",
      "Epoch [72/200], Train Loss: 0.0827, Valid Loss: 0.1484\n",
      "Epoch [73/200], Train Loss: 0.0968, Valid Loss: 0.1470\n",
      "Epoch [74/200], Train Loss: 0.0964, Valid Loss: 0.1302\n",
      "Epoch [75/200], Train Loss: 0.1147, Valid Loss: 0.1099\n",
      "Validation loss improved to 0.1099\n",
      "Epoch [76/200], Train Loss: 0.0562, Valid Loss: 0.0925\n",
      "Validation loss improved to 0.0925\n",
      "Epoch [77/200], Train Loss: 0.1260, Valid Loss: 0.0817\n",
      "Validation loss improved to 0.0817\n",
      "Epoch [78/200], Train Loss: 0.1279, Valid Loss: 0.0812\n",
      "Validation loss improved to 0.0812\n",
      "Epoch [79/200], Train Loss: 0.0749, Valid Loss: 0.0865\n",
      "Epoch [80/200], Train Loss: 0.0708, Valid Loss: 0.0957\n",
      "Epoch [81/200], Train Loss: 0.0489, Valid Loss: 0.1055\n",
      "Epoch [82/200], Train Loss: 0.0849, Valid Loss: 0.1137\n",
      "Epoch [83/200], Train Loss: 0.0422, Valid Loss: 0.1154\n",
      "Epoch [84/200], Train Loss: 0.0656, Valid Loss: 0.1148\n",
      "Epoch [85/200], Train Loss: 0.0759, Valid Loss: 0.1117\n",
      "Epoch [86/200], Train Loss: 0.0754, Valid Loss: 0.1061\n",
      "Epoch [87/200], Train Loss: 0.0736, Valid Loss: 0.0989\n",
      "Epoch [88/200], Train Loss: 0.0468, Valid Loss: 0.1006\n",
      "Early stopping triggered at epoch 88\n",
      "Training completed. Final model saved as model/loss_0.0812_lr_0.01_batch_64_opt_SGD.pt\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 200, 'learning_rate': 0.01, 'optimizer': 'RMSprop'}\n",
      "Epoch [1/200], Train Loss: 1.3844, Valid Loss: 2.8439\n",
      "Validation loss improved to 2.8439\n",
      "Epoch [2/200], Train Loss: 4.2098, Valid Loss: 17.0953\n",
      "Epoch [3/200], Train Loss: 16.4060, Valid Loss: 13.7700\n",
      "Epoch [4/200], Train Loss: 13.2497, Valid Loss: 6.7183\n",
      "Epoch [5/200], Train Loss: 6.8914, Valid Loss: 13.4121\n",
      "Epoch [6/200], Train Loss: 12.8386, Valid Loss: 2.5821\n",
      "Validation loss improved to 2.5821\n",
      "Epoch [7/200], Train Loss: 2.5834, Valid Loss: 1.4705\n",
      "Validation loss improved to 1.4705\n",
      "Epoch [8/200], Train Loss: 1.5788, Valid Loss: 1.3874\n",
      "Validation loss improved to 1.3874\n",
      "Epoch [9/200], Train Loss: 1.3965, Valid Loss: 1.3879\n",
      "Epoch [10/200], Train Loss: 1.3928, Valid Loss: 1.3889\n",
      "Epoch [11/200], Train Loss: 1.3918, Valid Loss: 1.3895\n",
      "Epoch [12/200], Train Loss: 1.3894, Valid Loss: 1.3880\n",
      "Epoch [13/200], Train Loss: 1.3913, Valid Loss: 1.3883\n",
      "Epoch [14/200], Train Loss: 1.3890, Valid Loss: 1.3880\n",
      "Epoch [15/200], Train Loss: 1.3934, Valid Loss: 1.3894\n",
      "Epoch [16/200], Train Loss: 1.3894, Valid Loss: 1.3891\n",
      "Epoch [17/200], Train Loss: 1.3891, Valid Loss: 1.3889\n",
      "Epoch [18/200], Train Loss: 1.3889, Valid Loss: 1.3887\n",
      "Early stopping triggered at epoch 18\n",
      "Training completed. Final model saved as model/loss_1.3874_lr_0.01_batch_64_opt_RMSprop.pt\n",
      "Training with parameters: {'batch_size': 128, 'epochs': 200, 'learning_rate': 0.0001, 'optimizer': 'Adam'}\n",
      "Epoch [1/200], Train Loss: 1.3752, Valid Loss: 1.3493\n",
      "Validation loss improved to 1.3493\n",
      "Epoch [2/200], Train Loss: 1.3381, Valid Loss: 1.3331\n",
      "Validation loss improved to 1.3331\n",
      "Epoch [3/200], Train Loss: 1.3401, Valid Loss: 1.3188\n",
      "Validation loss improved to 1.3188\n",
      "Epoch [4/200], Train Loss: 1.2966, Valid Loss: 1.3076\n",
      "Validation loss improved to 1.3076\n",
      "Epoch [5/200], Train Loss: 1.2863, Valid Loss: 1.2972\n",
      "Validation loss improved to 1.2972\n",
      "Epoch [6/200], Train Loss: 1.2863, Valid Loss: 1.2878\n",
      "Validation loss improved to 1.2878\n",
      "Epoch [7/200], Train Loss: 1.2461, Valid Loss: 1.2789\n",
      "Validation loss improved to 1.2789\n",
      "Epoch [8/200], Train Loss: 1.2427, Valid Loss: 1.2703\n",
      "Validation loss improved to 1.2703\n",
      "Epoch [9/200], Train Loss: 1.2440, Valid Loss: 1.2604\n",
      "Validation loss improved to 1.2604\n",
      "Epoch [10/200], Train Loss: 1.2198, Valid Loss: 1.2503\n",
      "Validation loss improved to 1.2503\n",
      "Epoch [11/200], Train Loss: 1.2196, Valid Loss: 1.2397\n",
      "Validation loss improved to 1.2397\n",
      "Epoch [12/200], Train Loss: 1.2046, Valid Loss: 1.2289\n",
      "Validation loss improved to 1.2289\n",
      "Epoch [13/200], Train Loss: 1.1830, Valid Loss: 1.2180\n",
      "Validation loss improved to 1.2180\n",
      "Epoch [14/200], Train Loss: 1.1784, Valid Loss: 1.2066\n",
      "Validation loss improved to 1.2066\n",
      "Epoch [15/200], Train Loss: 1.1784, Valid Loss: 1.1955\n",
      "Validation loss improved to 1.1955\n",
      "Epoch [16/200], Train Loss: 1.1586, Valid Loss: 1.1842\n",
      "Validation loss improved to 1.1842\n",
      "Epoch [17/200], Train Loss: 1.1357, Valid Loss: 1.1724\n",
      "Validation loss improved to 1.1724\n",
      "Epoch [18/200], Train Loss: 1.1177, Valid Loss: 1.1599\n",
      "Validation loss improved to 1.1599\n",
      "Epoch [19/200], Train Loss: 1.1144, Valid Loss: 1.1466\n",
      "Validation loss improved to 1.1466\n",
      "Epoch [20/200], Train Loss: 1.1289, Valid Loss: 1.1339\n",
      "Validation loss improved to 1.1339\n",
      "Epoch [21/200], Train Loss: 1.0908, Valid Loss: 1.1210\n",
      "Validation loss improved to 1.1210\n",
      "Epoch [22/200], Train Loss: 1.0921, Valid Loss: 1.1086\n",
      "Validation loss improved to 1.1086\n",
      "Epoch [23/200], Train Loss: 1.0453, Valid Loss: 1.0955\n",
      "Validation loss improved to 1.0955\n",
      "Epoch [24/200], Train Loss: 1.0909, Valid Loss: 1.0826\n",
      "Validation loss improved to 1.0826\n",
      "Epoch [25/200], Train Loss: 1.0742, Valid Loss: 1.0697\n",
      "Validation loss improved to 1.0697\n",
      "Epoch [26/200], Train Loss: 1.0451, Valid Loss: 1.0568\n",
      "Validation loss improved to 1.0568\n",
      "Epoch [27/200], Train Loss: 1.0171, Valid Loss: 1.0436\n",
      "Validation loss improved to 1.0436\n",
      "Epoch [28/200], Train Loss: 1.0015, Valid Loss: 1.0293\n",
      "Validation loss improved to 1.0293\n",
      "Epoch [29/200], Train Loss: 0.9779, Valid Loss: 1.0145\n",
      "Validation loss improved to 1.0145\n",
      "Epoch [30/200], Train Loss: 1.0142, Valid Loss: 1.0005\n",
      "Validation loss improved to 1.0005\n",
      "Epoch [31/200], Train Loss: 0.9822, Valid Loss: 0.9866\n",
      "Validation loss improved to 0.9866\n",
      "Epoch [32/200], Train Loss: 0.9618, Valid Loss: 0.9722\n",
      "Validation loss improved to 0.9722\n",
      "Epoch [33/200], Train Loss: 0.9329, Valid Loss: 0.9579\n",
      "Validation loss improved to 0.9579\n",
      "Epoch [34/200], Train Loss: 0.9849, Valid Loss: 0.9434\n",
      "Validation loss improved to 0.9434\n",
      "Epoch [35/200], Train Loss: 0.9335, Valid Loss: 0.9304\n",
      "Validation loss improved to 0.9304\n",
      "Epoch [36/200], Train Loss: 0.9264, Valid Loss: 0.9179\n",
      "Validation loss improved to 0.9179\n",
      "Epoch [37/200], Train Loss: 0.9045, Valid Loss: 0.9063\n",
      "Validation loss improved to 0.9063\n",
      "Epoch [38/200], Train Loss: 0.8961, Valid Loss: 0.8944\n",
      "Validation loss improved to 0.8944\n",
      "Epoch [39/200], Train Loss: 0.8515, Valid Loss: 0.8819\n",
      "Validation loss improved to 0.8819\n",
      "Epoch [40/200], Train Loss: 0.8702, Valid Loss: 0.8696\n",
      "Validation loss improved to 0.8696\n",
      "Epoch [41/200], Train Loss: 0.8377, Valid Loss: 0.8573\n",
      "Validation loss improved to 0.8573\n",
      "Epoch [42/200], Train Loss: 0.8159, Valid Loss: 0.8459\n",
      "Validation loss improved to 0.8459\n",
      "Epoch [43/200], Train Loss: 0.8474, Valid Loss: 0.8355\n",
      "Validation loss improved to 0.8355\n",
      "Epoch [44/200], Train Loss: 0.8098, Valid Loss: 0.8246\n",
      "Validation loss improved to 0.8246\n",
      "Epoch [45/200], Train Loss: 0.8002, Valid Loss: 0.8139\n",
      "Validation loss improved to 0.8139\n",
      "Epoch [46/200], Train Loss: 0.8231, Valid Loss: 0.8020\n",
      "Validation loss improved to 0.8020\n",
      "Epoch [47/200], Train Loss: 0.8035, Valid Loss: 0.7904\n",
      "Validation loss improved to 0.7904\n",
      "Epoch [48/200], Train Loss: 0.7672, Valid Loss: 0.7781\n",
      "Validation loss improved to 0.7781\n",
      "Epoch [49/200], Train Loss: 0.7885, Valid Loss: 0.7651\n",
      "Validation loss improved to 0.7651\n",
      "Epoch [50/200], Train Loss: 0.7605, Valid Loss: 0.7531\n",
      "Validation loss improved to 0.7531\n",
      "Epoch [51/200], Train Loss: 0.7405, Valid Loss: 0.7423\n",
      "Validation loss improved to 0.7423\n",
      "Epoch [52/200], Train Loss: 0.7400, Valid Loss: 0.7314\n",
      "Validation loss improved to 0.7314\n",
      "Epoch [53/200], Train Loss: 0.6775, Valid Loss: 0.7177\n",
      "Validation loss improved to 0.7177\n",
      "Epoch [54/200], Train Loss: 0.6996, Valid Loss: 0.7063\n",
      "Validation loss improved to 0.7063\n",
      "Epoch [55/200], Train Loss: 0.7224, Valid Loss: 0.6950\n",
      "Validation loss improved to 0.6950\n",
      "Epoch [56/200], Train Loss: 0.6855, Valid Loss: 0.6849\n",
      "Validation loss improved to 0.6849\n",
      "Epoch [57/200], Train Loss: 0.6515, Valid Loss: 0.6768\n",
      "Validation loss improved to 0.6768\n",
      "Epoch [58/200], Train Loss: 0.6740, Valid Loss: 0.6690\n",
      "Validation loss improved to 0.6690\n",
      "Epoch [59/200], Train Loss: 0.6303, Valid Loss: 0.6596\n",
      "Validation loss improved to 0.6596\n",
      "Epoch [60/200], Train Loss: 0.5921, Valid Loss: 0.6490\n",
      "Validation loss improved to 0.6490\n",
      "Epoch [61/200], Train Loss: 0.5967, Valid Loss: 0.6383\n",
      "Validation loss improved to 0.6383\n",
      "Epoch [62/200], Train Loss: 0.5959, Valid Loss: 0.6275\n",
      "Validation loss improved to 0.6275\n",
      "Epoch [63/200], Train Loss: 0.6422, Valid Loss: 0.6170\n",
      "Validation loss improved to 0.6170\n",
      "Epoch [64/200], Train Loss: 0.5748, Valid Loss: 0.6081\n",
      "Validation loss improved to 0.6081\n",
      "Epoch [65/200], Train Loss: 0.6218, Valid Loss: 0.5982\n",
      "Validation loss improved to 0.5982\n",
      "Epoch [66/200], Train Loss: 0.5855, Valid Loss: 0.5870\n",
      "Validation loss improved to 0.5870\n",
      "Epoch [67/200], Train Loss: 0.5501, Valid Loss: 0.5769\n",
      "Validation loss improved to 0.5769\n",
      "Epoch [68/200], Train Loss: 0.5811, Valid Loss: 0.5672\n",
      "Validation loss improved to 0.5672\n",
      "Epoch [69/200], Train Loss: 0.5685, Valid Loss: 0.5596\n",
      "Validation loss improved to 0.5596\n",
      "Epoch [70/200], Train Loss: 0.5933, Valid Loss: 0.5531\n",
      "Validation loss improved to 0.5531\n",
      "Epoch [71/200], Train Loss: 0.5266, Valid Loss: 0.5446\n",
      "Validation loss improved to 0.5446\n",
      "Epoch [72/200], Train Loss: 0.5418, Valid Loss: 0.5350\n",
      "Validation loss improved to 0.5350\n",
      "Epoch [73/200], Train Loss: 0.5678, Valid Loss: 0.5270\n",
      "Validation loss improved to 0.5270\n",
      "Epoch [74/200], Train Loss: 0.5384, Valid Loss: 0.5183\n",
      "Validation loss improved to 0.5183\n",
      "Epoch [75/200], Train Loss: 0.5084, Valid Loss: 0.5093\n",
      "Validation loss improved to 0.5093\n",
      "Epoch [76/200], Train Loss: 0.4553, Valid Loss: 0.5014\n",
      "Validation loss improved to 0.5014\n",
      "Epoch [77/200], Train Loss: 0.4917, Valid Loss: 0.4936\n",
      "Validation loss improved to 0.4936\n",
      "Epoch [78/200], Train Loss: 0.5359, Valid Loss: 0.4854\n",
      "Validation loss improved to 0.4854\n",
      "Epoch [79/200], Train Loss: 0.4557, Valid Loss: 0.4789\n",
      "Validation loss improved to 0.4789\n",
      "Epoch [80/200], Train Loss: 0.4629, Valid Loss: 0.4736\n",
      "Validation loss improved to 0.4736\n",
      "Epoch [81/200], Train Loss: 0.4250, Valid Loss: 0.4661\n",
      "Validation loss improved to 0.4661\n",
      "Epoch [82/200], Train Loss: 0.4459, Valid Loss: 0.4602\n",
      "Validation loss improved to 0.4602\n",
      "Epoch [83/200], Train Loss: 0.4279, Valid Loss: 0.4546\n",
      "Validation loss improved to 0.4546\n",
      "Epoch [84/200], Train Loss: 0.4390, Valid Loss: 0.4467\n",
      "Validation loss improved to 0.4467\n",
      "Epoch [85/200], Train Loss: 0.4175, Valid Loss: 0.4377\n",
      "Validation loss improved to 0.4377\n",
      "Epoch [86/200], Train Loss: 0.4321, Valid Loss: 0.4308\n",
      "Validation loss improved to 0.4308\n",
      "Epoch [87/200], Train Loss: 0.3627, Valid Loss: 0.4240\n",
      "Validation loss improved to 0.4240\n",
      "Epoch [88/200], Train Loss: 0.3618, Valid Loss: 0.4168\n",
      "Validation loss improved to 0.4168\n",
      "Epoch [89/200], Train Loss: 0.3743, Valid Loss: 0.4097\n",
      "Validation loss improved to 0.4097\n",
      "Epoch [90/200], Train Loss: 0.3797, Valid Loss: 0.4041\n",
      "Validation loss improved to 0.4041\n",
      "Epoch [91/200], Train Loss: 0.3530, Valid Loss: 0.3986\n",
      "Validation loss improved to 0.3986\n",
      "Epoch [92/200], Train Loss: 0.3817, Valid Loss: 0.3935\n",
      "Validation loss improved to 0.3935\n",
      "Epoch [93/200], Train Loss: 0.3802, Valid Loss: 0.3886\n",
      "Validation loss improved to 0.3886\n",
      "Epoch [94/200], Train Loss: 0.4049, Valid Loss: 0.3837\n",
      "Validation loss improved to 0.3837\n",
      "Epoch [95/200], Train Loss: 0.3369, Valid Loss: 0.3783\n",
      "Validation loss improved to 0.3783\n",
      "Epoch [96/200], Train Loss: 0.3782, Valid Loss: 0.3719\n",
      "Validation loss improved to 0.3719\n",
      "Epoch [97/200], Train Loss: 0.3463, Valid Loss: 0.3652\n",
      "Validation loss improved to 0.3652\n",
      "Epoch [98/200], Train Loss: 0.2956, Valid Loss: 0.3590\n",
      "Validation loss improved to 0.3590\n",
      "Epoch [99/200], Train Loss: 0.3083, Valid Loss: 0.3541\n",
      "Validation loss improved to 0.3541\n",
      "Epoch [100/200], Train Loss: 0.3027, Valid Loss: 0.3500\n",
      "Validation loss improved to 0.3500\n",
      "Epoch [101/200], Train Loss: 0.2936, Valid Loss: 0.3460\n",
      "Validation loss improved to 0.3460\n",
      "Epoch [102/200], Train Loss: 0.3163, Valid Loss: 0.3430\n",
      "Validation loss improved to 0.3430\n",
      "Epoch [103/200], Train Loss: 0.3693, Valid Loss: 0.3393\n",
      "Validation loss improved to 0.3393\n",
      "Epoch [104/200], Train Loss: 0.3142, Valid Loss: 0.3330\n",
      "Validation loss improved to 0.3330\n",
      "Epoch [105/200], Train Loss: 0.2778, Valid Loss: 0.3261\n",
      "Validation loss improved to 0.3261\n",
      "Epoch [106/200], Train Loss: 0.2673, Valid Loss: 0.3214\n",
      "Validation loss improved to 0.3214\n",
      "Epoch [107/200], Train Loss: 0.2545, Valid Loss: 0.3170\n",
      "Validation loss improved to 0.3170\n",
      "Epoch [108/200], Train Loss: 0.2523, Valid Loss: 0.3128\n",
      "Validation loss improved to 0.3128\n",
      "Epoch [109/200], Train Loss: 0.2308, Valid Loss: 0.3098\n",
      "Validation loss improved to 0.3098\n",
      "Epoch [110/200], Train Loss: 0.2981, Valid Loss: 0.3076\n",
      "Validation loss improved to 0.3076\n",
      "Epoch [111/200], Train Loss: 0.2311, Valid Loss: 0.3042\n",
      "Validation loss improved to 0.3042\n",
      "Epoch [112/200], Train Loss: 0.2728, Valid Loss: 0.2998\n",
      "Validation loss improved to 0.2998\n",
      "Epoch [113/200], Train Loss: 0.2833, Valid Loss: 0.2948\n",
      "Validation loss improved to 0.2948\n",
      "Epoch [114/200], Train Loss: 0.2238, Valid Loss: 0.2923\n",
      "Validation loss improved to 0.2923\n",
      "Epoch [115/200], Train Loss: 0.2291, Valid Loss: 0.2900\n",
      "Validation loss improved to 0.2900\n",
      "Epoch [116/200], Train Loss: 0.2507, Valid Loss: 0.2863\n",
      "Validation loss improved to 0.2863\n",
      "Epoch [117/200], Train Loss: 0.2195, Valid Loss: 0.2816\n",
      "Validation loss improved to 0.2816\n",
      "Epoch [118/200], Train Loss: 0.2132, Valid Loss: 0.2789\n",
      "Validation loss improved to 0.2789\n",
      "Epoch [119/200], Train Loss: 0.2472, Valid Loss: 0.2757\n",
      "Validation loss improved to 0.2757\n",
      "Epoch [120/200], Train Loss: 0.2107, Valid Loss: 0.2741\n",
      "Validation loss improved to 0.2741\n",
      "Epoch [121/200], Train Loss: 0.2409, Valid Loss: 0.2727\n",
      "Validation loss improved to 0.2727\n",
      "Epoch [122/200], Train Loss: 0.1875, Valid Loss: 0.2706\n",
      "Validation loss improved to 0.2706\n",
      "Epoch [123/200], Train Loss: 0.2064, Valid Loss: 0.2680\n",
      "Validation loss improved to 0.2680\n",
      "Epoch [124/200], Train Loss: 0.1881, Valid Loss: 0.2643\n",
      "Validation loss improved to 0.2643\n",
      "Epoch [125/200], Train Loss: 0.1808, Valid Loss: 0.2609\n",
      "Validation loss improved to 0.2609\n",
      "Epoch [126/200], Train Loss: 0.1886, Valid Loss: 0.2578\n",
      "Validation loss improved to 0.2578\n",
      "Epoch [127/200], Train Loss: 0.2257, Valid Loss: 0.2530\n",
      "Validation loss improved to 0.2530\n",
      "Epoch [128/200], Train Loss: 0.1710, Valid Loss: 0.2489\n",
      "Validation loss improved to 0.2489\n",
      "Epoch [129/200], Train Loss: 0.1726, Valid Loss: 0.2442\n",
      "Validation loss improved to 0.2442\n",
      "Epoch [130/200], Train Loss: 0.1758, Valid Loss: 0.2412\n",
      "Validation loss improved to 0.2412\n",
      "Epoch [131/200], Train Loss: 0.1773, Valid Loss: 0.2397\n",
      "Validation loss improved to 0.2397\n",
      "Epoch [132/200], Train Loss: 0.1649, Valid Loss: 0.2385\n",
      "Validation loss improved to 0.2385\n",
      "Epoch [133/200], Train Loss: 0.1687, Valid Loss: 0.2372\n",
      "Validation loss improved to 0.2372\n",
      "Epoch [134/200], Train Loss: 0.1614, Valid Loss: 0.2376\n",
      "Epoch [135/200], Train Loss: 0.1539, Valid Loss: 0.2377\n",
      "Epoch [136/200], Train Loss: 0.1311, Valid Loss: 0.2363\n",
      "Validation loss improved to 0.2363\n",
      "Epoch [137/200], Train Loss: 0.1558, Valid Loss: 0.2342\n",
      "Validation loss improved to 0.2342\n",
      "Epoch [138/200], Train Loss: 0.1643, Valid Loss: 0.2327\n",
      "Validation loss improved to 0.2327\n",
      "Epoch [139/200], Train Loss: 0.1498, Valid Loss: 0.2318\n",
      "Validation loss improved to 0.2318\n",
      "Epoch [140/200], Train Loss: 0.1513, Valid Loss: 0.2299\n",
      "Validation loss improved to 0.2299\n",
      "Epoch [141/200], Train Loss: 0.1923, Valid Loss: 0.2281\n",
      "Validation loss improved to 0.2281\n",
      "Epoch [142/200], Train Loss: 0.1334, Valid Loss: 0.2273\n",
      "Validation loss improved to 0.2273\n",
      "Epoch [143/200], Train Loss: 0.1205, Valid Loss: 0.2269\n",
      "Validation loss improved to 0.2269\n",
      "Epoch [144/200], Train Loss: 0.1490, Valid Loss: 0.2258\n",
      "Validation loss improved to 0.2258\n",
      "Epoch [145/200], Train Loss: 0.1448, Valid Loss: 0.2251\n",
      "Validation loss improved to 0.2251\n",
      "Epoch [146/200], Train Loss: 0.1039, Valid Loss: 0.2236\n",
      "Validation loss improved to 0.2236\n",
      "Epoch [147/200], Train Loss: 0.1264, Valid Loss: 0.2209\n",
      "Validation loss improved to 0.2209\n",
      "Epoch [148/200], Train Loss: 0.1253, Valid Loss: 0.2173\n",
      "Validation loss improved to 0.2173\n",
      "Epoch [149/200], Train Loss: 0.1150, Valid Loss: 0.2143\n",
      "Validation loss improved to 0.2143\n",
      "Epoch [150/200], Train Loss: 0.1245, Valid Loss: 0.2123\n",
      "Validation loss improved to 0.2123\n",
      "Epoch [151/200], Train Loss: 0.0905, Valid Loss: 0.2122\n",
      "Validation loss improved to 0.2122\n",
      "Epoch [152/200], Train Loss: 0.1101, Valid Loss: 0.2129\n",
      "Epoch [153/200], Train Loss: 0.1064, Valid Loss: 0.2136\n",
      "Epoch [154/200], Train Loss: 0.0982, Valid Loss: 0.2134\n",
      "Epoch [155/200], Train Loss: 0.0906, Valid Loss: 0.2106\n",
      "Validation loss improved to 0.2106\n",
      "Epoch [156/200], Train Loss: 0.1395, Valid Loss: 0.2053\n",
      "Validation loss improved to 0.2053\n",
      "Epoch [157/200], Train Loss: 0.1141, Valid Loss: 0.2024\n",
      "Validation loss improved to 0.2024\n",
      "Epoch [158/200], Train Loss: 0.0995, Valid Loss: 0.2023\n",
      "Validation loss improved to 0.2023\n",
      "Epoch [159/200], Train Loss: 0.0898, Valid Loss: 0.2049\n",
      "Epoch [160/200], Train Loss: 0.1012, Valid Loss: 0.2091\n",
      "Epoch [161/200], Train Loss: 0.1251, Valid Loss: 0.2124\n",
      "Epoch [162/200], Train Loss: 0.1095, Valid Loss: 0.2149\n",
      "Epoch [163/200], Train Loss: 0.0992, Valid Loss: 0.2152\n",
      "Epoch [164/200], Train Loss: 0.1117, Valid Loss: 0.2141\n",
      "Epoch [165/200], Train Loss: 0.0803, Valid Loss: 0.2108\n",
      "Epoch [166/200], Train Loss: 0.1105, Valid Loss: 0.2066\n",
      "Epoch [167/200], Train Loss: 0.1155, Valid Loss: 0.2036\n",
      "Epoch [168/200], Train Loss: 0.0975, Valid Loss: 0.2021\n",
      "Validation loss improved to 0.2021\n",
      "Epoch [169/200], Train Loss: 0.0700, Valid Loss: 0.2030\n",
      "Epoch [170/200], Train Loss: 0.0928, Valid Loss: 0.2042\n",
      "Epoch [171/200], Train Loss: 0.0900, Valid Loss: 0.2066\n",
      "Epoch [172/200], Train Loss: 0.0733, Valid Loss: 0.2094\n",
      "Epoch [173/200], Train Loss: 0.0935, Valid Loss: 0.2075\n",
      "Epoch [174/200], Train Loss: 0.0906, Valid Loss: 0.2042\n",
      "Epoch [175/200], Train Loss: 0.0744, Valid Loss: 0.2017\n",
      "Validation loss improved to 0.2017\n",
      "Epoch [176/200], Train Loss: 0.0857, Valid Loss: 0.2010\n",
      "Validation loss improved to 0.2010\n",
      "Epoch [177/200], Train Loss: 0.1066, Valid Loss: 0.2027\n",
      "Epoch [178/200], Train Loss: 0.0782, Valid Loss: 0.2062\n",
      "Epoch [179/200], Train Loss: 0.0561, Valid Loss: 0.2095\n",
      "Epoch [180/200], Train Loss: 0.0913, Valid Loss: 0.2114\n",
      "Epoch [181/200], Train Loss: 0.0841, Valid Loss: 0.2108\n",
      "Epoch [182/200], Train Loss: 0.0701, Valid Loss: 0.2088\n",
      "Epoch [183/200], Train Loss: 0.0884, Valid Loss: 0.2062\n",
      "Epoch [184/200], Train Loss: 0.0794, Valid Loss: 0.2036\n",
      "Epoch [185/200], Train Loss: 0.0651, Valid Loss: 0.2006\n",
      "Validation loss improved to 0.2006\n",
      "Epoch [186/200], Train Loss: 0.0534, Valid Loss: 0.1973\n",
      "Validation loss improved to 0.1973\n",
      "Epoch [187/200], Train Loss: 0.0666, Valid Loss: 0.1943\n",
      "Validation loss improved to 0.1943\n",
      "Epoch [188/200], Train Loss: 0.0745, Valid Loss: 0.1916\n",
      "Validation loss improved to 0.1916\n",
      "Epoch [189/200], Train Loss: 0.0961, Valid Loss: 0.1901\n",
      "Validation loss improved to 0.1901\n",
      "Epoch [190/200], Train Loss: 0.0565, Valid Loss: 0.1899\n",
      "Validation loss improved to 0.1899\n",
      "Epoch [191/200], Train Loss: 0.0631, Valid Loss: 0.1911\n",
      "Epoch [192/200], Train Loss: 0.0736, Valid Loss: 0.1950\n",
      "Epoch [193/200], Train Loss: 0.0777, Valid Loss: 0.2006\n",
      "Epoch [194/200], Train Loss: 0.0734, Valid Loss: 0.2049\n",
      "Epoch [195/200], Train Loss: 0.0682, Valid Loss: 0.2068\n",
      "Epoch [196/200], Train Loss: 0.0539, Valid Loss: 0.2091\n",
      "Epoch [197/200], Train Loss: 0.0617, Valid Loss: 0.2101\n",
      "Epoch [198/200], Train Loss: 0.0691, Valid Loss: 0.2100\n",
      "Epoch [199/200], Train Loss: 0.0625, Valid Loss: 0.2091\n",
      "Epoch [200/200], Train Loss: 0.0646, Valid Loss: 0.2081\n",
      "Early stopping triggered at epoch 200\n",
      "Training completed. Final model saved as model/loss_0.1899_lr_0.0001_batch_128_opt_Adam.pt\n",
      "Training with parameters: {'batch_size': 128, 'epochs': 200, 'learning_rate': 0.0001, 'optimizer': 'SGD'}\n",
      "Epoch [1/200], Train Loss: 1.3862, Valid Loss: 1.3737\n",
      "Validation loss improved to 1.3737\n",
      "Epoch [2/200], Train Loss: 1.3769, Valid Loss: 1.3737\n",
      "Validation loss improved to 1.3737\n",
      "Epoch [3/200], Train Loss: 1.3736, Valid Loss: 1.3736\n",
      "Validation loss improved to 1.3736\n",
      "Epoch [4/200], Train Loss: 1.3582, Valid Loss: 1.3735\n",
      "Validation loss improved to 1.3735\n",
      "Epoch [5/200], Train Loss: 1.3669, Valid Loss: 1.3734\n",
      "Validation loss improved to 1.3734\n",
      "Epoch [6/200], Train Loss: 1.3629, Valid Loss: 1.3732\n",
      "Validation loss improved to 1.3732\n",
      "Epoch [7/200], Train Loss: 1.3761, Valid Loss: 1.3730\n",
      "Validation loss improved to 1.3730\n",
      "Epoch [8/200], Train Loss: 1.3755, Valid Loss: 1.3729\n",
      "Validation loss improved to 1.3729\n",
      "Epoch [9/200], Train Loss: 1.3751, Valid Loss: 1.3727\n",
      "Validation loss improved to 1.3727\n",
      "Epoch [10/200], Train Loss: 1.3764, Valid Loss: 1.3725\n",
      "Validation loss improved to 1.3725\n",
      "Epoch [11/200], Train Loss: 1.3785, Valid Loss: 1.3723\n",
      "Validation loss improved to 1.3723\n",
      "Epoch [12/200], Train Loss: 1.3656, Valid Loss: 1.3720\n",
      "Validation loss improved to 1.3720\n",
      "Epoch [13/200], Train Loss: 1.3727, Valid Loss: 1.3718\n",
      "Validation loss improved to 1.3718\n",
      "Epoch [14/200], Train Loss: 1.3850, Valid Loss: 1.3716\n",
      "Validation loss improved to 1.3716\n",
      "Epoch [15/200], Train Loss: 1.3712, Valid Loss: 1.3713\n",
      "Validation loss improved to 1.3713\n",
      "Epoch [16/200], Train Loss: 1.3679, Valid Loss: 1.3711\n",
      "Validation loss improved to 1.3711\n",
      "Epoch [17/200], Train Loss: 1.3659, Valid Loss: 1.3708\n",
      "Validation loss improved to 1.3708\n",
      "Epoch [18/200], Train Loss: 1.3625, Valid Loss: 1.3705\n",
      "Validation loss improved to 1.3705\n",
      "Epoch [19/200], Train Loss: 1.3713, Valid Loss: 1.3703\n",
      "Validation loss improved to 1.3703\n",
      "Epoch [20/200], Train Loss: 1.3649, Valid Loss: 1.3700\n",
      "Validation loss improved to 1.3700\n",
      "Epoch [21/200], Train Loss: 1.3566, Valid Loss: 1.3697\n",
      "Validation loss improved to 1.3697\n",
      "Epoch [22/200], Train Loss: 1.3735, Valid Loss: 1.3695\n",
      "Validation loss improved to 1.3695\n",
      "Epoch [23/200], Train Loss: 1.3779, Valid Loss: 1.3692\n",
      "Validation loss improved to 1.3692\n",
      "Epoch [24/200], Train Loss: 1.3595, Valid Loss: 1.3689\n",
      "Validation loss improved to 1.3689\n",
      "Epoch [25/200], Train Loss: 1.3707, Valid Loss: 1.3687\n",
      "Validation loss improved to 1.3687\n",
      "Epoch [26/200], Train Loss: 1.3660, Valid Loss: 1.3684\n",
      "Validation loss improved to 1.3684\n",
      "Epoch [27/200], Train Loss: 1.3798, Valid Loss: 1.3681\n",
      "Validation loss improved to 1.3681\n",
      "Epoch [28/200], Train Loss: 1.3779, Valid Loss: 1.3678\n",
      "Validation loss improved to 1.3678\n",
      "Epoch [29/200], Train Loss: 1.3674, Valid Loss: 1.3676\n",
      "Validation loss improved to 1.3676\n",
      "Epoch [30/200], Train Loss: 1.3608, Valid Loss: 1.3673\n",
      "Validation loss improved to 1.3673\n",
      "Epoch [31/200], Train Loss: 1.3666, Valid Loss: 1.3670\n",
      "Validation loss improved to 1.3670\n",
      "Epoch [32/200], Train Loss: 1.3731, Valid Loss: 1.3667\n",
      "Validation loss improved to 1.3667\n",
      "Epoch [33/200], Train Loss: 1.3705, Valid Loss: 1.3665\n",
      "Validation loss improved to 1.3665\n",
      "Epoch [34/200], Train Loss: 1.3660, Valid Loss: 1.3662\n",
      "Validation loss improved to 1.3662\n",
      "Epoch [35/200], Train Loss: 1.3724, Valid Loss: 1.3659\n",
      "Validation loss improved to 1.3659\n",
      "Epoch [36/200], Train Loss: 1.3782, Valid Loss: 1.3656\n",
      "Validation loss improved to 1.3656\n",
      "Epoch [37/200], Train Loss: 1.3833, Valid Loss: 1.3654\n",
      "Validation loss improved to 1.3654\n",
      "Epoch [38/200], Train Loss: 1.3701, Valid Loss: 1.3651\n",
      "Validation loss improved to 1.3651\n",
      "Epoch [39/200], Train Loss: 1.3662, Valid Loss: 1.3648\n",
      "Validation loss improved to 1.3648\n",
      "Epoch [40/200], Train Loss: 1.3736, Valid Loss: 1.3646\n",
      "Validation loss improved to 1.3646\n",
      "Epoch [41/200], Train Loss: 1.3569, Valid Loss: 1.3643\n",
      "Validation loss improved to 1.3643\n",
      "Epoch [42/200], Train Loss: 1.3798, Valid Loss: 1.3640\n",
      "Validation loss improved to 1.3640\n",
      "Epoch [43/200], Train Loss: 1.3554, Valid Loss: 1.3637\n",
      "Validation loss improved to 1.3637\n",
      "Epoch [44/200], Train Loss: 1.3538, Valid Loss: 1.3634\n",
      "Validation loss improved to 1.3634\n",
      "Epoch [45/200], Train Loss: 1.3784, Valid Loss: 1.3632\n",
      "Validation loss improved to 1.3632\n",
      "Epoch [46/200], Train Loss: 1.3600, Valid Loss: 1.3629\n",
      "Validation loss improved to 1.3629\n",
      "Epoch [47/200], Train Loss: 1.3495, Valid Loss: 1.3626\n",
      "Validation loss improved to 1.3626\n",
      "Epoch [48/200], Train Loss: 1.3831, Valid Loss: 1.3623\n",
      "Validation loss improved to 1.3623\n",
      "Epoch [49/200], Train Loss: 1.3562, Valid Loss: 1.3620\n",
      "Validation loss improved to 1.3620\n",
      "Epoch [50/200], Train Loss: 1.3579, Valid Loss: 1.3618\n",
      "Validation loss improved to 1.3618\n",
      "Epoch [51/200], Train Loss: 1.3498, Valid Loss: 1.3615\n",
      "Validation loss improved to 1.3615\n",
      "Epoch [52/200], Train Loss: 1.3574, Valid Loss: 1.3612\n",
      "Validation loss improved to 1.3612\n",
      "Epoch [53/200], Train Loss: 1.3625, Valid Loss: 1.3609\n",
      "Validation loss improved to 1.3609\n",
      "Epoch [54/200], Train Loss: 1.3590, Valid Loss: 1.3606\n",
      "Validation loss improved to 1.3606\n",
      "Epoch [55/200], Train Loss: 1.3519, Valid Loss: 1.3604\n",
      "Validation loss improved to 1.3604\n",
      "Epoch [56/200], Train Loss: 1.3509, Valid Loss: 1.3601\n",
      "Validation loss improved to 1.3601\n",
      "Epoch [57/200], Train Loss: 1.3413, Valid Loss: 1.3599\n",
      "Validation loss improved to 1.3599\n",
      "Epoch [58/200], Train Loss: 1.3609, Valid Loss: 1.3596\n",
      "Validation loss improved to 1.3596\n",
      "Epoch [59/200], Train Loss: 1.3564, Valid Loss: 1.3594\n",
      "Validation loss improved to 1.3594\n",
      "Epoch [60/200], Train Loss: 1.3693, Valid Loss: 1.3591\n",
      "Validation loss improved to 1.3591\n",
      "Epoch [61/200], Train Loss: 1.3687, Valid Loss: 1.3589\n",
      "Validation loss improved to 1.3589\n",
      "Epoch [62/200], Train Loss: 1.3575, Valid Loss: 1.3586\n",
      "Validation loss improved to 1.3586\n",
      "Epoch [63/200], Train Loss: 1.3687, Valid Loss: 1.3584\n",
      "Validation loss improved to 1.3584\n",
      "Epoch [64/200], Train Loss: 1.3663, Valid Loss: 1.3582\n",
      "Validation loss improved to 1.3582\n",
      "Epoch [65/200], Train Loss: 1.3632, Valid Loss: 1.3579\n",
      "Validation loss improved to 1.3579\n",
      "Epoch [66/200], Train Loss: 1.3689, Valid Loss: 1.3577\n",
      "Validation loss improved to 1.3577\n",
      "Epoch [67/200], Train Loss: 1.3501, Valid Loss: 1.3574\n",
      "Validation loss improved to 1.3574\n",
      "Epoch [68/200], Train Loss: 1.3571, Valid Loss: 1.3572\n",
      "Validation loss improved to 1.3572\n",
      "Epoch [69/200], Train Loss: 1.3476, Valid Loss: 1.3569\n",
      "Validation loss improved to 1.3569\n",
      "Epoch [70/200], Train Loss: 1.3432, Valid Loss: 1.3567\n",
      "Validation loss improved to 1.3567\n",
      "Epoch [71/200], Train Loss: 1.3763, Valid Loss: 1.3564\n",
      "Validation loss improved to 1.3564\n",
      "Epoch [72/200], Train Loss: 1.3439, Valid Loss: 1.3562\n",
      "Validation loss improved to 1.3562\n",
      "Epoch [73/200], Train Loss: 1.3417, Valid Loss: 1.3559\n",
      "Validation loss improved to 1.3559\n",
      "Epoch [74/200], Train Loss: 1.3442, Valid Loss: 1.3557\n",
      "Validation loss improved to 1.3557\n",
      "Epoch [75/200], Train Loss: 1.3499, Valid Loss: 1.3554\n",
      "Validation loss improved to 1.3554\n",
      "Epoch [76/200], Train Loss: 1.3540, Valid Loss: 1.3552\n",
      "Validation loss improved to 1.3552\n",
      "Epoch [77/200], Train Loss: 1.3654, Valid Loss: 1.3549\n",
      "Validation loss improved to 1.3549\n",
      "Epoch [78/200], Train Loss: 1.3700, Valid Loss: 1.3547\n",
      "Validation loss improved to 1.3547\n",
      "Epoch [79/200], Train Loss: 1.3345, Valid Loss: 1.3544\n",
      "Validation loss improved to 1.3544\n",
      "Epoch [80/200], Train Loss: 1.3412, Valid Loss: 1.3541\n",
      "Validation loss improved to 1.3541\n",
      "Epoch [81/200], Train Loss: 1.3470, Valid Loss: 1.3539\n",
      "Validation loss improved to 1.3539\n",
      "Epoch [82/200], Train Loss: 1.3580, Valid Loss: 1.3536\n",
      "Validation loss improved to 1.3536\n",
      "Epoch [83/200], Train Loss: 1.3407, Valid Loss: 1.3534\n",
      "Validation loss improved to 1.3534\n",
      "Epoch [84/200], Train Loss: 1.3441, Valid Loss: 1.3531\n",
      "Validation loss improved to 1.3531\n",
      "Epoch [85/200], Train Loss: 1.3291, Valid Loss: 1.3528\n",
      "Validation loss improved to 1.3528\n",
      "Epoch [86/200], Train Loss: 1.3815, Valid Loss: 1.3526\n",
      "Validation loss improved to 1.3526\n",
      "Epoch [87/200], Train Loss: 1.3548, Valid Loss: 1.3523\n",
      "Validation loss improved to 1.3523\n",
      "Epoch [88/200], Train Loss: 1.3529, Valid Loss: 1.3520\n",
      "Validation loss improved to 1.3520\n",
      "Epoch [89/200], Train Loss: 1.3496, Valid Loss: 1.3518\n",
      "Validation loss improved to 1.3518\n",
      "Epoch [90/200], Train Loss: 1.3347, Valid Loss: 1.3515\n",
      "Validation loss improved to 1.3515\n",
      "Epoch [91/200], Train Loss: 1.3594, Valid Loss: 1.3513\n",
      "Validation loss improved to 1.3513\n",
      "Epoch [92/200], Train Loss: 1.3286, Valid Loss: 1.3510\n",
      "Validation loss improved to 1.3510\n",
      "Epoch [93/200], Train Loss: 1.3465, Valid Loss: 1.3507\n",
      "Validation loss improved to 1.3507\n",
      "Epoch [94/200], Train Loss: 1.3447, Valid Loss: 1.3505\n",
      "Validation loss improved to 1.3505\n",
      "Epoch [95/200], Train Loss: 1.3567, Valid Loss: 1.3503\n",
      "Validation loss improved to 1.3503\n",
      "Epoch [96/200], Train Loss: 1.3463, Valid Loss: 1.3500\n",
      "Validation loss improved to 1.3500\n",
      "Epoch [97/200], Train Loss: 1.3550, Valid Loss: 1.3498\n",
      "Validation loss improved to 1.3498\n",
      "Epoch [98/200], Train Loss: 1.3385, Valid Loss: 1.3495\n",
      "Validation loss improved to 1.3495\n",
      "Epoch [99/200], Train Loss: 1.3338, Valid Loss: 1.3493\n",
      "Validation loss improved to 1.3493\n",
      "Epoch [100/200], Train Loss: 1.3478, Valid Loss: 1.3490\n",
      "Validation loss improved to 1.3490\n",
      "Epoch [101/200], Train Loss: 1.3485, Valid Loss: 1.3488\n",
      "Validation loss improved to 1.3488\n",
      "Epoch [102/200], Train Loss: 1.3429, Valid Loss: 1.3485\n",
      "Validation loss improved to 1.3485\n",
      "Epoch [103/200], Train Loss: 1.3369, Valid Loss: 1.3483\n",
      "Validation loss improved to 1.3483\n",
      "Epoch [104/200], Train Loss: 1.3415, Valid Loss: 1.3480\n",
      "Validation loss improved to 1.3480\n",
      "Epoch [105/200], Train Loss: 1.3271, Valid Loss: 1.3478\n",
      "Validation loss improved to 1.3478\n",
      "Epoch [106/200], Train Loss: 1.3533, Valid Loss: 1.3475\n",
      "Validation loss improved to 1.3475\n",
      "Epoch [107/200], Train Loss: 1.3422, Valid Loss: 1.3473\n",
      "Validation loss improved to 1.3473\n",
      "Epoch [108/200], Train Loss: 1.3289, Valid Loss: 1.3470\n",
      "Validation loss improved to 1.3470\n",
      "Epoch [109/200], Train Loss: 1.3447, Valid Loss: 1.3468\n",
      "Validation loss improved to 1.3468\n",
      "Epoch [110/200], Train Loss: 1.3288, Valid Loss: 1.3465\n",
      "Validation loss improved to 1.3465\n",
      "Epoch [111/200], Train Loss: 1.3197, Valid Loss: 1.3463\n",
      "Validation loss improved to 1.3463\n",
      "Epoch [112/200], Train Loss: 1.3434, Valid Loss: 1.3460\n",
      "Validation loss improved to 1.3460\n",
      "Epoch [113/200], Train Loss: 1.3394, Valid Loss: 1.3458\n",
      "Validation loss improved to 1.3458\n",
      "Epoch [114/200], Train Loss: 1.3395, Valid Loss: 1.3455\n",
      "Validation loss improved to 1.3455\n",
      "Epoch [115/200], Train Loss: 1.3404, Valid Loss: 1.3453\n",
      "Validation loss improved to 1.3453\n",
      "Epoch [116/200], Train Loss: 1.3258, Valid Loss: 1.3450\n",
      "Validation loss improved to 1.3450\n",
      "Epoch [117/200], Train Loss: 1.3527, Valid Loss: 1.3448\n",
      "Validation loss improved to 1.3448\n",
      "Epoch [118/200], Train Loss: 1.3263, Valid Loss: 1.3445\n",
      "Validation loss improved to 1.3445\n",
      "Epoch [119/200], Train Loss: 1.3474, Valid Loss: 1.3443\n",
      "Validation loss improved to 1.3443\n",
      "Epoch [120/200], Train Loss: 1.3351, Valid Loss: 1.3440\n",
      "Validation loss improved to 1.3440\n",
      "Epoch [121/200], Train Loss: 1.3385, Valid Loss: 1.3438\n",
      "Validation loss improved to 1.3438\n",
      "Epoch [122/200], Train Loss: 1.3364, Valid Loss: 1.3436\n",
      "Validation loss improved to 1.3436\n",
      "Epoch [123/200], Train Loss: 1.3217, Valid Loss: 1.3433\n",
      "Validation loss improved to 1.3433\n",
      "Epoch [124/200], Train Loss: 1.3313, Valid Loss: 1.3431\n",
      "Validation loss improved to 1.3431\n",
      "Epoch [125/200], Train Loss: 1.3350, Valid Loss: 1.3428\n",
      "Validation loss improved to 1.3428\n",
      "Epoch [126/200], Train Loss: 1.3460, Valid Loss: 1.3426\n",
      "Validation loss improved to 1.3426\n",
      "Epoch [127/200], Train Loss: 1.3386, Valid Loss: 1.3424\n",
      "Validation loss improved to 1.3424\n",
      "Epoch [128/200], Train Loss: 1.3276, Valid Loss: 1.3421\n",
      "Validation loss improved to 1.3421\n",
      "Epoch [129/200], Train Loss: 1.3686, Valid Loss: 1.3419\n",
      "Validation loss improved to 1.3419\n",
      "Epoch [130/200], Train Loss: 1.3338, Valid Loss: 1.3417\n",
      "Validation loss improved to 1.3417\n",
      "Epoch [131/200], Train Loss: 1.3349, Valid Loss: 1.3414\n",
      "Validation loss improved to 1.3414\n",
      "Epoch [132/200], Train Loss: 1.3249, Valid Loss: 1.3412\n",
      "Validation loss improved to 1.3412\n",
      "Epoch [133/200], Train Loss: 1.3347, Valid Loss: 1.3409\n",
      "Validation loss improved to 1.3409\n",
      "Epoch [134/200], Train Loss: 1.3196, Valid Loss: 1.3407\n",
      "Validation loss improved to 1.3407\n",
      "Epoch [135/200], Train Loss: 1.3250, Valid Loss: 1.3404\n",
      "Validation loss improved to 1.3404\n",
      "Epoch [136/200], Train Loss: 1.3215, Valid Loss: 1.3402\n",
      "Validation loss improved to 1.3402\n",
      "Epoch [137/200], Train Loss: 1.3440, Valid Loss: 1.3400\n",
      "Validation loss improved to 1.3400\n",
      "Epoch [138/200], Train Loss: 1.3295, Valid Loss: 1.3397\n",
      "Validation loss improved to 1.3397\n",
      "Epoch [139/200], Train Loss: 1.3230, Valid Loss: 1.3395\n",
      "Validation loss improved to 1.3395\n",
      "Epoch [140/200], Train Loss: 1.3081, Valid Loss: 1.3392\n",
      "Validation loss improved to 1.3392\n",
      "Epoch [141/200], Train Loss: 1.3121, Valid Loss: 1.3390\n",
      "Validation loss improved to 1.3390\n",
      "Epoch [142/200], Train Loss: 1.3240, Valid Loss: 1.3388\n",
      "Validation loss improved to 1.3388\n",
      "Epoch [143/200], Train Loss: 1.3295, Valid Loss: 1.3385\n",
      "Validation loss improved to 1.3385\n",
      "Epoch [144/200], Train Loss: 1.3168, Valid Loss: 1.3383\n",
      "Validation loss improved to 1.3383\n",
      "Epoch [145/200], Train Loss: 1.3289, Valid Loss: 1.3381\n",
      "Validation loss improved to 1.3381\n",
      "Epoch [146/200], Train Loss: 1.3200, Valid Loss: 1.3378\n",
      "Validation loss improved to 1.3378\n",
      "Epoch [147/200], Train Loss: 1.3350, Valid Loss: 1.3376\n",
      "Validation loss improved to 1.3376\n",
      "Epoch [148/200], Train Loss: 1.3201, Valid Loss: 1.3374\n",
      "Validation loss improved to 1.3374\n",
      "Epoch [149/200], Train Loss: 1.3266, Valid Loss: 1.3371\n",
      "Validation loss improved to 1.3371\n",
      "Epoch [150/200], Train Loss: 1.3283, Valid Loss: 1.3369\n",
      "Validation loss improved to 1.3369\n",
      "Epoch [151/200], Train Loss: 1.3389, Valid Loss: 1.3367\n",
      "Validation loss improved to 1.3367\n",
      "Epoch [152/200], Train Loss: 1.3333, Valid Loss: 1.3364\n",
      "Validation loss improved to 1.3364\n",
      "Epoch [153/200], Train Loss: 1.3207, Valid Loss: 1.3362\n",
      "Validation loss improved to 1.3362\n",
      "Epoch [154/200], Train Loss: 1.3136, Valid Loss: 1.3359\n",
      "Validation loss improved to 1.3359\n",
      "Epoch [155/200], Train Loss: 1.3140, Valid Loss: 1.3357\n",
      "Validation loss improved to 1.3357\n",
      "Epoch [156/200], Train Loss: 1.3128, Valid Loss: 1.3355\n",
      "Validation loss improved to 1.3355\n",
      "Epoch [157/200], Train Loss: 1.3126, Valid Loss: 1.3352\n",
      "Validation loss improved to 1.3352\n",
      "Epoch [158/200], Train Loss: 1.3221, Valid Loss: 1.3350\n",
      "Validation loss improved to 1.3350\n",
      "Epoch [159/200], Train Loss: 1.3227, Valid Loss: 1.3347\n",
      "Validation loss improved to 1.3347\n",
      "Epoch [160/200], Train Loss: 1.3079, Valid Loss: 1.3345\n",
      "Validation loss improved to 1.3345\n",
      "Epoch [161/200], Train Loss: 1.3271, Valid Loss: 1.3342\n",
      "Validation loss improved to 1.3342\n",
      "Epoch [162/200], Train Loss: 1.3234, Valid Loss: 1.3340\n",
      "Validation loss improved to 1.3340\n",
      "Epoch [163/200], Train Loss: 1.3297, Valid Loss: 1.3337\n",
      "Validation loss improved to 1.3337\n",
      "Epoch [164/200], Train Loss: 1.3170, Valid Loss: 1.3335\n",
      "Validation loss improved to 1.3335\n",
      "Epoch [165/200], Train Loss: 1.3152, Valid Loss: 1.3332\n",
      "Validation loss improved to 1.3332\n",
      "Epoch [166/200], Train Loss: 1.3121, Valid Loss: 1.3330\n",
      "Validation loss improved to 1.3330\n",
      "Epoch [167/200], Train Loss: 1.3326, Valid Loss: 1.3327\n",
      "Validation loss improved to 1.3327\n",
      "Epoch [168/200], Train Loss: 1.3151, Valid Loss: 1.3324\n",
      "Validation loss improved to 1.3324\n",
      "Epoch [169/200], Train Loss: 1.3339, Valid Loss: 1.3322\n",
      "Validation loss improved to 1.3322\n",
      "Epoch [170/200], Train Loss: 1.3279, Valid Loss: 1.3319\n",
      "Validation loss improved to 1.3319\n",
      "Epoch [171/200], Train Loss: 1.3093, Valid Loss: 1.3317\n",
      "Validation loss improved to 1.3317\n",
      "Epoch [172/200], Train Loss: 1.3278, Valid Loss: 1.3314\n",
      "Validation loss improved to 1.3314\n",
      "Epoch [173/200], Train Loss: 1.3306, Valid Loss: 1.3311\n",
      "Validation loss improved to 1.3311\n",
      "Epoch [174/200], Train Loss: 1.3323, Valid Loss: 1.3309\n",
      "Validation loss improved to 1.3309\n",
      "Epoch [175/200], Train Loss: 1.3055, Valid Loss: 1.3306\n",
      "Validation loss improved to 1.3306\n",
      "Epoch [176/200], Train Loss: 1.3237, Valid Loss: 1.3303\n",
      "Validation loss improved to 1.3303\n",
      "Epoch [177/200], Train Loss: 1.3085, Valid Loss: 1.3301\n",
      "Validation loss improved to 1.3301\n",
      "Epoch [178/200], Train Loss: 1.3066, Valid Loss: 1.3298\n",
      "Validation loss improved to 1.3298\n",
      "Epoch [179/200], Train Loss: 1.3200, Valid Loss: 1.3295\n",
      "Validation loss improved to 1.3295\n",
      "Epoch [180/200], Train Loss: 1.3152, Valid Loss: 1.3292\n",
      "Validation loss improved to 1.3292\n",
      "Epoch [181/200], Train Loss: 1.3140, Valid Loss: 1.3290\n",
      "Validation loss improved to 1.3290\n",
      "Epoch [182/200], Train Loss: 1.3131, Valid Loss: 1.3287\n",
      "Validation loss improved to 1.3287\n",
      "Epoch [183/200], Train Loss: 1.3392, Valid Loss: 1.3284\n",
      "Validation loss improved to 1.3284\n",
      "Epoch [184/200], Train Loss: 1.3166, Valid Loss: 1.3281\n",
      "Validation loss improved to 1.3281\n",
      "Epoch [185/200], Train Loss: 1.3205, Valid Loss: 1.3278\n",
      "Validation loss improved to 1.3278\n",
      "Epoch [186/200], Train Loss: 1.3140, Valid Loss: 1.3276\n",
      "Validation loss improved to 1.3276\n",
      "Epoch [187/200], Train Loss: 1.3109, Valid Loss: 1.3273\n",
      "Validation loss improved to 1.3273\n",
      "Epoch [188/200], Train Loss: 1.3332, Valid Loss: 1.3270\n",
      "Validation loss improved to 1.3270\n",
      "Epoch [189/200], Train Loss: 1.3104, Valid Loss: 1.3267\n",
      "Validation loss improved to 1.3267\n",
      "Epoch [190/200], Train Loss: 1.3016, Valid Loss: 1.3265\n",
      "Validation loss improved to 1.3265\n",
      "Epoch [191/200], Train Loss: 1.3080, Valid Loss: 1.3262\n",
      "Validation loss improved to 1.3262\n",
      "Epoch [192/200], Train Loss: 1.3140, Valid Loss: 1.3259\n",
      "Validation loss improved to 1.3259\n",
      "Epoch [193/200], Train Loss: 1.3249, Valid Loss: 1.3256\n",
      "Validation loss improved to 1.3256\n",
      "Epoch [194/200], Train Loss: 1.3150, Valid Loss: 1.3254\n",
      "Validation loss improved to 1.3254\n",
      "Epoch [195/200], Train Loss: 1.3163, Valid Loss: 1.3251\n",
      "Validation loss improved to 1.3251\n",
      "Epoch [196/200], Train Loss: 1.3050, Valid Loss: 1.3248\n",
      "Validation loss improved to 1.3248\n",
      "Epoch [197/200], Train Loss: 1.2965, Valid Loss: 1.3246\n",
      "Validation loss improved to 1.3246\n",
      "Epoch [198/200], Train Loss: 1.2995, Valid Loss: 1.3243\n",
      "Validation loss improved to 1.3243\n",
      "Epoch [199/200], Train Loss: 1.3080, Valid Loss: 1.3240\n",
      "Validation loss improved to 1.3240\n",
      "Epoch [200/200], Train Loss: 1.3170, Valid Loss: 1.3237\n",
      "Validation loss improved to 1.3237\n",
      "Training completed. Final model saved as model/loss_1.3237_lr_0.0001_batch_128_opt_SGD.pt\n",
      "Training with parameters: {'batch_size': 128, 'epochs': 200, 'learning_rate': 0.0001, 'optimizer': 'RMSprop'}\n",
      "Epoch [1/200], Train Loss: 1.4038, Valid Loss: 1.3623\n",
      "Validation loss improved to 1.3623\n",
      "Epoch [2/200], Train Loss: 1.3242, Valid Loss: 1.3444\n",
      "Validation loss improved to 1.3444\n",
      "Epoch [3/200], Train Loss: 1.2783, Valid Loss: 1.3073\n",
      "Validation loss improved to 1.3073\n",
      "Epoch [4/200], Train Loss: 1.2634, Valid Loss: 1.2943\n",
      "Validation loss improved to 1.2943\n",
      "Epoch [5/200], Train Loss: 1.2237, Valid Loss: 1.2234\n",
      "Validation loss improved to 1.2234\n",
      "Epoch [6/200], Train Loss: 1.1701, Valid Loss: 1.1916\n",
      "Validation loss improved to 1.1916\n",
      "Epoch [7/200], Train Loss: 1.1329, Valid Loss: 1.1954\n",
      "Epoch [8/200], Train Loss: 1.1395, Valid Loss: 1.1349\n",
      "Validation loss improved to 1.1349\n",
      "Epoch [9/200], Train Loss: 1.1331, Valid Loss: 1.0773\n",
      "Validation loss improved to 1.0773\n",
      "Epoch [10/200], Train Loss: 1.0643, Valid Loss: 1.0342\n",
      "Validation loss improved to 1.0342\n",
      "Epoch [11/200], Train Loss: 0.9986, Valid Loss: 0.9995\n",
      "Validation loss improved to 0.9995\n",
      "Epoch [12/200], Train Loss: 0.9502, Valid Loss: 0.9636\n",
      "Validation loss improved to 0.9636\n",
      "Epoch [13/200], Train Loss: 0.8954, Valid Loss: 0.9365\n",
      "Validation loss improved to 0.9365\n",
      "Epoch [14/200], Train Loss: 0.9139, Valid Loss: 0.9044\n",
      "Validation loss improved to 0.9044\n",
      "Epoch [15/200], Train Loss: 0.8639, Valid Loss: 0.8695\n",
      "Validation loss improved to 0.8695\n",
      "Epoch [16/200], Train Loss: 0.8202, Valid Loss: 0.8710\n",
      "Epoch [17/200], Train Loss: 0.8240, Valid Loss: 0.7807\n",
      "Validation loss improved to 0.7807\n",
      "Epoch [18/200], Train Loss: 0.7531, Valid Loss: 0.7948\n",
      "Epoch [19/200], Train Loss: 0.7365, Valid Loss: 0.7742\n",
      "Validation loss improved to 0.7742\n",
      "Epoch [20/200], Train Loss: 0.7445, Valid Loss: 0.7801\n",
      "Epoch [21/200], Train Loss: 0.7134, Valid Loss: 0.6803\n",
      "Validation loss improved to 0.6803\n",
      "Epoch [22/200], Train Loss: 0.7015, Valid Loss: 0.7228\n",
      "Epoch [23/200], Train Loss: 0.6893, Valid Loss: 0.6690\n",
      "Validation loss improved to 0.6690\n",
      "Epoch [24/200], Train Loss: 0.6951, Valid Loss: 0.6407\n",
      "Validation loss improved to 0.6407\n",
      "Epoch [25/200], Train Loss: 0.6267, Valid Loss: 0.6062\n",
      "Validation loss improved to 0.6062\n",
      "Epoch [26/200], Train Loss: 0.6211, Valid Loss: 0.6023\n",
      "Validation loss improved to 0.6023\n",
      "Epoch [27/200], Train Loss: 0.5599, Valid Loss: 0.5830\n",
      "Validation loss improved to 0.5830\n",
      "Epoch [28/200], Train Loss: 0.5790, Valid Loss: 0.5510\n",
      "Validation loss improved to 0.5510\n",
      "Epoch [29/200], Train Loss: 0.5358, Valid Loss: 0.5516\n",
      "Epoch [30/200], Train Loss: 0.5359, Valid Loss: 0.5311\n",
      "Validation loss improved to 0.5311\n",
      "Epoch [31/200], Train Loss: 0.5302, Valid Loss: 0.5219\n",
      "Validation loss improved to 0.5219\n",
      "Epoch [32/200], Train Loss: 0.5124, Valid Loss: 0.4886\n",
      "Validation loss improved to 0.4886\n",
      "Epoch [33/200], Train Loss: 0.4541, Valid Loss: 0.4781\n",
      "Validation loss improved to 0.4781\n",
      "Epoch [34/200], Train Loss: 0.4009, Valid Loss: 0.4594\n",
      "Validation loss improved to 0.4594\n",
      "Epoch [35/200], Train Loss: 0.4366, Valid Loss: 0.4547\n",
      "Validation loss improved to 0.4547\n",
      "Epoch [36/200], Train Loss: 0.4152, Valid Loss: 0.4643\n",
      "Epoch [37/200], Train Loss: 0.4004, Valid Loss: 0.4448\n",
      "Validation loss improved to 0.4448\n",
      "Epoch [38/200], Train Loss: 0.4082, Valid Loss: 0.4566\n",
      "Epoch [39/200], Train Loss: 0.3942, Valid Loss: 0.4065\n",
      "Validation loss improved to 0.4065\n",
      "Epoch [40/200], Train Loss: 0.3574, Valid Loss: 0.4426\n",
      "Epoch [41/200], Train Loss: 0.4608, Valid Loss: 0.4048\n",
      "Validation loss improved to 0.4048\n",
      "Epoch [42/200], Train Loss: 0.4177, Valid Loss: 0.4374\n",
      "Epoch [43/200], Train Loss: 0.3846, Valid Loss: 0.3635\n",
      "Validation loss improved to 0.3635\n",
      "Epoch [44/200], Train Loss: 0.3564, Valid Loss: 0.3731\n",
      "Epoch [45/200], Train Loss: 0.3351, Valid Loss: 0.3380\n",
      "Validation loss improved to 0.3380\n",
      "Epoch [46/200], Train Loss: 0.3397, Valid Loss: 0.4033\n",
      "Epoch [47/200], Train Loss: 0.3512, Valid Loss: 0.3416\n",
      "Epoch [48/200], Train Loss: 0.3371, Valid Loss: 0.3611\n",
      "Epoch [49/200], Train Loss: 0.3039, Valid Loss: 0.3267\n",
      "Validation loss improved to 0.3267\n",
      "Epoch [50/200], Train Loss: 0.3172, Valid Loss: 0.3154\n",
      "Validation loss improved to 0.3154\n",
      "Epoch [51/200], Train Loss: 0.2425, Valid Loss: 0.3320\n",
      "Epoch [52/200], Train Loss: 0.2790, Valid Loss: 0.3109\n",
      "Validation loss improved to 0.3109\n",
      "Epoch [53/200], Train Loss: 0.2558, Valid Loss: 0.3074\n",
      "Validation loss improved to 0.3074\n",
      "Epoch [54/200], Train Loss: 0.2486, Valid Loss: 0.3054\n",
      "Validation loss improved to 0.3054\n",
      "Epoch [55/200], Train Loss: 0.2282, Valid Loss: 0.2914\n",
      "Validation loss improved to 0.2914\n",
      "Epoch [56/200], Train Loss: 0.2349, Valid Loss: 0.2882\n",
      "Validation loss improved to 0.2882\n",
      "Epoch [57/200], Train Loss: 0.2272, Valid Loss: 0.2873\n",
      "Validation loss improved to 0.2873\n",
      "Epoch [58/200], Train Loss: 0.2252, Valid Loss: 0.2710\n",
      "Validation loss improved to 0.2710\n",
      "Epoch [59/200], Train Loss: 0.2070, Valid Loss: 0.2905\n",
      "Epoch [60/200], Train Loss: 0.2436, Valid Loss: 0.2545\n",
      "Validation loss improved to 0.2545\n",
      "Epoch [61/200], Train Loss: 0.2134, Valid Loss: 0.3021\n",
      "Epoch [62/200], Train Loss: 0.2290, Valid Loss: 0.2637\n",
      "Epoch [63/200], Train Loss: 0.1952, Valid Loss: 0.2661\n",
      "Epoch [64/200], Train Loss: 0.2043, Valid Loss: 0.2325\n",
      "Validation loss improved to 0.2325\n",
      "Epoch [65/200], Train Loss: 0.1860, Valid Loss: 0.2636\n",
      "Epoch [66/200], Train Loss: 0.1611, Valid Loss: 0.2323\n",
      "Validation loss improved to 0.2323\n",
      "Epoch [67/200], Train Loss: 0.1946, Valid Loss: 0.2481\n",
      "Epoch [68/200], Train Loss: 0.1945, Valid Loss: 0.2302\n",
      "Validation loss improved to 0.2302\n",
      "Epoch [69/200], Train Loss: 0.1909, Valid Loss: 0.2568\n",
      "Epoch [70/200], Train Loss: 0.1872, Valid Loss: 0.2128\n",
      "Validation loss improved to 0.2128\n",
      "Epoch [71/200], Train Loss: 0.1839, Valid Loss: 0.2168\n",
      "Epoch [72/200], Train Loss: 0.1845, Valid Loss: 0.2155\n",
      "Epoch [73/200], Train Loss: 0.1639, Valid Loss: 0.2386\n",
      "Epoch [74/200], Train Loss: 0.1759, Valid Loss: 0.2080\n",
      "Validation loss improved to 0.2080\n",
      "Epoch [75/200], Train Loss: 0.1426, Valid Loss: 0.2323\n",
      "Epoch [76/200], Train Loss: 0.1520, Valid Loss: 0.2010\n",
      "Validation loss improved to 0.2010\n",
      "Epoch [77/200], Train Loss: 0.1378, Valid Loss: 0.2140\n",
      "Epoch [78/200], Train Loss: 0.1207, Valid Loss: 0.2043\n",
      "Epoch [79/200], Train Loss: 0.1118, Valid Loss: 0.2011\n",
      "Epoch [80/200], Train Loss: 0.1168, Valid Loss: 0.2130\n",
      "Epoch [81/200], Train Loss: 0.1163, Valid Loss: 0.2116\n",
      "Epoch [82/200], Train Loss: 0.1519, Valid Loss: 0.1670\n",
      "Validation loss improved to 0.1670\n",
      "Epoch [83/200], Train Loss: 0.1373, Valid Loss: 0.2301\n",
      "Epoch [84/200], Train Loss: 0.1217, Valid Loss: 0.1813\n",
      "Epoch [85/200], Train Loss: 0.1251, Valid Loss: 0.2032\n",
      "Epoch [86/200], Train Loss: 0.1077, Valid Loss: 0.1734\n",
      "Epoch [87/200], Train Loss: 0.1158, Valid Loss: 0.1974\n",
      "Epoch [88/200], Train Loss: 0.1209, Valid Loss: 0.1889\n",
      "Epoch [89/200], Train Loss: 0.1441, Valid Loss: 0.1896\n",
      "Epoch [90/200], Train Loss: 0.1285, Valid Loss: 0.1758\n",
      "Epoch [91/200], Train Loss: 0.0968, Valid Loss: 0.1828\n",
      "Epoch [92/200], Train Loss: 0.0994, Valid Loss: 0.1720\n",
      "Early stopping triggered at epoch 92\n",
      "Training completed. Final model saved as model/loss_0.1670_lr_0.0001_batch_128_opt_RMSprop.pt\n",
      "Training with parameters: {'batch_size': 128, 'epochs': 200, 'learning_rate': 0.001, 'optimizer': 'Adam'}\n",
      "Epoch [1/200], Train Loss: 1.3993, Valid Loss: 1.3366\n",
      "Validation loss improved to 1.3366\n",
      "Epoch [2/200], Train Loss: 1.3185, Valid Loss: 1.3077\n",
      "Validation loss improved to 1.3077\n",
      "Epoch [3/200], Train Loss: 1.2878, Valid Loss: 1.2601\n",
      "Validation loss improved to 1.2601\n",
      "Epoch [4/200], Train Loss: 1.2280, Valid Loss: 1.2183\n",
      "Validation loss improved to 1.2183\n",
      "Epoch [5/200], Train Loss: 1.1574, Valid Loss: 1.1682\n",
      "Validation loss improved to 1.1682\n",
      "Epoch [6/200], Train Loss: 1.1438, Valid Loss: 1.1180\n",
      "Validation loss improved to 1.1180\n",
      "Epoch [7/200], Train Loss: 1.0863, Valid Loss: 1.0666\n",
      "Validation loss improved to 1.0666\n",
      "Epoch [8/200], Train Loss: 1.0053, Valid Loss: 0.9928\n",
      "Validation loss improved to 0.9928\n",
      "Epoch [9/200], Train Loss: 1.0008, Valid Loss: 0.9362\n",
      "Validation loss improved to 0.9362\n",
      "Epoch [10/200], Train Loss: 0.9342, Valid Loss: 0.8694\n",
      "Validation loss improved to 0.8694\n",
      "Epoch [11/200], Train Loss: 0.8689, Valid Loss: 0.8099\n",
      "Validation loss improved to 0.8099\n",
      "Epoch [12/200], Train Loss: 0.8066, Valid Loss: 0.7535\n",
      "Validation loss improved to 0.7535\n",
      "Epoch [13/200], Train Loss: 0.7409, Valid Loss: 0.7034\n",
      "Validation loss improved to 0.7034\n",
      "Epoch [14/200], Train Loss: 0.6516, Valid Loss: 0.6362\n",
      "Validation loss improved to 0.6362\n",
      "Epoch [15/200], Train Loss: 0.5961, Valid Loss: 0.5842\n",
      "Validation loss improved to 0.5842\n",
      "Epoch [16/200], Train Loss: 0.5373, Valid Loss: 0.5530\n",
      "Validation loss improved to 0.5530\n",
      "Epoch [17/200], Train Loss: 0.5757, Valid Loss: 0.4882\n",
      "Validation loss improved to 0.4882\n",
      "Epoch [18/200], Train Loss: 0.4946, Valid Loss: 0.4636\n",
      "Validation loss improved to 0.4636\n",
      "Epoch [19/200], Train Loss: 0.4369, Valid Loss: 0.4328\n",
      "Validation loss improved to 0.4328\n",
      "Epoch [20/200], Train Loss: 0.3548, Valid Loss: 0.4091\n",
      "Validation loss improved to 0.4091\n",
      "Epoch [21/200], Train Loss: 0.3201, Valid Loss: 0.3699\n",
      "Validation loss improved to 0.3699\n",
      "Epoch [22/200], Train Loss: 0.3055, Valid Loss: 0.3380\n",
      "Validation loss improved to 0.3380\n",
      "Epoch [23/200], Train Loss: 0.2474, Valid Loss: 0.3203\n",
      "Validation loss improved to 0.3203\n",
      "Epoch [24/200], Train Loss: 0.2302, Valid Loss: 0.3123\n",
      "Validation loss improved to 0.3123\n",
      "Epoch [25/200], Train Loss: 0.1806, Valid Loss: 0.3020\n",
      "Validation loss improved to 0.3020\n",
      "Epoch [26/200], Train Loss: 0.1527, Valid Loss: 0.2911\n",
      "Validation loss improved to 0.2911\n",
      "Epoch [27/200], Train Loss: 0.1641, Valid Loss: 0.2835\n",
      "Validation loss improved to 0.2835\n",
      "Epoch [28/200], Train Loss: 0.1167, Valid Loss: 0.2677\n",
      "Validation loss improved to 0.2677\n",
      "Epoch [29/200], Train Loss: 0.1217, Valid Loss: 0.2767\n",
      "Epoch [30/200], Train Loss: 0.0980, Valid Loss: 0.2561\n",
      "Validation loss improved to 0.2561\n",
      "Epoch [31/200], Train Loss: 0.0845, Valid Loss: 0.2337\n",
      "Validation loss improved to 0.2337\n",
      "Epoch [32/200], Train Loss: 0.0791, Valid Loss: 0.2200\n",
      "Validation loss improved to 0.2200\n",
      "Epoch [33/200], Train Loss: 0.1043, Valid Loss: 0.2122\n",
      "Validation loss improved to 0.2122\n",
      "Epoch [34/200], Train Loss: 0.0675, Valid Loss: 0.2178\n",
      "Epoch [35/200], Train Loss: 0.0540, Valid Loss: 0.1683\n",
      "Validation loss improved to 0.1683\n",
      "Epoch [36/200], Train Loss: 0.0438, Valid Loss: 0.1348\n",
      "Validation loss improved to 0.1348\n",
      "Epoch [37/200], Train Loss: 0.0501, Valid Loss: 0.1472\n",
      "Epoch [38/200], Train Loss: 0.0415, Valid Loss: 0.1532\n",
      "Epoch [39/200], Train Loss: 0.0454, Valid Loss: 0.1526\n",
      "Epoch [40/200], Train Loss: 0.0385, Valid Loss: 0.1293\n",
      "Validation loss improved to 0.1293\n",
      "Epoch [41/200], Train Loss: 0.0419, Valid Loss: 0.1426\n",
      "Epoch [42/200], Train Loss: 0.0431, Valid Loss: 0.1474\n",
      "Epoch [43/200], Train Loss: 0.0236, Valid Loss: 0.1366\n",
      "Epoch [44/200], Train Loss: 0.0266, Valid Loss: 0.1259\n",
      "Validation loss improved to 0.1259\n",
      "Epoch [45/200], Train Loss: 0.0126, Valid Loss: 0.1279\n",
      "Epoch [46/200], Train Loss: 0.0249, Valid Loss: 0.1298\n",
      "Epoch [47/200], Train Loss: 0.0121, Valid Loss: 0.1294\n",
      "Epoch [48/200], Train Loss: 0.0246, Valid Loss: 0.1263\n",
      "Epoch [49/200], Train Loss: 0.0110, Valid Loss: 0.1259\n",
      "Validation loss improved to 0.1259\n",
      "Epoch [50/200], Train Loss: 0.0126, Valid Loss: 0.1248\n",
      "Validation loss improved to 0.1248\n",
      "Epoch [51/200], Train Loss: 0.0279, Valid Loss: 0.1141\n",
      "Validation loss improved to 0.1141\n",
      "Epoch [52/200], Train Loss: 0.0184, Valid Loss: 0.1038\n",
      "Validation loss improved to 0.1038\n",
      "Epoch [53/200], Train Loss: 0.0264, Valid Loss: 0.1043\n",
      "Epoch [54/200], Train Loss: 0.0160, Valid Loss: 0.1106\n",
      "Epoch [55/200], Train Loss: 0.0130, Valid Loss: 0.1083\n",
      "Epoch [56/200], Train Loss: 0.0123, Valid Loss: 0.0969\n",
      "Validation loss improved to 0.0969\n",
      "Epoch [57/200], Train Loss: 0.0164, Valid Loss: 0.1013\n",
      "Epoch [58/200], Train Loss: 0.0060, Valid Loss: 0.1197\n",
      "Epoch [59/200], Train Loss: 0.0096, Valid Loss: 0.1436\n",
      "Epoch [60/200], Train Loss: 0.0048, Valid Loss: 0.1632\n",
      "Epoch [61/200], Train Loss: 0.0133, Valid Loss: 0.1650\n",
      "Epoch [62/200], Train Loss: 0.0058, Valid Loss: 0.1580\n",
      "Epoch [63/200], Train Loss: 0.0051, Valid Loss: 0.1491\n",
      "Epoch [64/200], Train Loss: 0.0036, Valid Loss: 0.1400\n",
      "Epoch [65/200], Train Loss: 0.0062, Valid Loss: 0.1327\n",
      "Epoch [66/200], Train Loss: 0.0021, Valid Loss: 0.1249\n",
      "Early stopping triggered at epoch 66\n",
      "Training completed. Final model saved as model/loss_0.0969_lr_0.001_batch_128_opt_Adam.pt\n",
      "Training with parameters: {'batch_size': 128, 'epochs': 200, 'learning_rate': 0.001, 'optimizer': 'SGD'}\n",
      "Epoch [1/200], Train Loss: 1.3885, Valid Loss: 1.3842\n",
      "Validation loss improved to 1.3842\n",
      "Epoch [2/200], Train Loss: 1.3726, Valid Loss: 1.3832\n",
      "Validation loss improved to 1.3832\n",
      "Epoch [3/200], Train Loss: 1.3970, Valid Loss: 1.3817\n",
      "Validation loss improved to 1.3817\n",
      "Epoch [4/200], Train Loss: 1.3586, Valid Loss: 1.3799\n",
      "Validation loss improved to 1.3799\n",
      "Epoch [5/200], Train Loss: 1.3758, Valid Loss: 1.3778\n",
      "Validation loss improved to 1.3778\n",
      "Epoch [6/200], Train Loss: 1.3652, Valid Loss: 1.3754\n",
      "Validation loss improved to 1.3754\n",
      "Epoch [7/200], Train Loss: 1.3706, Valid Loss: 1.3728\n",
      "Validation loss improved to 1.3728\n",
      "Epoch [8/200], Train Loss: 1.3816, Valid Loss: 1.3702\n",
      "Validation loss improved to 1.3702\n",
      "Epoch [9/200], Train Loss: 1.3758, Valid Loss: 1.3673\n",
      "Validation loss improved to 1.3673\n",
      "Epoch [10/200], Train Loss: 1.3776, Valid Loss: 1.3645\n",
      "Validation loss improved to 1.3645\n",
      "Epoch [11/200], Train Loss: 1.3779, Valid Loss: 1.3617\n",
      "Validation loss improved to 1.3617\n",
      "Epoch [12/200], Train Loss: 1.3560, Valid Loss: 1.3589\n",
      "Validation loss improved to 1.3589\n",
      "Epoch [13/200], Train Loss: 1.3540, Valid Loss: 1.3560\n",
      "Validation loss improved to 1.3560\n",
      "Epoch [14/200], Train Loss: 1.3409, Valid Loss: 1.3531\n",
      "Validation loss improved to 1.3531\n",
      "Epoch [15/200], Train Loss: 1.3423, Valid Loss: 1.3503\n",
      "Validation loss improved to 1.3503\n",
      "Epoch [16/200], Train Loss: 1.3662, Valid Loss: 1.3475\n",
      "Validation loss improved to 1.3475\n",
      "Epoch [17/200], Train Loss: 1.3537, Valid Loss: 1.3447\n",
      "Validation loss improved to 1.3447\n",
      "Epoch [18/200], Train Loss: 1.3565, Valid Loss: 1.3419\n",
      "Validation loss improved to 1.3419\n",
      "Epoch [19/200], Train Loss: 1.3446, Valid Loss: 1.3393\n",
      "Validation loss improved to 1.3393\n",
      "Epoch [20/200], Train Loss: 1.3302, Valid Loss: 1.3367\n",
      "Validation loss improved to 1.3367\n",
      "Epoch [21/200], Train Loss: 1.3400, Valid Loss: 1.3343\n",
      "Validation loss improved to 1.3343\n",
      "Epoch [22/200], Train Loss: 1.3349, Valid Loss: 1.3319\n",
      "Validation loss improved to 1.3319\n",
      "Epoch [23/200], Train Loss: 1.3380, Valid Loss: 1.3295\n",
      "Validation loss improved to 1.3295\n",
      "Epoch [24/200], Train Loss: 1.3362, Valid Loss: 1.3273\n",
      "Validation loss improved to 1.3273\n",
      "Epoch [25/200], Train Loss: 1.3232, Valid Loss: 1.3252\n",
      "Validation loss improved to 1.3252\n",
      "Epoch [26/200], Train Loss: 1.3148, Valid Loss: 1.3231\n",
      "Validation loss improved to 1.3231\n",
      "Epoch [27/200], Train Loss: 1.3127, Valid Loss: 1.3209\n",
      "Validation loss improved to 1.3209\n",
      "Epoch [28/200], Train Loss: 1.3140, Valid Loss: 1.3188\n",
      "Validation loss improved to 1.3188\n",
      "Epoch [29/200], Train Loss: 1.3272, Valid Loss: 1.3166\n",
      "Validation loss improved to 1.3166\n",
      "Epoch [30/200], Train Loss: 1.3088, Valid Loss: 1.3144\n",
      "Validation loss improved to 1.3144\n",
      "Epoch [31/200], Train Loss: 1.3068, Valid Loss: 1.3122\n",
      "Validation loss improved to 1.3122\n",
      "Epoch [32/200], Train Loss: 1.2986, Valid Loss: 1.3099\n",
      "Validation loss improved to 1.3099\n",
      "Epoch [33/200], Train Loss: 1.3157, Valid Loss: 1.3076\n",
      "Validation loss improved to 1.3076\n",
      "Epoch [34/200], Train Loss: 1.3077, Valid Loss: 1.3053\n",
      "Validation loss improved to 1.3053\n",
      "Epoch [35/200], Train Loss: 1.2993, Valid Loss: 1.3031\n",
      "Validation loss improved to 1.3031\n",
      "Epoch [36/200], Train Loss: 1.2999, Valid Loss: 1.3009\n",
      "Validation loss improved to 1.3009\n",
      "Epoch [37/200], Train Loss: 1.3069, Valid Loss: 1.2987\n",
      "Validation loss improved to 1.2987\n",
      "Epoch [38/200], Train Loss: 1.2814, Valid Loss: 1.2964\n",
      "Validation loss improved to 1.2964\n",
      "Epoch [39/200], Train Loss: 1.2767, Valid Loss: 1.2942\n",
      "Validation loss improved to 1.2942\n",
      "Epoch [40/200], Train Loss: 1.3025, Valid Loss: 1.2920\n",
      "Validation loss improved to 1.2920\n",
      "Epoch [41/200], Train Loss: 1.2792, Valid Loss: 1.2898\n",
      "Validation loss improved to 1.2898\n",
      "Epoch [42/200], Train Loss: 1.2839, Valid Loss: 1.2876\n",
      "Validation loss improved to 1.2876\n",
      "Epoch [43/200], Train Loss: 1.2512, Valid Loss: 1.2853\n",
      "Validation loss improved to 1.2853\n",
      "Epoch [44/200], Train Loss: 1.2789, Valid Loss: 1.2831\n",
      "Validation loss improved to 1.2831\n",
      "Epoch [45/200], Train Loss: 1.2607, Valid Loss: 1.2808\n",
      "Validation loss improved to 1.2808\n",
      "Epoch [46/200], Train Loss: 1.2689, Valid Loss: 1.2785\n",
      "Validation loss improved to 1.2785\n",
      "Epoch [47/200], Train Loss: 1.2635, Valid Loss: 1.2763\n",
      "Validation loss improved to 1.2763\n",
      "Epoch [48/200], Train Loss: 1.2434, Valid Loss: 1.2740\n",
      "Validation loss improved to 1.2740\n",
      "Epoch [49/200], Train Loss: 1.2703, Valid Loss: 1.2717\n",
      "Validation loss improved to 1.2717\n",
      "Epoch [50/200], Train Loss: 1.2671, Valid Loss: 1.2694\n",
      "Validation loss improved to 1.2694\n",
      "Epoch [51/200], Train Loss: 1.2779, Valid Loss: 1.2670\n",
      "Validation loss improved to 1.2670\n",
      "Epoch [52/200], Train Loss: 1.2483, Valid Loss: 1.2646\n",
      "Validation loss improved to 1.2646\n",
      "Epoch [53/200], Train Loss: 1.2562, Valid Loss: 1.2621\n",
      "Validation loss improved to 1.2621\n",
      "Epoch [54/200], Train Loss: 1.2497, Valid Loss: 1.2597\n",
      "Validation loss improved to 1.2597\n",
      "Epoch [55/200], Train Loss: 1.2538, Valid Loss: 1.2572\n",
      "Validation loss improved to 1.2572\n",
      "Epoch [56/200], Train Loss: 1.2193, Valid Loss: 1.2548\n",
      "Validation loss improved to 1.2548\n",
      "Epoch [57/200], Train Loss: 1.2245, Valid Loss: 1.2523\n",
      "Validation loss improved to 1.2523\n",
      "Epoch [58/200], Train Loss: 1.2371, Valid Loss: 1.2498\n",
      "Validation loss improved to 1.2498\n",
      "Epoch [59/200], Train Loss: 1.2306, Valid Loss: 1.2473\n",
      "Validation loss improved to 1.2473\n",
      "Epoch [60/200], Train Loss: 1.2596, Valid Loss: 1.2447\n",
      "Validation loss improved to 1.2447\n",
      "Epoch [61/200], Train Loss: 1.2091, Valid Loss: 1.2422\n",
      "Validation loss improved to 1.2422\n",
      "Epoch [62/200], Train Loss: 1.2213, Valid Loss: 1.2396\n",
      "Validation loss improved to 1.2396\n",
      "Epoch [63/200], Train Loss: 1.2320, Valid Loss: 1.2370\n",
      "Validation loss improved to 1.2370\n",
      "Epoch [64/200], Train Loss: 1.2163, Valid Loss: 1.2344\n",
      "Validation loss improved to 1.2344\n",
      "Epoch [65/200], Train Loss: 1.2111, Valid Loss: 1.2317\n",
      "Validation loss improved to 1.2317\n",
      "Epoch [66/200], Train Loss: 1.2278, Valid Loss: 1.2290\n",
      "Validation loss improved to 1.2290\n",
      "Epoch [67/200], Train Loss: 1.1960, Valid Loss: 1.2263\n",
      "Validation loss improved to 1.2263\n",
      "Epoch [68/200], Train Loss: 1.1982, Valid Loss: 1.2236\n",
      "Validation loss improved to 1.2236\n",
      "Epoch [69/200], Train Loss: 1.2142, Valid Loss: 1.2209\n",
      "Validation loss improved to 1.2209\n",
      "Epoch [70/200], Train Loss: 1.2067, Valid Loss: 1.2183\n",
      "Validation loss improved to 1.2183\n",
      "Epoch [71/200], Train Loss: 1.1864, Valid Loss: 1.2156\n",
      "Validation loss improved to 1.2156\n",
      "Epoch [72/200], Train Loss: 1.1785, Valid Loss: 1.2128\n",
      "Validation loss improved to 1.2128\n",
      "Epoch [73/200], Train Loss: 1.1723, Valid Loss: 1.2101\n",
      "Validation loss improved to 1.2101\n",
      "Epoch [74/200], Train Loss: 1.1749, Valid Loss: 1.2072\n",
      "Validation loss improved to 1.2072\n",
      "Epoch [75/200], Train Loss: 1.1816, Valid Loss: 1.2042\n",
      "Validation loss improved to 1.2042\n",
      "Epoch [76/200], Train Loss: 1.1776, Valid Loss: 1.2012\n",
      "Validation loss improved to 1.2012\n",
      "Epoch [77/200], Train Loss: 1.1641, Valid Loss: 1.1982\n",
      "Validation loss improved to 1.1982\n",
      "Epoch [78/200], Train Loss: 1.1921, Valid Loss: 1.1952\n",
      "Validation loss improved to 1.1952\n",
      "Epoch [79/200], Train Loss: 1.1960, Valid Loss: 1.1921\n",
      "Validation loss improved to 1.1921\n",
      "Epoch [80/200], Train Loss: 1.1694, Valid Loss: 1.1891\n",
      "Validation loss improved to 1.1891\n",
      "Epoch [81/200], Train Loss: 1.1985, Valid Loss: 1.1860\n",
      "Validation loss improved to 1.1860\n",
      "Epoch [82/200], Train Loss: 1.1604, Valid Loss: 1.1829\n",
      "Validation loss improved to 1.1829\n",
      "Epoch [83/200], Train Loss: 1.1523, Valid Loss: 1.1798\n",
      "Validation loss improved to 1.1798\n",
      "Epoch [84/200], Train Loss: 1.1608, Valid Loss: 1.1767\n",
      "Validation loss improved to 1.1767\n",
      "Epoch [85/200], Train Loss: 1.1500, Valid Loss: 1.1735\n",
      "Validation loss improved to 1.1735\n",
      "Epoch [86/200], Train Loss: 1.1406, Valid Loss: 1.1702\n",
      "Validation loss improved to 1.1702\n",
      "Epoch [87/200], Train Loss: 1.1415, Valid Loss: 1.1669\n",
      "Validation loss improved to 1.1669\n",
      "Epoch [88/200], Train Loss: 1.1597, Valid Loss: 1.1635\n",
      "Validation loss improved to 1.1635\n",
      "Epoch [89/200], Train Loss: 1.1351, Valid Loss: 1.1600\n",
      "Validation loss improved to 1.1600\n",
      "Epoch [90/200], Train Loss: 1.1283, Valid Loss: 1.1566\n",
      "Validation loss improved to 1.1566\n",
      "Epoch [91/200], Train Loss: 1.1529, Valid Loss: 1.1532\n",
      "Validation loss improved to 1.1532\n",
      "Epoch [92/200], Train Loss: 1.1303, Valid Loss: 1.1497\n",
      "Validation loss improved to 1.1497\n",
      "Epoch [93/200], Train Loss: 1.1437, Valid Loss: 1.1462\n",
      "Validation loss improved to 1.1462\n",
      "Epoch [94/200], Train Loss: 1.1371, Valid Loss: 1.1428\n",
      "Validation loss improved to 1.1428\n",
      "Epoch [95/200], Train Loss: 1.1005, Valid Loss: 1.1393\n",
      "Validation loss improved to 1.1393\n",
      "Epoch [96/200], Train Loss: 1.1155, Valid Loss: 1.1359\n",
      "Validation loss improved to 1.1359\n",
      "Epoch [97/200], Train Loss: 1.1332, Valid Loss: 1.1324\n",
      "Validation loss improved to 1.1324\n",
      "Epoch [98/200], Train Loss: 1.1090, Valid Loss: 1.1289\n",
      "Validation loss improved to 1.1289\n",
      "Epoch [99/200], Train Loss: 1.1145, Valid Loss: 1.1253\n",
      "Validation loss improved to 1.1253\n",
      "Epoch [100/200], Train Loss: 1.1121, Valid Loss: 1.1218\n",
      "Validation loss improved to 1.1218\n",
      "Epoch [101/200], Train Loss: 1.0698, Valid Loss: 1.1182\n",
      "Validation loss improved to 1.1182\n",
      "Epoch [102/200], Train Loss: 1.0928, Valid Loss: 1.1145\n",
      "Validation loss improved to 1.1145\n",
      "Epoch [103/200], Train Loss: 1.0839, Valid Loss: 1.1107\n",
      "Validation loss improved to 1.1107\n",
      "Epoch [104/200], Train Loss: 1.0665, Valid Loss: 1.1069\n",
      "Validation loss improved to 1.1069\n",
      "Epoch [105/200], Train Loss: 1.0791, Valid Loss: 1.1030\n",
      "Validation loss improved to 1.1030\n",
      "Epoch [106/200], Train Loss: 1.0834, Valid Loss: 1.0990\n",
      "Validation loss improved to 1.0990\n",
      "Epoch [107/200], Train Loss: 1.0758, Valid Loss: 1.0951\n",
      "Validation loss improved to 1.0951\n",
      "Epoch [108/200], Train Loss: 1.0768, Valid Loss: 1.0913\n",
      "Validation loss improved to 1.0913\n",
      "Epoch [109/200], Train Loss: 1.0994, Valid Loss: 1.0874\n",
      "Validation loss improved to 1.0874\n",
      "Epoch [110/200], Train Loss: 1.0521, Valid Loss: 1.0835\n",
      "Validation loss improved to 1.0835\n",
      "Epoch [111/200], Train Loss: 1.0516, Valid Loss: 1.0795\n",
      "Validation loss improved to 1.0795\n",
      "Epoch [112/200], Train Loss: 1.0463, Valid Loss: 1.0753\n",
      "Validation loss improved to 1.0753\n",
      "Epoch [113/200], Train Loss: 1.1022, Valid Loss: 1.0713\n",
      "Validation loss improved to 1.0713\n",
      "Epoch [114/200], Train Loss: 1.0393, Valid Loss: 1.0672\n",
      "Validation loss improved to 1.0672\n",
      "Epoch [115/200], Train Loss: 1.0292, Valid Loss: 1.0631\n",
      "Validation loss improved to 1.0631\n",
      "Epoch [116/200], Train Loss: 1.0461, Valid Loss: 1.0590\n",
      "Validation loss improved to 1.0590\n",
      "Epoch [117/200], Train Loss: 1.0961, Valid Loss: 1.0549\n",
      "Validation loss improved to 1.0549\n",
      "Epoch [118/200], Train Loss: 1.0287, Valid Loss: 1.0506\n",
      "Validation loss improved to 1.0506\n",
      "Epoch [119/200], Train Loss: 1.0367, Valid Loss: 1.0463\n",
      "Validation loss improved to 1.0463\n",
      "Epoch [120/200], Train Loss: 1.0345, Valid Loss: 1.0421\n",
      "Validation loss improved to 1.0421\n",
      "Epoch [121/200], Train Loss: 1.0297, Valid Loss: 1.0380\n",
      "Validation loss improved to 1.0380\n",
      "Epoch [122/200], Train Loss: 1.0051, Valid Loss: 1.0338\n",
      "Validation loss improved to 1.0338\n",
      "Epoch [123/200], Train Loss: 1.0022, Valid Loss: 1.0295\n",
      "Validation loss improved to 1.0295\n",
      "Epoch [124/200], Train Loss: 0.9820, Valid Loss: 1.0251\n",
      "Validation loss improved to 1.0251\n",
      "Epoch [125/200], Train Loss: 1.0308, Valid Loss: 1.0206\n",
      "Validation loss improved to 1.0206\n",
      "Epoch [126/200], Train Loss: 0.9929, Valid Loss: 1.0160\n",
      "Validation loss improved to 1.0160\n",
      "Epoch [127/200], Train Loss: 1.0111, Valid Loss: 1.0115\n",
      "Validation loss improved to 1.0115\n",
      "Epoch [128/200], Train Loss: 1.0023, Valid Loss: 1.0069\n",
      "Validation loss improved to 1.0069\n",
      "Epoch [129/200], Train Loss: 0.9949, Valid Loss: 1.0021\n",
      "Validation loss improved to 1.0021\n",
      "Epoch [130/200], Train Loss: 1.0214, Valid Loss: 0.9974\n",
      "Validation loss improved to 0.9974\n",
      "Epoch [131/200], Train Loss: 0.9878, Valid Loss: 0.9925\n",
      "Validation loss improved to 0.9925\n",
      "Epoch [132/200], Train Loss: 1.0015, Valid Loss: 0.9877\n",
      "Validation loss improved to 0.9877\n",
      "Epoch [133/200], Train Loss: 0.9385, Valid Loss: 0.9828\n",
      "Validation loss improved to 0.9828\n",
      "Epoch [134/200], Train Loss: 0.9817, Valid Loss: 0.9778\n",
      "Validation loss improved to 0.9778\n",
      "Epoch [135/200], Train Loss: 0.9447, Valid Loss: 0.9727\n",
      "Validation loss improved to 0.9727\n",
      "Epoch [136/200], Train Loss: 0.9436, Valid Loss: 0.9674\n",
      "Validation loss improved to 0.9674\n",
      "Epoch [137/200], Train Loss: 0.9765, Valid Loss: 0.9622\n",
      "Validation loss improved to 0.9622\n",
      "Epoch [138/200], Train Loss: 0.9593, Valid Loss: 0.9570\n",
      "Validation loss improved to 0.9570\n",
      "Epoch [139/200], Train Loss: 0.9093, Valid Loss: 0.9517\n",
      "Validation loss improved to 0.9517\n",
      "Epoch [140/200], Train Loss: 0.9056, Valid Loss: 0.9462\n",
      "Validation loss improved to 0.9462\n",
      "Epoch [141/200], Train Loss: 0.9275, Valid Loss: 0.9409\n",
      "Validation loss improved to 0.9409\n",
      "Epoch [142/200], Train Loss: 0.8849, Valid Loss: 0.9355\n",
      "Validation loss improved to 0.9355\n",
      "Epoch [143/200], Train Loss: 0.9190, Valid Loss: 0.9300\n",
      "Validation loss improved to 0.9300\n",
      "Epoch [144/200], Train Loss: 0.9081, Valid Loss: 0.9244\n",
      "Validation loss improved to 0.9244\n",
      "Epoch [145/200], Train Loss: 0.9181, Valid Loss: 0.9188\n",
      "Validation loss improved to 0.9188\n",
      "Epoch [146/200], Train Loss: 0.9450, Valid Loss: 0.9134\n",
      "Validation loss improved to 0.9134\n",
      "Epoch [147/200], Train Loss: 0.9419, Valid Loss: 0.9082\n",
      "Validation loss improved to 0.9082\n",
      "Epoch [148/200], Train Loss: 0.9016, Valid Loss: 0.9029\n",
      "Validation loss improved to 0.9029\n",
      "Epoch [149/200], Train Loss: 0.8726, Valid Loss: 0.8976\n",
      "Validation loss improved to 0.8976\n",
      "Epoch [150/200], Train Loss: 0.8990, Valid Loss: 0.8923\n",
      "Validation loss improved to 0.8923\n",
      "Epoch [151/200], Train Loss: 0.9180, Valid Loss: 0.8872\n",
      "Validation loss improved to 0.8872\n",
      "Epoch [152/200], Train Loss: 0.8795, Valid Loss: 0.8823\n",
      "Validation loss improved to 0.8823\n",
      "Epoch [153/200], Train Loss: 0.9244, Valid Loss: 0.8776\n",
      "Validation loss improved to 0.8776\n",
      "Epoch [154/200], Train Loss: 0.8496, Valid Loss: 0.8731\n",
      "Validation loss improved to 0.8731\n",
      "Epoch [155/200], Train Loss: 0.8777, Valid Loss: 0.8688\n",
      "Validation loss improved to 0.8688\n",
      "Epoch [156/200], Train Loss: 0.8265, Valid Loss: 0.8642\n",
      "Validation loss improved to 0.8642\n",
      "Epoch [157/200], Train Loss: 0.8244, Valid Loss: 0.8593\n",
      "Validation loss improved to 0.8593\n",
      "Epoch [158/200], Train Loss: 0.8623, Valid Loss: 0.8541\n",
      "Validation loss improved to 0.8541\n",
      "Epoch [159/200], Train Loss: 0.8703, Valid Loss: 0.8487\n",
      "Validation loss improved to 0.8487\n",
      "Epoch [160/200], Train Loss: 0.8650, Valid Loss: 0.8428\n",
      "Validation loss improved to 0.8428\n",
      "Epoch [161/200], Train Loss: 0.7990, Valid Loss: 0.8368\n",
      "Validation loss improved to 0.8368\n",
      "Epoch [162/200], Train Loss: 0.8630, Valid Loss: 0.8309\n",
      "Validation loss improved to 0.8309\n",
      "Epoch [163/200], Train Loss: 0.8047, Valid Loss: 0.8252\n",
      "Validation loss improved to 0.8252\n",
      "Epoch [164/200], Train Loss: 0.8045, Valid Loss: 0.8197\n",
      "Validation loss improved to 0.8197\n",
      "Epoch [165/200], Train Loss: 0.8355, Valid Loss: 0.8145\n",
      "Validation loss improved to 0.8145\n",
      "Epoch [166/200], Train Loss: 0.8099, Valid Loss: 0.8094\n",
      "Validation loss improved to 0.8094\n",
      "Epoch [167/200], Train Loss: 0.8088, Valid Loss: 0.8047\n",
      "Validation loss improved to 0.8047\n",
      "Epoch [168/200], Train Loss: 0.8197, Valid Loss: 0.7996\n",
      "Validation loss improved to 0.7996\n",
      "Epoch [169/200], Train Loss: 0.7874, Valid Loss: 0.7944\n",
      "Validation loss improved to 0.7944\n",
      "Epoch [170/200], Train Loss: 0.8037, Valid Loss: 0.7889\n",
      "Validation loss improved to 0.7889\n",
      "Epoch [171/200], Train Loss: 0.8051, Valid Loss: 0.7831\n",
      "Validation loss improved to 0.7831\n",
      "Epoch [172/200], Train Loss: 0.7784, Valid Loss: 0.7775\n",
      "Validation loss improved to 0.7775\n",
      "Epoch [173/200], Train Loss: 0.7411, Valid Loss: 0.7720\n",
      "Validation loss improved to 0.7720\n",
      "Epoch [174/200], Train Loss: 0.7552, Valid Loss: 0.7664\n",
      "Validation loss improved to 0.7664\n",
      "Epoch [175/200], Train Loss: 0.8516, Valid Loss: 0.7611\n",
      "Validation loss improved to 0.7611\n",
      "Epoch [176/200], Train Loss: 0.7580, Valid Loss: 0.7557\n",
      "Validation loss improved to 0.7557\n",
      "Epoch [177/200], Train Loss: 0.7431, Valid Loss: 0.7503\n",
      "Validation loss improved to 0.7503\n",
      "Epoch [178/200], Train Loss: 0.7470, Valid Loss: 0.7449\n",
      "Validation loss improved to 0.7449\n",
      "Epoch [179/200], Train Loss: 0.7158, Valid Loss: 0.7392\n",
      "Validation loss improved to 0.7392\n",
      "Epoch [180/200], Train Loss: 0.7686, Valid Loss: 0.7333\n",
      "Validation loss improved to 0.7333\n",
      "Epoch [181/200], Train Loss: 0.6907, Valid Loss: 0.7276\n",
      "Validation loss improved to 0.7276\n",
      "Epoch [182/200], Train Loss: 0.7501, Valid Loss: 0.7226\n",
      "Validation loss improved to 0.7226\n",
      "Epoch [183/200], Train Loss: 0.7103, Valid Loss: 0.7173\n",
      "Validation loss improved to 0.7173\n",
      "Epoch [184/200], Train Loss: 0.7047, Valid Loss: 0.7117\n",
      "Validation loss improved to 0.7117\n",
      "Epoch [185/200], Train Loss: 0.6556, Valid Loss: 0.7058\n",
      "Validation loss improved to 0.7058\n",
      "Epoch [186/200], Train Loss: 0.7232, Valid Loss: 0.7003\n",
      "Validation loss improved to 0.7003\n",
      "Epoch [187/200], Train Loss: 0.6543, Valid Loss: 0.6946\n",
      "Validation loss improved to 0.6946\n",
      "Epoch [188/200], Train Loss: 0.6896, Valid Loss: 0.6888\n",
      "Validation loss improved to 0.6888\n",
      "Epoch [189/200], Train Loss: 0.7159, Valid Loss: 0.6832\n",
      "Validation loss improved to 0.6832\n",
      "Epoch [190/200], Train Loss: 0.6678, Valid Loss: 0.6780\n",
      "Validation loss improved to 0.6780\n",
      "Epoch [191/200], Train Loss: 0.6604, Valid Loss: 0.6730\n",
      "Validation loss improved to 0.6730\n",
      "Epoch [192/200], Train Loss: 0.6689, Valid Loss: 0.6680\n",
      "Validation loss improved to 0.6680\n",
      "Epoch [193/200], Train Loss: 0.6746, Valid Loss: 0.6628\n",
      "Validation loss improved to 0.6628\n",
      "Epoch [194/200], Train Loss: 0.6615, Valid Loss: 0.6572\n",
      "Validation loss improved to 0.6572\n",
      "Epoch [195/200], Train Loss: 0.6419, Valid Loss: 0.6513\n",
      "Validation loss improved to 0.6513\n",
      "Epoch [196/200], Train Loss: 0.6565, Valid Loss: 0.6454\n",
      "Validation loss improved to 0.6454\n",
      "Epoch [197/200], Train Loss: 0.6195, Valid Loss: 0.6393\n",
      "Validation loss improved to 0.6393\n",
      "Epoch [198/200], Train Loss: 0.6199, Valid Loss: 0.6337\n",
      "Validation loss improved to 0.6337\n",
      "Epoch [199/200], Train Loss: 0.5852, Valid Loss: 0.6286\n",
      "Validation loss improved to 0.6286\n",
      "Epoch [200/200], Train Loss: 0.5765, Valid Loss: 0.6229\n",
      "Validation loss improved to 0.6229\n",
      "Training completed. Final model saved as model/loss_0.6229_lr_0.001_batch_128_opt_SGD.pt\n",
      "Training with parameters: {'batch_size': 128, 'epochs': 200, 'learning_rate': 0.001, 'optimizer': 'RMSprop'}\n",
      "Epoch [1/200], Train Loss: 1.3828, Valid Loss: 1.3917\n",
      "Validation loss improved to 1.3917\n",
      "Epoch [2/200], Train Loss: 1.4099, Valid Loss: 1.5526\n",
      "Epoch [3/200], Train Loss: 1.5635, Valid Loss: 1.4063\n",
      "Epoch [4/200], Train Loss: 1.4458, Valid Loss: 1.3550\n",
      "Validation loss improved to 1.3550\n",
      "Epoch [5/200], Train Loss: 1.4438, Valid Loss: 1.3517\n",
      "Validation loss improved to 1.3517\n",
      "Epoch [6/200], Train Loss: 1.3474, Valid Loss: 1.3560\n",
      "Epoch [7/200], Train Loss: 1.3501, Valid Loss: 1.3899\n",
      "Epoch [8/200], Train Loss: 1.3228, Valid Loss: 1.2526\n",
      "Validation loss improved to 1.2526\n",
      "Epoch [9/200], Train Loss: 1.3898, Valid Loss: 1.3069\n",
      "Epoch [10/200], Train Loss: 1.4102, Valid Loss: 1.2748\n",
      "Epoch [11/200], Train Loss: 1.3173, Valid Loss: 1.2332\n",
      "Validation loss improved to 1.2332\n",
      "Epoch [12/200], Train Loss: 1.3323, Valid Loss: 1.2372\n",
      "Epoch [13/200], Train Loss: 1.2915, Valid Loss: 1.1748\n",
      "Validation loss improved to 1.1748\n",
      "Epoch [14/200], Train Loss: 1.2580, Valid Loss: 1.1554\n",
      "Validation loss improved to 1.1554\n",
      "Epoch [15/200], Train Loss: 1.1702, Valid Loss: 1.1301\n",
      "Validation loss improved to 1.1301\n",
      "Epoch [16/200], Train Loss: 1.1613, Valid Loss: 1.1828\n",
      "Epoch [17/200], Train Loss: 1.2527, Valid Loss: 1.5381\n",
      "Epoch [18/200], Train Loss: 1.5124, Valid Loss: 1.2707\n",
      "Epoch [19/200], Train Loss: 1.3153, Valid Loss: 1.2768\n",
      "Epoch [20/200], Train Loss: 1.3395, Valid Loss: 1.2741\n",
      "Epoch [21/200], Train Loss: 1.2857, Valid Loss: 1.2006\n",
      "Epoch [22/200], Train Loss: 1.2694, Valid Loss: 1.1892\n",
      "Epoch [23/200], Train Loss: 1.2633, Valid Loss: 1.2499\n",
      "Epoch [24/200], Train Loss: 1.2358, Valid Loss: 1.1674\n",
      "Epoch [25/200], Train Loss: 1.2259, Valid Loss: 1.2041\n",
      "Early stopping triggered at epoch 25\n",
      "Training completed. Final model saved as model/loss_1.1301_lr_0.001_batch_128_opt_RMSprop.pt\n",
      "Training with parameters: {'batch_size': 128, 'epochs': 200, 'learning_rate': 0.01, 'optimizer': 'Adam'}\n",
      "Epoch [1/200], Train Loss: 1.3945, Valid Loss: 1.3881\n",
      "Validation loss improved to 1.3881\n",
      "Epoch [2/200], Train Loss: 1.3540, Valid Loss: 1.4297\n",
      "Epoch [3/200], Train Loss: 1.4724, Valid Loss: 1.4268\n",
      "Epoch [4/200], Train Loss: 1.3831, Valid Loss: 1.4196\n",
      "Epoch [5/200], Train Loss: 1.4789, Valid Loss: 1.3934\n",
      "Epoch [6/200], Train Loss: 1.3814, Valid Loss: 1.4881\n",
      "Epoch [7/200], Train Loss: 1.4909, Valid Loss: 1.3775\n",
      "Validation loss improved to 1.3775\n",
      "Epoch [8/200], Train Loss: 1.4423, Valid Loss: 1.3748\n",
      "Validation loss improved to 1.3748\n",
      "Epoch [9/200], Train Loss: 1.4150, Valid Loss: 1.3879\n",
      "Epoch [10/200], Train Loss: 1.3810, Valid Loss: 1.3887\n",
      "Epoch [11/200], Train Loss: 1.4153, Valid Loss: 1.3564\n",
      "Validation loss improved to 1.3564\n",
      "Epoch [12/200], Train Loss: 1.3407, Valid Loss: 1.3356\n",
      "Validation loss improved to 1.3356\n",
      "Epoch [13/200], Train Loss: 1.3208, Valid Loss: 1.3267\n",
      "Validation loss improved to 1.3267\n",
      "Epoch [14/200], Train Loss: 1.3433, Valid Loss: 1.3105\n",
      "Validation loss improved to 1.3105\n",
      "Epoch [15/200], Train Loss: 1.3337, Valid Loss: 1.2988\n",
      "Validation loss improved to 1.2988\n",
      "Epoch [16/200], Train Loss: 1.3145, Valid Loss: 1.2775\n",
      "Validation loss improved to 1.2775\n",
      "Epoch [17/200], Train Loss: 1.3315, Valid Loss: 1.2480\n",
      "Validation loss improved to 1.2480\n",
      "Epoch [18/200], Train Loss: 1.3015, Valid Loss: 1.2789\n",
      "Epoch [19/200], Train Loss: 1.3087, Valid Loss: 1.2557\n",
      "Epoch [20/200], Train Loss: 1.2533, Valid Loss: 1.2346\n",
      "Validation loss improved to 1.2346\n",
      "Epoch [21/200], Train Loss: 1.2495, Valid Loss: 1.3750\n",
      "Epoch [22/200], Train Loss: 1.3283, Valid Loss: 1.3808\n",
      "Epoch [23/200], Train Loss: 1.2946, Valid Loss: 1.3243\n",
      "Epoch [24/200], Train Loss: 1.2754, Valid Loss: 1.2839\n",
      "Epoch [25/200], Train Loss: 1.2864, Valid Loss: 1.2795\n",
      "Epoch [26/200], Train Loss: 1.2490, Valid Loss: 1.2804\n",
      "Epoch [27/200], Train Loss: 1.2252, Valid Loss: 1.3151\n",
      "Epoch [28/200], Train Loss: 1.2509, Valid Loss: 1.3326\n",
      "Epoch [29/200], Train Loss: 1.2047, Valid Loss: 1.3319\n",
      "Epoch [30/200], Train Loss: 1.1949, Valid Loss: 1.4390\n",
      "Early stopping triggered at epoch 30\n",
      "Training completed. Final model saved as model/loss_1.2346_lr_0.01_batch_128_opt_Adam.pt\n",
      "Training with parameters: {'batch_size': 128, 'epochs': 200, 'learning_rate': 0.01, 'optimizer': 'SGD'}\n",
      "Epoch [1/200], Train Loss: 1.4030, Valid Loss: 1.3916\n",
      "Validation loss improved to 1.3916\n",
      "Epoch [2/200], Train Loss: 1.4092, Valid Loss: 1.3822\n",
      "Validation loss improved to 1.3822\n",
      "Epoch [3/200], Train Loss: 1.3754, Valid Loss: 1.3712\n",
      "Validation loss improved to 1.3712\n",
      "Epoch [4/200], Train Loss: 1.3416, Valid Loss: 1.3585\n",
      "Validation loss improved to 1.3585\n",
      "Epoch [5/200], Train Loss: 1.3672, Valid Loss: 1.3454\n",
      "Validation loss improved to 1.3454\n",
      "Epoch [6/200], Train Loss: 1.3417, Valid Loss: 1.3316\n",
      "Validation loss improved to 1.3316\n",
      "Epoch [7/200], Train Loss: 1.3234, Valid Loss: 1.3187\n",
      "Validation loss improved to 1.3187\n",
      "Epoch [8/200], Train Loss: 1.2902, Valid Loss: 1.3071\n",
      "Validation loss improved to 1.3071\n",
      "Epoch [9/200], Train Loss: 1.2923, Valid Loss: 1.2958\n",
      "Validation loss improved to 1.2958\n",
      "Epoch [10/200], Train Loss: 1.2565, Valid Loss: 1.2844\n",
      "Validation loss improved to 1.2844\n",
      "Epoch [11/200], Train Loss: 1.2476, Valid Loss: 1.2727\n",
      "Validation loss improved to 1.2727\n",
      "Epoch [12/200], Train Loss: 1.2170, Valid Loss: 1.2607\n",
      "Validation loss improved to 1.2607\n",
      "Epoch [13/200], Train Loss: 1.2397, Valid Loss: 1.2484\n",
      "Validation loss improved to 1.2484\n",
      "Epoch [14/200], Train Loss: 1.2026, Valid Loss: 1.2355\n",
      "Validation loss improved to 1.2355\n",
      "Epoch [15/200], Train Loss: 1.2067, Valid Loss: 1.2211\n",
      "Validation loss improved to 1.2211\n",
      "Epoch [16/200], Train Loss: 1.1867, Valid Loss: 1.2060\n",
      "Validation loss improved to 1.2060\n",
      "Epoch [17/200], Train Loss: 1.1867, Valid Loss: 1.1901\n",
      "Validation loss improved to 1.1901\n",
      "Epoch [18/200], Train Loss: 1.1456, Valid Loss: 1.1735\n",
      "Validation loss improved to 1.1735\n",
      "Epoch [19/200], Train Loss: 1.1653, Valid Loss: 1.1562\n",
      "Validation loss improved to 1.1562\n",
      "Epoch [20/200], Train Loss: 1.1118, Valid Loss: 1.1374\n",
      "Validation loss improved to 1.1374\n",
      "Epoch [21/200], Train Loss: 1.1288, Valid Loss: 1.1179\n",
      "Validation loss improved to 1.1179\n",
      "Epoch [22/200], Train Loss: 1.0922, Valid Loss: 1.0978\n",
      "Validation loss improved to 1.0978\n",
      "Epoch [23/200], Train Loss: 1.0641, Valid Loss: 1.0774\n",
      "Validation loss improved to 1.0774\n",
      "Epoch [24/200], Train Loss: 1.0285, Valid Loss: 1.0556\n",
      "Validation loss improved to 1.0556\n",
      "Epoch [25/200], Train Loss: 1.0106, Valid Loss: 1.0321\n",
      "Validation loss improved to 1.0321\n",
      "Epoch [26/200], Train Loss: 0.9825, Valid Loss: 1.0067\n",
      "Validation loss improved to 1.0067\n",
      "Epoch [27/200], Train Loss: 0.9601, Valid Loss: 0.9786\n",
      "Validation loss improved to 0.9786\n",
      "Epoch [28/200], Train Loss: 0.9086, Valid Loss: 0.9481\n",
      "Validation loss improved to 0.9481\n",
      "Epoch [29/200], Train Loss: 0.9101, Valid Loss: 0.9147\n",
      "Validation loss improved to 0.9147\n",
      "Epoch [30/200], Train Loss: 0.8934, Valid Loss: 0.8807\n",
      "Validation loss improved to 0.8807\n",
      "Epoch [31/200], Train Loss: 0.8742, Valid Loss: 0.8459\n",
      "Validation loss improved to 0.8459\n",
      "Epoch [32/200], Train Loss: 0.8166, Valid Loss: 0.8089\n",
      "Validation loss improved to 0.8089\n",
      "Epoch [33/200], Train Loss: 0.7661, Valid Loss: 0.7705\n",
      "Validation loss improved to 0.7705\n",
      "Epoch [34/200], Train Loss: 0.7355, Valid Loss: 0.7315\n",
      "Validation loss improved to 0.7315\n",
      "Epoch [35/200], Train Loss: 0.7411, Valid Loss: 0.6954\n",
      "Validation loss improved to 0.6954\n",
      "Epoch [36/200], Train Loss: 0.6878, Valid Loss: 0.6589\n",
      "Validation loss improved to 0.6589\n",
      "Epoch [37/200], Train Loss: 0.7053, Valid Loss: 0.6242\n",
      "Validation loss improved to 0.6242\n",
      "Epoch [38/200], Train Loss: 0.5793, Valid Loss: 0.5892\n",
      "Validation loss improved to 0.5892\n",
      "Epoch [39/200], Train Loss: 0.6205, Valid Loss: 0.5530\n",
      "Validation loss improved to 0.5530\n",
      "Epoch [40/200], Train Loss: 0.6035, Valid Loss: 0.5176\n",
      "Validation loss improved to 0.5176\n",
      "Epoch [41/200], Train Loss: 0.5423, Valid Loss: 0.4853\n",
      "Validation loss improved to 0.4853\n",
      "Epoch [42/200], Train Loss: 0.5375, Valid Loss: 0.4567\n",
      "Validation loss improved to 0.4567\n",
      "Epoch [43/200], Train Loss: 0.4556, Valid Loss: 0.4321\n",
      "Validation loss improved to 0.4321\n",
      "Epoch [44/200], Train Loss: 0.4326, Valid Loss: 0.4057\n",
      "Validation loss improved to 0.4057\n",
      "Epoch [45/200], Train Loss: 0.4461, Valid Loss: 0.3750\n",
      "Validation loss improved to 0.3750\n",
      "Epoch [46/200], Train Loss: 0.3774, Valid Loss: 0.3489\n",
      "Validation loss improved to 0.3489\n",
      "Epoch [47/200], Train Loss: 0.3860, Valid Loss: 0.3253\n",
      "Validation loss improved to 0.3253\n",
      "Epoch [48/200], Train Loss: 0.3662, Valid Loss: 0.3044\n",
      "Validation loss improved to 0.3044\n",
      "Epoch [49/200], Train Loss: 0.2848, Valid Loss: 0.2858\n",
      "Validation loss improved to 0.2858\n",
      "Epoch [50/200], Train Loss: 0.2454, Valid Loss: 0.2696\n",
      "Validation loss improved to 0.2696\n",
      "Epoch [51/200], Train Loss: 0.2816, Valid Loss: 0.2518\n",
      "Validation loss improved to 0.2518\n",
      "Epoch [52/200], Train Loss: 0.2895, Valid Loss: 0.2357\n",
      "Validation loss improved to 0.2357\n",
      "Epoch [53/200], Train Loss: 0.2534, Valid Loss: 0.2211\n",
      "Validation loss improved to 0.2211\n",
      "Epoch [54/200], Train Loss: 0.2645, Valid Loss: 0.2038\n",
      "Validation loss improved to 0.2038\n",
      "Epoch [55/200], Train Loss: 0.2391, Valid Loss: 0.1866\n",
      "Validation loss improved to 0.1866\n",
      "Epoch [56/200], Train Loss: 0.1781, Valid Loss: 0.1752\n",
      "Validation loss improved to 0.1752\n",
      "Epoch [57/200], Train Loss: 0.2339, Valid Loss: 0.1670\n",
      "Validation loss improved to 0.1670\n",
      "Epoch [58/200], Train Loss: 0.2299, Valid Loss: 0.1626\n",
      "Validation loss improved to 0.1626\n",
      "Epoch [59/200], Train Loss: 0.1798, Valid Loss: 0.1604\n",
      "Validation loss improved to 0.1604\n",
      "Epoch [60/200], Train Loss: 0.2165, Valid Loss: 0.1508\n",
      "Validation loss improved to 0.1508\n",
      "Epoch [61/200], Train Loss: 0.1585, Valid Loss: 0.1354\n",
      "Validation loss improved to 0.1354\n",
      "Epoch [62/200], Train Loss: 0.1404, Valid Loss: 0.1215\n",
      "Validation loss improved to 0.1215\n",
      "Epoch [63/200], Train Loss: 0.1260, Valid Loss: 0.1136\n",
      "Validation loss improved to 0.1136\n",
      "Epoch [64/200], Train Loss: 0.1599, Valid Loss: 0.1094\n",
      "Validation loss improved to 0.1094\n",
      "Epoch [65/200], Train Loss: 0.1035, Valid Loss: 0.1055\n",
      "Validation loss improved to 0.1055\n",
      "Epoch [66/200], Train Loss: 0.1003, Valid Loss: 0.1007\n",
      "Validation loss improved to 0.1007\n",
      "Epoch [67/200], Train Loss: 0.1073, Valid Loss: 0.0975\n",
      "Validation loss improved to 0.0975\n",
      "Epoch [68/200], Train Loss: 0.1028, Valid Loss: 0.0932\n",
      "Validation loss improved to 0.0932\n",
      "Epoch [69/200], Train Loss: 0.1268, Valid Loss: 0.0880\n",
      "Validation loss improved to 0.0880\n",
      "Epoch [70/200], Train Loss: 0.0916, Valid Loss: 0.0844\n",
      "Validation loss improved to 0.0844\n",
      "Epoch [71/200], Train Loss: 0.0689, Valid Loss: 0.0809\n",
      "Validation loss improved to 0.0809\n",
      "Epoch [72/200], Train Loss: 0.1050, Valid Loss: 0.0783\n",
      "Validation loss improved to 0.0783\n",
      "Epoch [73/200], Train Loss: 0.0519, Valid Loss: 0.0779\n",
      "Validation loss improved to 0.0779\n",
      "Epoch [74/200], Train Loss: 0.0635, Valid Loss: 0.0810\n",
      "Epoch [75/200], Train Loss: 0.0702, Valid Loss: 0.0836\n",
      "Epoch [76/200], Train Loss: 0.0850, Valid Loss: 0.0827\n",
      "Epoch [77/200], Train Loss: 0.0706, Valid Loss: 0.0751\n",
      "Validation loss improved to 0.0751\n",
      "Epoch [78/200], Train Loss: 0.0936, Valid Loss: 0.0689\n",
      "Validation loss improved to 0.0689\n",
      "Epoch [79/200], Train Loss: 0.0601, Valid Loss: 0.0641\n",
      "Validation loss improved to 0.0641\n",
      "Epoch [80/200], Train Loss: 0.0775, Valid Loss: 0.0632\n",
      "Validation loss improved to 0.0632\n",
      "Epoch [81/200], Train Loss: 0.0857, Valid Loss: 0.0693\n",
      "Epoch [82/200], Train Loss: 0.0474, Valid Loss: 0.0821\n",
      "Epoch [83/200], Train Loss: 0.0581, Valid Loss: 0.0934\n",
      "Epoch [84/200], Train Loss: 0.0408, Valid Loss: 0.1049\n",
      "Epoch [85/200], Train Loss: 0.0533, Valid Loss: 0.1082\n",
      "Epoch [86/200], Train Loss: 0.0538, Valid Loss: 0.1000\n",
      "Epoch [87/200], Train Loss: 0.0339, Valid Loss: 0.0901\n",
      "Epoch [88/200], Train Loss: 0.0584, Valid Loss: 0.0791\n",
      "Epoch [89/200], Train Loss: 0.0339, Valid Loss: 0.0692\n",
      "Epoch [90/200], Train Loss: 0.0383, Valid Loss: 0.0609\n",
      "Validation loss improved to 0.0609\n",
      "Epoch [91/200], Train Loss: 0.0517, Valid Loss: 0.0553\n",
      "Validation loss improved to 0.0553\n",
      "Epoch [92/200], Train Loss: 0.0578, Valid Loss: 0.0541\n",
      "Validation loss improved to 0.0541\n",
      "Epoch [93/200], Train Loss: 0.0529, Valid Loss: 0.0537\n",
      "Validation loss improved to 0.0537\n",
      "Epoch [94/200], Train Loss: 0.0539, Valid Loss: 0.0526\n",
      "Validation loss improved to 0.0526\n",
      "Epoch [95/200], Train Loss: 0.0311, Valid Loss: 0.0531\n",
      "Epoch [96/200], Train Loss: 0.0320, Valid Loss: 0.0584\n",
      "Epoch [97/200], Train Loss: 0.0453, Valid Loss: 0.0670\n",
      "Epoch [98/200], Train Loss: 0.0423, Valid Loss: 0.0732\n",
      "Epoch [99/200], Train Loss: 0.0337, Valid Loss: 0.0783\n",
      "Epoch [100/200], Train Loss: 0.0380, Valid Loss: 0.0812\n",
      "Epoch [101/200], Train Loss: 0.0445, Valid Loss: 0.0824\n",
      "Epoch [102/200], Train Loss: 0.0574, Valid Loss: 0.0837\n",
      "Epoch [103/200], Train Loss: 0.0241, Valid Loss: 0.0855\n",
      "Epoch [104/200], Train Loss: 0.0356, Valid Loss: 0.0851\n",
      "Early stopping triggered at epoch 104\n",
      "Training completed. Final model saved as model/loss_0.0526_lr_0.01_batch_128_opt_SGD.pt\n",
      "Training with parameters: {'batch_size': 128, 'epochs': 200, 'learning_rate': 0.01, 'optimizer': 'RMSprop'}\n",
      "Epoch [1/200], Train Loss: 1.4129, Valid Loss: 1.6804\n",
      "Validation loss improved to 1.6804\n",
      "Epoch [2/200], Train Loss: 1.7781, Valid Loss: 12.0030\n",
      "Epoch [3/200], Train Loss: 11.8885, Valid Loss: 19.4823\n",
      "Epoch [4/200], Train Loss: 22.1069, Valid Loss: 8.1547\n",
      "Epoch [5/200], Train Loss: 7.7352, Valid Loss: 4.1245\n",
      "Epoch [6/200], Train Loss: 4.9970, Valid Loss: 3.4344\n",
      "Epoch [7/200], Train Loss: 3.7979, Valid Loss: 3.0530\n",
      "Epoch [8/200], Train Loss: 3.2979, Valid Loss: 1.4005\n",
      "Validation loss improved to 1.4005\n",
      "Epoch [9/200], Train Loss: 1.4050, Valid Loss: 1.4031\n",
      "Epoch [10/200], Train Loss: 1.4347, Valid Loss: 1.3867\n",
      "Validation loss improved to 1.3867\n",
      "Epoch [11/200], Train Loss: 1.3847, Valid Loss: 1.3898\n",
      "Epoch [12/200], Train Loss: 1.3909, Valid Loss: 1.3867\n",
      "Validation loss improved to 1.3867\n",
      "Epoch [13/200], Train Loss: 1.3873, Valid Loss: 1.3867\n",
      "Validation loss improved to 1.3867\n",
      "Epoch [14/200], Train Loss: 1.3867, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [15/200], Train Loss: 1.3866, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [16/200], Train Loss: 1.3866, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [17/200], Train Loss: 1.3866, Valid Loss: 1.3866\n",
      "Validation loss improved to 1.3866\n",
      "Epoch [18/200], Train Loss: 1.3866, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [19/200], Train Loss: 1.3865, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [20/200], Train Loss: 1.3865, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [21/200], Train Loss: 1.3865, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [22/200], Train Loss: 1.3865, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [23/200], Train Loss: 1.3865, Valid Loss: 1.3865\n",
      "Validation loss improved to 1.3865\n",
      "Epoch [24/200], Train Loss: 1.3865, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [25/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [26/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [27/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [28/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [29/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [30/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [31/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [32/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [33/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [34/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [35/200], Train Loss: 1.3864, Valid Loss: 1.3864\n",
      "Validation loss improved to 1.3864\n",
      "Epoch [36/200], Train Loss: 1.3864, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [37/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [38/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [39/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [40/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [41/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [42/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [43/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [44/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [45/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [46/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [47/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [48/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [49/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [50/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [51/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [52/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [53/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [54/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [55/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [56/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [57/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [58/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [59/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [60/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [61/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [62/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [63/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [64/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [65/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [66/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [67/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [68/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [69/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [70/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [71/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [72/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [73/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [74/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [75/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [76/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [77/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [78/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [79/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [80/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [81/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [82/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [83/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [84/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [85/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [86/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [87/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [88/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [89/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [90/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [91/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [92/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [93/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [94/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [95/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [96/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [97/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [98/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [99/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [100/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [101/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [102/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [103/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [104/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [105/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [106/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [107/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Validation loss improved to 1.3863\n",
      "Epoch [108/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [109/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [110/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [111/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [112/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [113/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [114/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [115/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [116/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Epoch [117/200], Train Loss: 1.3863, Valid Loss: 1.3863\n",
      "Early stopping triggered at epoch 117\n",
      "Training completed. Final model saved as model/loss_1.3863_lr_0.01_batch_128_opt_RMSprop.pt\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1e14ba5676db3b5d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
